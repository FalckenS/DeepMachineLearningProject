{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Deep Machine Learning Project (SSY340)\n",
    "\n",
    "Project Group 92"
   ],
   "id": "755ce3c68a828da7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Environment setup:",
   "id": "7ab7239d695adf25"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports and CUDA setup:",
   "id": "6ac8efba5d72a9fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T10:03:39.533791Z",
     "start_time": "2025-10-21T10:03:18.614101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, math, random, torch, gc, ast, re\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from transformers import AutoModel\n",
    "\n",
    "%pip install --upgrade pip\n",
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu129\n",
    "\n",
    "print(\"\\nPyTorch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA version:\", torch.version.cuda)\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "PIN_MEMORY = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "SEED = 0\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Method for clearing cache and GPU memory\n",
    "def clear_cache():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ],
   "id": "81b8df0429de0732",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\python312\\lib\\site-packages (25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu129\n",
      "Requirement already satisfied: torch in c:\\python312\\lib\\site-packages (2.8.0+cu129)\n",
      "Requirement already satisfied: torchvision in c:\\python312\\lib\\site-packages (0.23.0+cu129)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python312\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\python312\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (from torchvision) (2.3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python312\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "PyTorch: 2.8.0+cu129\n",
      "CUDA available: True\n",
      "CUDA version: 12.9\n",
      "Device name: NVIDIA GeForce RTX 2070\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Constants:",
   "id": "33e675f07eca55ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T10:03:48.716423Z",
     "start_time": "2025-10-21T10:03:48.711496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paths\n",
    "IMAGES_DIR = \"flickr30k-images\"\n",
    "CSV_PATH = \"flickr_annotations_30k.csv\"\n",
    "CAPTIONS_FILE = \"Flickr30k.token.txt\"\n",
    "\n",
    "NUM_WORKERS = 0\n",
    "MIN_FREQ = 5 # Minimum frequency for vocab, lower value means slower training but bigger vocabulary\n",
    "MAX_LEN = 100\n",
    "NUM_EPOCHS = 5\n",
    "PRINT_EVERY = 10\n",
    "\n",
    "TRAIN_RATIO = 0.8\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1"
   ],
   "id": "6aef934d3f1eddd2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup Flickr30k.token.txt (captions):",
   "id": "50c62e26d9f6e174"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T10:03:52.261190Z",
     "start_time": "2025-10-21T10:03:52.254945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def _get_image_name(row, df):\n",
    "    for col in ('file_name','filename','image','img','image_filename','img_name','image_name','img_id','image_id','path'):\n",
    "        if col in df.columns:\n",
    "            val = row.get(col)\n",
    "            if pd.isna(val):\n",
    "                continue\n",
    "            return os.path.basename(str(val))\n",
    "    return f\"{row.name}.jpg\"\n",
    "\n",
    "def _get_captions(row, df):\n",
    "    for col in ('raw','captions','sentences','sentence','caption','raw_captions','sentids'):\n",
    "        if col in df.columns:\n",
    "            val = row.get(col)\n",
    "            if pd.isna(val):\n",
    "                continue\n",
    "            if isinstance(val, (list, tuple)):\n",
    "                return [str(x).strip() for x in val if str(x).strip()]\n",
    "            if isinstance(val, str):\n",
    "                try:\n",
    "                    parsed = ast.literal_eval(val)\n",
    "                    if isinstance(parsed, (list, tuple)):\n",
    "                        return [str(x).strip() for x in parsed if str(x).strip()]\n",
    "                    if isinstance(parsed, dict) and 'raw' in parsed:\n",
    "                        r = parsed['raw']\n",
    "                        if isinstance(r, (list, tuple)):\n",
    "                            return [str(x).strip() for x in r if str(x).strip()]\n",
    "                except Exception:\n",
    "                    pass\n",
    "                for sep in ('|||', '||', '\\n'):\n",
    "                    if sep in val:\n",
    "                        return [s.strip() for s in val.split(sep) if s.strip()]\n",
    "                return [val.strip()]\n",
    "    return []\n",
    "\n",
    "def generate_token_file_from_csv(csv_path, captions_file):\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    print(\"CSV columns:\", list(df.columns))\n",
    "    with open(captions_file, 'w', encoding='utf-8') as fout:\n",
    "        for _, row in df.iterrows():\n",
    "            img_name = _get_image_name(row, df)\n",
    "            caps = _get_captions(row, df)\n",
    "            if not caps:\n",
    "                continue\n",
    "            for i, c in enumerate(caps):\n",
    "                fout.write(f\"{img_name}#{i}\\t{c}\\n\")\n",
    "    print(\"Wrote token file:\", captions_file)\n",
    "\n",
    "# If you already have CAPTIONS_FILE from earlier step, skip this call.\n",
    "if os.path.exists(CSV_PATH) and not os.path.exists(CAPTIONS_FILE):\n",
    "    generate_token_file_from_csv(CSV_PATH, CAPTIONS_FILE)"
   ],
   "id": "8eb6d435fed5dbeb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Setup tokenizer/vocab:",
   "id": "ba2fcb2a0232f7b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T10:03:57.180321Z",
     "start_time": "2025-10-21T10:03:57.172462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Vocab:\n",
    "    def __init__(self, min_freq=5, reserved=None):\n",
    "        if reserved is None:\n",
    "            reserved = ['<pad>', '<start>', '<end>', '<unk>']\n",
    "        self.min_freq = min_freq\n",
    "        self.reserved = reserved\n",
    "        self.freq = Counter()\n",
    "        self.itos = []\n",
    "        self.stoi = {}\n",
    "\n",
    "    def build(self, token_lists):\n",
    "        for t in token_lists:\n",
    "            self.freq.update(t)\n",
    "        self.itos = list(self.reserved)\n",
    "        for tok, cnt in self.freq.most_common():\n",
    "            if cnt < self.min_freq:\n",
    "                continue\n",
    "            if tok in self.reserved:\n",
    "                continue\n",
    "            self.itos.append(tok)\n",
    "        self.stoi = {tok:i for i,tok in enumerate(self.itos)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "    def numericalize(self, tokens):\n",
    "        return [self.stoi.get(t, self.stoi['<unk>']) for t in tokens]\n",
    "\n",
    "\n",
    "def tokenize_caption(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9' ]+\", \" \", text)\n",
    "    tokens = text.split()\n",
    "    return tokens"
   ],
   "id": "b9bb3bc066e6ff1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Datasets:",
   "id": "cd6c39a10b09d502"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T10:04:03.308319Z",
     "start_time": "2025-10-21T10:04:02.021476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Flickr30kDataset(Dataset):\n",
    "    def __init__(self, images_dir, captions_file, vocab=None, transform=None, split='train', seed=SEED):\n",
    "        self.images_dir = str(images_dir)\n",
    "        self.transform = transform\n",
    "        image_to_captions = defaultdict(list)\n",
    "        with open(captions_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                parts = line.split('\\t')\n",
    "                if len(parts) != 2:\n",
    "                    continue\n",
    "                img_token, cap = parts\n",
    "                img_name = img_token.split('#')[0]\n",
    "                image_to_captions[img_name].append(cap)\n",
    "\n",
    "        available = set(os.listdir(self.images_dir))\n",
    "        self.entries = []\n",
    "        for img, caps in image_to_captions.items():\n",
    "            if img not in available:\n",
    "                continue\n",
    "            for c in caps:\n",
    "                self.entries.append((img, c))\n",
    "\n",
    "        # Split images at the image level\n",
    "        images = sorted(list({e[0] for e in self.entries}))\n",
    "        random.Random(seed).shuffle(images)\n",
    "        n_train = int(len(images) * TRAIN_RATIO)\n",
    "        n_val = int(len(images) * VAL_RATIO)\n",
    "        train_images = set(images[:n_train])\n",
    "        val_images = set(images[n_train:n_train+n_val])\n",
    "        test_images = set(images[n_train+n_val:])\n",
    "\n",
    "        if split == 'train':\n",
    "            self.entries = [e for e in self.entries if e[0] in train_images]\n",
    "        elif split == 'val':\n",
    "            self.entries = [e for e in self.entries if e[0] in val_images]\n",
    "        elif split == 'test':\n",
    "            self.entries = [e for e in self.entries if e[0] in test_images]\n",
    "        else:\n",
    "            raise ValueError(\"split must be 'train', 'val', or 'test'\")\n",
    "\n",
    "        if vocab is None and split=='train':\n",
    "            token_lists = [tokenize_caption(c) for _, c in self.entries]\n",
    "            self.vocab = Vocab(min_freq=MIN_FREQ)\n",
    "            self.vocab.build(token_lists)\n",
    "        elif vocab is not None:\n",
    "            self.vocab = vocab\n",
    "        else:\n",
    "            raise ValueError(\"Provide vocab for val/test split\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name, cap = self.entries[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        tokens = tokenize_caption(cap)\n",
    "        num_caption = torch.tensor([self.vocab.stoi['<start>']] + self.vocab.numericalize(tokens) + [self.vocab.stoi['<end>']])\n",
    "        return image, num_caption\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, caps = zip(*batch)\n",
    "    images = torch.stack(images, dim=0)\n",
    "    lengths = [c.size(0) for c in caps]\n",
    "    caps_padded = nn.utils.rnn.pad_sequence(caps, batch_first=True, padding_value=0)\n",
    "    return images, caps_padded, lengths\n",
    "\n",
    "# Transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = Flickr30kDataset(IMAGES_DIR, CAPTIONS_FILE, vocab=None, transform=train_transform, split='train')\n",
    "vocab = train_ds.vocab\n",
    "val_ds = Flickr30kDataset(IMAGES_DIR, CAPTIONS_FILE, vocab=vocab, transform=val_transform, split='val')\n",
    "test_ds = Flickr30kDataset(IMAGES_DIR, CAPTIONS_FILE, vocab=vocab, transform=val_transform, split='test')"
   ],
   "id": "bbccdb64a818704",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training utilities:",
   "id": "f804f60af8e30afc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T10:04:07.017111Z",
     "start_time": "2025-10-21T10:04:07.008251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch(enc, dec, loader, criterion, enc_opt, dec_opt, device, print_every=PRINT_EVERY):\n",
    "    enc.train(); dec.train()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "    n_batches = 0\n",
    "\n",
    "    for images, caps, lengths in loader:\n",
    "        images = images.to(device)\n",
    "        caps = caps.to(device)\n",
    "\n",
    "        feats = enc(images)\n",
    "\n",
    "        # Clip captions to decoder's max length\n",
    "        caps_input = caps[:, :-1]             # (B, L-1)\n",
    "        caps_input = caps_input[:, :dec.max_len]  # clip to max_len\n",
    "        logits = dec(feats, caps_input)\n",
    "\n",
    "        targets = caps[:, 1:]                 # (B, L-1)\n",
    "        targets = targets[:, :dec.max_len]   # same length as logits\n",
    "        logits = logits[:, :targets.size(1), :]  # make shapes match\n",
    "\n",
    "        logits_flat = logits.contiguous().view(-1, logits.size(-1))\n",
    "        targets_flat = targets.contiguous().view(-1)\n",
    "        loss = criterion(logits_flat, targets_flat)\n",
    "\n",
    "        if enc_opt: enc_opt.zero_grad()\n",
    "        dec_opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(dec.parameters(), 5.0)\n",
    "        if enc_opt: nn.utils.clip_grad_norm_(enc.parameters(), 5.0)\n",
    "\n",
    "        if enc_opt: enc_opt.step()\n",
    "        dec_opt.step()\n",
    "\n",
    "        # compute token-level accuracy ignoring <pad>\n",
    "        pred_tokens = logits.argmax(dim=2)  # (B, L)\n",
    "        mask = targets != 0  # ignore <pad>\n",
    "        correct = (pred_tokens == targets) & mask\n",
    "        correct_tokens += correct.sum().item()\n",
    "        total_tokens += mask.sum().item()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        n_batches += 1\n",
    "\n",
    "    return total_loss / max(1, n_batches), 100*correct_tokens/total_tokens\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(enc, dec, loader, criterion, device, vocab=None, print_every=PRINT_EVERY):\n",
    "    enc.eval()\n",
    "    dec.eval()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    correct_tokens = 0\n",
    "    n_batches = 0\n",
    "    pad_idx = vocab.stoi['<pad>'] if vocab else 0\n",
    "\n",
    "    for batch_idx, (images, caps, _) in enumerate(loader, 1):\n",
    "        images, caps = images.to(device), caps.to(device)\n",
    "        feats = enc(images)\n",
    "\n",
    "        # Always slice teacher-forcing input\n",
    "        logits = dec(feats, caps[:, :-1])\n",
    "        targets = caps[:, 1:]\n",
    "\n",
    "        loss = criterion(logits.reshape(-1, logits.size(-1)), targets.reshape(-1))\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if vocab is not None:\n",
    "            pred_tokens = logits.argmax(dim=2)\n",
    "            mask = targets != pad_idx\n",
    "            correct_tokens += ((pred_tokens == targets) & mask).sum().item()\n",
    "            total_tokens += mask.sum().item()\n",
    "        n_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / max(1, n_batches)\n",
    "    avg_acc = 100*correct_tokens/total_tokens if total_tokens > 0 else None\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_caption(enc, dec, img_path, transform, vocab, device, max_len=30):\n",
    "    enc.eval(); dec.eval()\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    feats = enc(x)  # (1, E)\n",
    "    start_id = vocab.stoi.get('<start>', None)\n",
    "    # pass start_id for transformer decoder; RNN ignores it\n",
    "    gen = dec.sample(feats, start_id=start_id, max_len=max_len)  # (1, max_len)\n",
    "    gen = gen[0].cpu().tolist()\n",
    "    words=[]\n",
    "    for idx in gen:\n",
    "        if idx < len(vocab.itos):\n",
    "            tok = vocab.itos[idx]\n",
    "        else:\n",
    "            tok = '<unk>'\n",
    "        if tok == '<end>': break\n",
    "        if tok not in ('<pad>','<start>'):\n",
    "            words.append(tok)\n",
    "    return ' '.join(words)"
   ],
   "id": "1033064fef890217",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fit and plot model functions:",
   "id": "846fe48b7a6b84f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T10:04:11.371557Z",
     "start_time": "2025-10-21T10:04:11.350981Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_training_history(history):\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    # --------------- Plot loss: ---------------\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(epochs, history['train_loss'], label='Train Loss', marker='o')\n",
    "    plt.plot(epochs, history['val_loss'], label='Val Loss', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # --------------- Plot accuracy: ---------------\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(epochs, history['train_acc'], label='Train Accuracy', marker='o')\n",
    "    plt.plot(epochs, history['val_acc'], label='Val Accuracy', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "CEL = nn.CrossEntropyLoss(ignore_index=vocab.stoi['<pad>'])\n",
    "\n",
    "def fit_model(\n",
    "    enc, dec,\n",
    "    train_loader, val_loader,\n",
    "    enc_opt, dec_opt,\n",
    "    device,\n",
    "    vocab,\n",
    "    output_dir,\n",
    "    num_epochs,\n",
    "    criterion=CEL,\n",
    "    print_every=PRINT_EVERY,\n",
    "    train_encoder_only=False\n",
    "):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    enc.to(device)\n",
    "    dec.to(device)\n",
    "\n",
    "    # Freeze decoder\n",
    "    if train_encoder_only:\n",
    "        for p in dec.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    best_val = float('inf')\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    pad_idx = vocab.stoi['<pad>'] if vocab else 0\n",
    "\n",
    "    def compute_accuracy(logits, targets):\n",
    "        preds = logits.argmax(dim=-1)\n",
    "        mask = targets != pad_idx\n",
    "        correct = (preds == targets) & mask\n",
    "        total = mask.sum().item()\n",
    "        return correct.sum().item() / total if total > 0 else 0.0\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        enc.train(); dec.train()\n",
    "\n",
    "        # --------------- Train: ---------------\n",
    "\n",
    "        train_loss_accum, train_acc_accum, steps = 0.0, 0.0, 0\n",
    "        for batch_idx, (images, caps, _) in enumerate(train_loader, 1):\n",
    "            images, caps = images.to(device), caps.to(device)\n",
    "            features = enc(images)\n",
    "            logits = dec(features, caps[:, :-1])\n",
    "            loss = criterion(logits.reshape(-1, logits.size(-1)), caps[:, 1:].reshape(-1))\n",
    "\n",
    "            if enc_opt: enc_opt.zero_grad()\n",
    "            if not train_encoder_only and dec_opt: dec_opt.zero_grad()  # only if decoder is trainable\n",
    "            loss.backward()\n",
    "\n",
    "            # Gradient clipping\n",
    "            if enc_opt: torch.nn.utils.clip_grad_norm_(enc.parameters(), 5.0)\n",
    "            if not train_encoder_only and dec_opt: torch.nn.utils.clip_grad_norm_(dec.parameters(), 5.0)\n",
    "\n",
    "            if enc_opt: enc_opt.step()\n",
    "            if not train_encoder_only and dec_opt: dec_opt.step()\n",
    "\n",
    "            train_loss_accum += loss.item()\n",
    "            train_acc_accum += compute_accuracy(logits, caps[:, 1:])\n",
    "            steps += 1\n",
    "            if batch_idx % print_every == 0 or batch_idx == len(train_loader):\n",
    "                print(f\"Epoch {epoch} Train batch {batch_idx}/{len(train_loader)} \"\n",
    "                      f\"Loss={train_loss_accum/steps:.4f} Acc={100*train_acc_accum/steps:.2f}%\")\n",
    "\n",
    "        train_loss = train_loss_accum / steps\n",
    "        train_acc = 100 * train_acc_accum / steps\n",
    "\n",
    "        # --------------- Validate: ---------------\n",
    "\n",
    "        enc.eval(); dec.eval()\n",
    "        val_loss_accum, val_acc_accum, steps = 0.0, 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images, caps, _) in enumerate(val_loader, 1):\n",
    "                images, caps = images.to(device), caps.to(device)\n",
    "                features = enc(images)\n",
    "                logits = dec(features, caps[:, :-1])\n",
    "                loss = criterion(logits.reshape(-1, logits.size(-1)), caps[:, 1:].reshape(-1))\n",
    "\n",
    "                val_loss_accum += loss.item()\n",
    "                pred_tokens = logits.argmax(dim=2)\n",
    "                mask = caps[:, 1:] != pad_idx\n",
    "                correct = (pred_tokens == caps[:, 1:]) & mask\n",
    "                val_acc_accum += correct.sum().item() / mask.sum().item()\n",
    "                steps += 1\n",
    "\n",
    "        val_loss = val_loss_accum / steps\n",
    "        val_acc = 100 * val_acc_accum / steps\n",
    "\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{num_epochs} train_loss={train_loss:.4f} train_acc={train_acc:.2f}% \"\n",
    "              f\"val_loss={val_loss:.4f} val_acc={val_acc:.2f}%\")\n",
    "\n",
    "        # --------------- Save checkpoint: ---------------\n",
    "\n",
    "        ckpt = {\n",
    "            'epoch': epoch,\n",
    "            'encoder_state_dict': enc.state_dict(),\n",
    "            'decoder_state_dict': dec.state_dict(),\n",
    "            'vocab': getattr(vocab, 'itos', vocab),\n",
    "            'history': history,\n",
    "            'enc_optimizer_state_dict': enc_opt.state_dict() if enc_opt else None,\n",
    "            'dec_optimizer_state_dict': dec_opt.state_dict() if dec_opt else None,\n",
    "        }\n",
    "        torch.save(ckpt, os.path.join(output_dir, f\"ckpt_epoch_{epoch}.pth\"))\n",
    "        if val_loss < best_val:\n",
    "            best_val = val_loss\n",
    "            torch.save(ckpt, os.path.join(output_dir, \"best.pth\"))\n",
    "\n",
    "    plot_training_history(history)\n",
    "    return history"
   ],
   "id": "35c183f0c3620a27",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decoder base class:",
   "id": "a8a625cdfdeeb08f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T10:04:16.134503Z",
     "start_time": "2025-10-21T10:04:16.126569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DecoderBase(nn.Module):\n",
    "    def forward(self, features, captions):\n",
    "        raise NotImplementedError\n",
    "    def sample(self, features, start_id=None, max_len=30):\n",
    "        raise NotImplementedError"
   ],
   "id": "5c3e4c2346443dac",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model 1: CNN-RNN",
   "id": "3c2c59171b681b76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Simple CNN->RNN image caption baseline model.\n",
    "\n",
    "Encoder: CNN with transfer learning from ResNet18.\n",
    "\n",
    "Decoder: Text RNN, no transfer learning."
   ],
   "id": "6e0057fff467073f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T00:47:55.882154Z",
     "start_time": "2025-10-20T23:46:51.959067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------- Encoder: ---------------\n",
    "\n",
    "class CNNEncoder(nn.Module):\n",
    "    def __init__(self, embed_size, fine_tune=False):\n",
    "        super().__init__()\n",
    "        resnet = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        modules = list(resnet.children())[:-1]  # remove fc\n",
    "        self.backbone = nn.Sequential(*modules)\n",
    "        self.fc = nn.Linear(512, embed_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fine_tune(fine_tune)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)               # (B, 512, 1, 1)\n",
    "        feat = feat.view(feat.size(0), -1)    # (B, 512)\n",
    "        feat = self.fc(feat)                  # (B, embed)\n",
    "        feat = self.relu(feat)\n",
    "        return feat\n",
    "\n",
    "    def fine_tune(self, fine):\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = fine\n",
    "\n",
    "# --------------- Decoder: ---------------\n",
    "\n",
    "class RNNDecoder(DecoderBase):\n",
    "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        self.init_h = nn.Linear(embed_size, hidden_size)\n",
    "        self.init_c = nn.Linear(embed_size, hidden_size)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        embeddings = self.dropout(self.embed(captions))\n",
    "        h0 = self.init_h(features).unsqueeze(0)\n",
    "        c0 = self.init_c(features).unsqueeze(0)\n",
    "        outputs, _ = self.lstm(embeddings, (h0, c0))\n",
    "        outputs = self.dropout(outputs)\n",
    "        logits = self.linear(outputs)\n",
    "        return logits\n",
    "\n",
    "# --------------- Training: ---------------\n",
    "\n",
    "clear_cache()\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "ENC_LR = 1e-3\n",
    "DEC_LR = 1e-3\n",
    "FINE_TUNE = False\n",
    "\n",
    "DROPOUT = 0.3\n",
    "EMBED_SIZE = 512\n",
    "HIDDEN_SIZE = 1024\n",
    "\n",
    "OUTPUT_DIR = \"./models_cnn_rnn\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "# Instantiate models\n",
    "enc = CNNEncoder(\n",
    "    embed_size=EMBED_SIZE,\n",
    "    fine_tune=FINE_TUNE\n",
    ")\n",
    "dec = RNNDecoder(\n",
    "    embed_size=EMBED_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    vocab_size=len(vocab),\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "# Optimizers and loss\n",
    "enc_opt = optim.Adam(enc.parameters(), lr=ENC_LR) if FINE_TUNE else None\n",
    "dec_opt = optim.Adam(dec.parameters(), lr=DEC_LR)\n",
    "\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "\n",
    "# Train\n",
    "history = fit_model(\n",
    "    enc=enc, dec=dec,\n",
    "    train_loader=train_loader, val_loader=val_loader,\n",
    "    enc_opt=enc_opt, dec_opt=dec_opt,\n",
    "    device=DEVICE,\n",
    "    vocab=vocab,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_epochs=NUM_EPOCHS\n",
    ")"
   ],
   "id": "4a815cba02749e22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 6989\n",
      "Epoch 1 Train batch 10/1939 Loss=7.0176 Acc=12.15%\n",
      "Epoch 1 Train batch 20/1939 Loss=6.2733 Acc=14.30%\n",
      "Epoch 1 Train batch 30/1939 Loss=5.8936 Acc=16.75%\n",
      "Epoch 1 Train batch 40/1939 Loss=5.6474 Acc=18.44%\n",
      "Epoch 1 Train batch 50/1939 Loss=5.4779 Acc=19.68%\n",
      "Epoch 1 Train batch 60/1939 Loss=5.3441 Acc=20.53%\n",
      "Epoch 1 Train batch 70/1939 Loss=5.2288 Acc=21.35%\n",
      "Epoch 1 Train batch 80/1939 Loss=5.1415 Acc=22.05%\n",
      "Epoch 1 Train batch 90/1939 Loss=5.0624 Acc=22.57%\n",
      "Epoch 1 Train batch 100/1939 Loss=4.9965 Acc=23.03%\n",
      "Epoch 1 Train batch 110/1939 Loss=4.9341 Acc=23.45%\n",
      "Epoch 1 Train batch 120/1939 Loss=4.8803 Acc=23.84%\n",
      "Epoch 1 Train batch 130/1939 Loss=4.8406 Acc=24.10%\n",
      "Epoch 1 Train batch 140/1939 Loss=4.7950 Acc=24.40%\n",
      "Epoch 1 Train batch 150/1939 Loss=4.7592 Acc=24.66%\n",
      "Epoch 1 Train batch 160/1939 Loss=4.7244 Acc=24.89%\n",
      "Epoch 1 Train batch 170/1939 Loss=4.6899 Acc=25.17%\n",
      "Epoch 1 Train batch 180/1939 Loss=4.6646 Acc=25.40%\n",
      "Epoch 1 Train batch 190/1939 Loss=4.6373 Acc=25.61%\n",
      "Epoch 1 Train batch 200/1939 Loss=4.6130 Acc=25.78%\n",
      "Epoch 1 Train batch 210/1939 Loss=4.5903 Acc=25.92%\n",
      "Epoch 1 Train batch 220/1939 Loss=4.5694 Acc=26.07%\n",
      "Epoch 1 Train batch 230/1939 Loss=4.5468 Acc=26.26%\n",
      "Epoch 1 Train batch 240/1939 Loss=4.5257 Acc=26.40%\n",
      "Epoch 1 Train batch 250/1939 Loss=4.5038 Acc=26.56%\n",
      "Epoch 1 Train batch 260/1939 Loss=4.4863 Acc=26.70%\n",
      "Epoch 1 Train batch 270/1939 Loss=4.4673 Acc=26.86%\n",
      "Epoch 1 Train batch 280/1939 Loss=4.4512 Acc=26.99%\n",
      "Epoch 1 Train batch 290/1939 Loss=4.4320 Acc=27.15%\n",
      "Epoch 1 Train batch 300/1939 Loss=4.4149 Acc=27.28%\n",
      "Epoch 1 Train batch 310/1939 Loss=4.4015 Acc=27.37%\n",
      "Epoch 1 Train batch 320/1939 Loss=4.3886 Acc=27.47%\n",
      "Epoch 1 Train batch 330/1939 Loss=4.3744 Acc=27.58%\n",
      "Epoch 1 Train batch 340/1939 Loss=4.3615 Acc=27.65%\n",
      "Epoch 1 Train batch 350/1939 Loss=4.3469 Acc=27.77%\n",
      "Epoch 1 Train batch 360/1939 Loss=4.3332 Acc=27.89%\n",
      "Epoch 1 Train batch 370/1939 Loss=4.3199 Acc=27.99%\n",
      "Epoch 1 Train batch 380/1939 Loss=4.3070 Acc=28.10%\n",
      "Epoch 1 Train batch 390/1939 Loss=4.2954 Acc=28.19%\n",
      "Epoch 1 Train batch 400/1939 Loss=4.2837 Acc=28.28%\n",
      "Epoch 1 Train batch 410/1939 Loss=4.2725 Acc=28.36%\n",
      "Epoch 1 Train batch 420/1939 Loss=4.2609 Acc=28.46%\n",
      "Epoch 1 Train batch 430/1939 Loss=4.2511 Acc=28.53%\n",
      "Epoch 1 Train batch 440/1939 Loss=4.2416 Acc=28.60%\n",
      "Epoch 1 Train batch 450/1939 Loss=4.2318 Acc=28.67%\n",
      "Epoch 1 Train batch 460/1939 Loss=4.2224 Acc=28.74%\n",
      "Epoch 1 Train batch 470/1939 Loss=4.2105 Acc=28.86%\n",
      "Epoch 1 Train batch 480/1939 Loss=4.2007 Acc=28.93%\n",
      "Epoch 1 Train batch 490/1939 Loss=4.1910 Acc=29.00%\n",
      "Epoch 1 Train batch 500/1939 Loss=4.1812 Acc=29.09%\n",
      "Epoch 1 Train batch 510/1939 Loss=4.1713 Acc=29.17%\n",
      "Epoch 1 Train batch 520/1939 Loss=4.1627 Acc=29.24%\n",
      "Epoch 1 Train batch 530/1939 Loss=4.1540 Acc=29.31%\n",
      "Epoch 1 Train batch 540/1939 Loss=4.1472 Acc=29.36%\n",
      "Epoch 1 Train batch 550/1939 Loss=4.1388 Acc=29.41%\n",
      "Epoch 1 Train batch 560/1939 Loss=4.1304 Acc=29.48%\n",
      "Epoch 1 Train batch 570/1939 Loss=4.1234 Acc=29.53%\n",
      "Epoch 1 Train batch 580/1939 Loss=4.1158 Acc=29.58%\n",
      "Epoch 1 Train batch 590/1939 Loss=4.1091 Acc=29.64%\n",
      "Epoch 1 Train batch 600/1939 Loss=4.1022 Acc=29.69%\n",
      "Epoch 1 Train batch 610/1939 Loss=4.0952 Acc=29.74%\n",
      "Epoch 1 Train batch 620/1939 Loss=4.0875 Acc=29.79%\n",
      "Epoch 1 Train batch 630/1939 Loss=4.0806 Acc=29.84%\n",
      "Epoch 1 Train batch 640/1939 Loss=4.0730 Acc=29.90%\n",
      "Epoch 1 Train batch 650/1939 Loss=4.0662 Acc=29.96%\n",
      "Epoch 1 Train batch 660/1939 Loss=4.0604 Acc=30.00%\n",
      "Epoch 1 Train batch 670/1939 Loss=4.0539 Acc=30.05%\n",
      "Epoch 1 Train batch 680/1939 Loss=4.0476 Acc=30.09%\n",
      "Epoch 1 Train batch 690/1939 Loss=4.0413 Acc=30.14%\n",
      "Epoch 1 Train batch 700/1939 Loss=4.0359 Acc=30.19%\n",
      "Epoch 1 Train batch 710/1939 Loss=4.0298 Acc=30.24%\n",
      "Epoch 1 Train batch 720/1939 Loss=4.0234 Acc=30.29%\n",
      "Epoch 1 Train batch 730/1939 Loss=4.0183 Acc=30.34%\n",
      "Epoch 1 Train batch 740/1939 Loss=4.0136 Acc=30.37%\n",
      "Epoch 1 Train batch 750/1939 Loss=4.0085 Acc=30.40%\n",
      "Epoch 1 Train batch 760/1939 Loss=4.0025 Acc=30.44%\n",
      "Epoch 1 Train batch 770/1939 Loss=3.9972 Acc=30.49%\n",
      "Epoch 1 Train batch 780/1939 Loss=3.9927 Acc=30.52%\n",
      "Epoch 1 Train batch 790/1939 Loss=3.9878 Acc=30.56%\n",
      "Epoch 1 Train batch 800/1939 Loss=3.9832 Acc=30.60%\n",
      "Epoch 1 Train batch 810/1939 Loss=3.9786 Acc=30.63%\n",
      "Epoch 1 Train batch 820/1939 Loss=3.9737 Acc=30.68%\n",
      "Epoch 1 Train batch 830/1939 Loss=3.9689 Acc=30.71%\n",
      "Epoch 1 Train batch 840/1939 Loss=3.9634 Acc=30.76%\n",
      "Epoch 1 Train batch 850/1939 Loss=3.9584 Acc=30.80%\n",
      "Epoch 1 Train batch 860/1939 Loss=3.9528 Acc=30.85%\n",
      "Epoch 1 Train batch 870/1939 Loss=3.9483 Acc=30.88%\n",
      "Epoch 1 Train batch 880/1939 Loss=3.9442 Acc=30.91%\n",
      "Epoch 1 Train batch 890/1939 Loss=3.9404 Acc=30.93%\n",
      "Epoch 1 Train batch 900/1939 Loss=3.9358 Acc=30.97%\n",
      "Epoch 1 Train batch 910/1939 Loss=3.9314 Acc=31.01%\n",
      "Epoch 1 Train batch 920/1939 Loss=3.9271 Acc=31.04%\n",
      "Epoch 1 Train batch 930/1939 Loss=3.9223 Acc=31.08%\n",
      "Epoch 1 Train batch 940/1939 Loss=3.9184 Acc=31.11%\n",
      "Epoch 1 Train batch 950/1939 Loss=3.9144 Acc=31.14%\n",
      "Epoch 1 Train batch 960/1939 Loss=3.9097 Acc=31.17%\n",
      "Epoch 1 Train batch 970/1939 Loss=3.9067 Acc=31.20%\n",
      "Epoch 1 Train batch 980/1939 Loss=3.9031 Acc=31.23%\n",
      "Epoch 1 Train batch 990/1939 Loss=3.8993 Acc=31.25%\n",
      "Epoch 1 Train batch 1000/1939 Loss=3.8951 Acc=31.28%\n",
      "Epoch 1 Train batch 1010/1939 Loss=3.8914 Acc=31.31%\n",
      "Epoch 1 Train batch 1020/1939 Loss=3.8876 Acc=31.33%\n",
      "Epoch 1 Train batch 1030/1939 Loss=3.8837 Acc=31.36%\n",
      "Epoch 1 Train batch 1040/1939 Loss=3.8802 Acc=31.39%\n",
      "Epoch 1 Train batch 1050/1939 Loss=3.8759 Acc=31.43%\n",
      "Epoch 1 Train batch 1060/1939 Loss=3.8726 Acc=31.45%\n",
      "Epoch 1 Train batch 1070/1939 Loss=3.8686 Acc=31.48%\n",
      "Epoch 1 Train batch 1080/1939 Loss=3.8650 Acc=31.51%\n",
      "Epoch 1 Train batch 1090/1939 Loss=3.8612 Acc=31.54%\n",
      "Epoch 1 Train batch 1100/1939 Loss=3.8575 Acc=31.57%\n",
      "Epoch 1 Train batch 1110/1939 Loss=3.8540 Acc=31.60%\n",
      "Epoch 1 Train batch 1120/1939 Loss=3.8502 Acc=31.63%\n",
      "Epoch 1 Train batch 1130/1939 Loss=3.8468 Acc=31.66%\n",
      "Epoch 1 Train batch 1140/1939 Loss=3.8438 Acc=31.68%\n",
      "Epoch 1 Train batch 1150/1939 Loss=3.8400 Acc=31.71%\n",
      "Epoch 1 Train batch 1160/1939 Loss=3.8365 Acc=31.75%\n",
      "Epoch 1 Train batch 1170/1939 Loss=3.8332 Acc=31.77%\n",
      "Epoch 1 Train batch 1180/1939 Loss=3.8299 Acc=31.80%\n",
      "Epoch 1 Train batch 1190/1939 Loss=3.8271 Acc=31.81%\n",
      "Epoch 1 Train batch 1200/1939 Loss=3.8237 Acc=31.84%\n",
      "Epoch 1 Train batch 1210/1939 Loss=3.8210 Acc=31.86%\n",
      "Epoch 1 Train batch 1220/1939 Loss=3.8175 Acc=31.90%\n",
      "Epoch 1 Train batch 1230/1939 Loss=3.8146 Acc=31.92%\n",
      "Epoch 1 Train batch 1240/1939 Loss=3.8117 Acc=31.94%\n",
      "Epoch 1 Train batch 1250/1939 Loss=3.8094 Acc=31.96%\n",
      "Epoch 1 Train batch 1260/1939 Loss=3.8069 Acc=31.98%\n",
      "Epoch 1 Train batch 1270/1939 Loss=3.8035 Acc=32.00%\n",
      "Epoch 1 Train batch 1280/1939 Loss=3.8006 Acc=32.03%\n",
      "Epoch 1 Train batch 1290/1939 Loss=3.7977 Acc=32.05%\n",
      "Epoch 1 Train batch 1300/1939 Loss=3.7951 Acc=32.07%\n",
      "Epoch 1 Train batch 1310/1939 Loss=3.7917 Acc=32.10%\n",
      "Epoch 1 Train batch 1320/1939 Loss=3.7891 Acc=32.12%\n",
      "Epoch 1 Train batch 1330/1939 Loss=3.7857 Acc=32.15%\n",
      "Epoch 1 Train batch 1340/1939 Loss=3.7826 Acc=32.17%\n",
      "Epoch 1 Train batch 1350/1939 Loss=3.7798 Acc=32.19%\n",
      "Epoch 1 Train batch 1360/1939 Loss=3.7774 Acc=32.21%\n",
      "Epoch 1 Train batch 1370/1939 Loss=3.7745 Acc=32.23%\n",
      "Epoch 1 Train batch 1380/1939 Loss=3.7715 Acc=32.26%\n",
      "Epoch 1 Train batch 1390/1939 Loss=3.7689 Acc=32.28%\n",
      "Epoch 1 Train batch 1400/1939 Loss=3.7659 Acc=32.31%\n",
      "Epoch 1 Train batch 1410/1939 Loss=3.7635 Acc=32.33%\n",
      "Epoch 1 Train batch 1420/1939 Loss=3.7604 Acc=32.35%\n",
      "Epoch 1 Train batch 1430/1939 Loss=3.7573 Acc=32.38%\n",
      "Epoch 1 Train batch 1440/1939 Loss=3.7546 Acc=32.40%\n",
      "Epoch 1 Train batch 1450/1939 Loss=3.7521 Acc=32.42%\n",
      "Epoch 1 Train batch 1460/1939 Loss=3.7501 Acc=32.43%\n",
      "Epoch 1 Train batch 1470/1939 Loss=3.7477 Acc=32.45%\n",
      "Epoch 1 Train batch 1480/1939 Loss=3.7452 Acc=32.47%\n",
      "Epoch 1 Train batch 1490/1939 Loss=3.7429 Acc=32.49%\n",
      "Epoch 1 Train batch 1500/1939 Loss=3.7406 Acc=32.51%\n",
      "Epoch 1 Train batch 1510/1939 Loss=3.7381 Acc=32.53%\n",
      "Epoch 1 Train batch 1520/1939 Loss=3.7356 Acc=32.55%\n",
      "Epoch 1 Train batch 1530/1939 Loss=3.7333 Acc=32.57%\n",
      "Epoch 1 Train batch 1540/1939 Loss=3.7310 Acc=32.58%\n",
      "Epoch 1 Train batch 1550/1939 Loss=3.7288 Acc=32.60%\n",
      "Epoch 1 Train batch 1560/1939 Loss=3.7261 Acc=32.62%\n",
      "Epoch 1 Train batch 1570/1939 Loss=3.7236 Acc=32.64%\n",
      "Epoch 1 Train batch 1580/1939 Loss=3.7215 Acc=32.66%\n",
      "Epoch 1 Train batch 1590/1939 Loss=3.7191 Acc=32.68%\n",
      "Epoch 1 Train batch 1600/1939 Loss=3.7172 Acc=32.69%\n",
      "Epoch 1 Train batch 1610/1939 Loss=3.7148 Acc=32.71%\n",
      "Epoch 1 Train batch 1620/1939 Loss=3.7125 Acc=32.73%\n",
      "Epoch 1 Train batch 1630/1939 Loss=3.7102 Acc=32.75%\n",
      "Epoch 1 Train batch 1640/1939 Loss=3.7079 Acc=32.76%\n",
      "Epoch 1 Train batch 1650/1939 Loss=3.7058 Acc=32.78%\n",
      "Epoch 1 Train batch 1660/1939 Loss=3.7035 Acc=32.80%\n",
      "Epoch 1 Train batch 1670/1939 Loss=3.7013 Acc=32.82%\n",
      "Epoch 1 Train batch 1680/1939 Loss=3.6992 Acc=32.84%\n",
      "Epoch 1 Train batch 1690/1939 Loss=3.6965 Acc=32.86%\n",
      "Epoch 1 Train batch 1700/1939 Loss=3.6946 Acc=32.88%\n",
      "Epoch 1 Train batch 1710/1939 Loss=3.6925 Acc=32.90%\n",
      "Epoch 1 Train batch 1720/1939 Loss=3.6904 Acc=32.91%\n",
      "Epoch 1 Train batch 1730/1939 Loss=3.6885 Acc=32.93%\n",
      "Epoch 1 Train batch 1740/1939 Loss=3.6865 Acc=32.95%\n",
      "Epoch 1 Train batch 1750/1939 Loss=3.6842 Acc=32.96%\n",
      "Epoch 1 Train batch 1760/1939 Loss=3.6827 Acc=32.98%\n",
      "Epoch 1 Train batch 1770/1939 Loss=3.6808 Acc=32.99%\n",
      "Epoch 1 Train batch 1780/1939 Loss=3.6788 Acc=33.01%\n",
      "Epoch 1 Train batch 1790/1939 Loss=3.6768 Acc=33.02%\n",
      "Epoch 1 Train batch 1800/1939 Loss=3.6749 Acc=33.04%\n",
      "Epoch 1 Train batch 1810/1939 Loss=3.6727 Acc=33.05%\n",
      "Epoch 1 Train batch 1820/1939 Loss=3.6712 Acc=33.07%\n",
      "Epoch 1 Train batch 1830/1939 Loss=3.6693 Acc=33.09%\n",
      "Epoch 1 Train batch 1840/1939 Loss=3.6674 Acc=33.10%\n",
      "Epoch 1 Train batch 1850/1939 Loss=3.6652 Acc=33.12%\n",
      "Epoch 1 Train batch 1860/1939 Loss=3.6634 Acc=33.13%\n",
      "Epoch 1 Train batch 1870/1939 Loss=3.6619 Acc=33.15%\n",
      "Epoch 1 Train batch 1880/1939 Loss=3.6600 Acc=33.16%\n",
      "Epoch 1 Train batch 1890/1939 Loss=3.6581 Acc=33.18%\n",
      "Epoch 1 Train batch 1900/1939 Loss=3.6563 Acc=33.19%\n",
      "Epoch 1 Train batch 1910/1939 Loss=3.6548 Acc=33.20%\n",
      "Epoch 1 Train batch 1920/1939 Loss=3.6530 Acc=33.22%\n",
      "Epoch 1 Train batch 1930/1939 Loss=3.6510 Acc=33.23%\n",
      "Epoch 1 Train batch 1939/1939 Loss=3.6498 Acc=33.24%\n",
      "Epoch 1/5 train_loss=3.6498 train_acc=33.24% val_loss=3.1970 val_acc=37.32%\n",
      "Epoch 2 Train batch 10/1939 Loss=3.1188 Acc=36.98%\n",
      "Epoch 2 Train batch 20/1939 Loss=3.1676 Acc=36.57%\n",
      "Epoch 2 Train batch 30/1939 Loss=3.1362 Acc=36.90%\n",
      "Epoch 2 Train batch 40/1939 Loss=3.1588 Acc=36.71%\n",
      "Epoch 2 Train batch 50/1939 Loss=3.1594 Acc=36.74%\n",
      "Epoch 2 Train batch 60/1939 Loss=3.1614 Acc=36.71%\n",
      "Epoch 2 Train batch 70/1939 Loss=3.1568 Acc=36.84%\n",
      "Epoch 2 Train batch 80/1939 Loss=3.1626 Acc=36.72%\n",
      "Epoch 2 Train batch 90/1939 Loss=3.1636 Acc=36.80%\n",
      "Epoch 2 Train batch 100/1939 Loss=3.1655 Acc=36.74%\n",
      "Epoch 2 Train batch 110/1939 Loss=3.1680 Acc=36.77%\n",
      "Epoch 2 Train batch 120/1939 Loss=3.1663 Acc=36.79%\n",
      "Epoch 2 Train batch 130/1939 Loss=3.1673 Acc=36.76%\n",
      "Epoch 2 Train batch 140/1939 Loss=3.1626 Acc=36.83%\n",
      "Epoch 2 Train batch 150/1939 Loss=3.1656 Acc=36.82%\n",
      "Epoch 2 Train batch 160/1939 Loss=3.1674 Acc=36.78%\n",
      "Epoch 2 Train batch 170/1939 Loss=3.1671 Acc=36.77%\n",
      "Epoch 2 Train batch 180/1939 Loss=3.1658 Acc=36.77%\n",
      "Epoch 2 Train batch 190/1939 Loss=3.1642 Acc=36.82%\n",
      "Epoch 2 Train batch 200/1939 Loss=3.1648 Acc=36.83%\n",
      "Epoch 2 Train batch 210/1939 Loss=3.1688 Acc=36.76%\n",
      "Epoch 2 Train batch 220/1939 Loss=3.1731 Acc=36.76%\n",
      "Epoch 2 Train batch 230/1939 Loss=3.1712 Acc=36.78%\n",
      "Epoch 2 Train batch 240/1939 Loss=3.1715 Acc=36.76%\n",
      "Epoch 2 Train batch 250/1939 Loss=3.1710 Acc=36.75%\n",
      "Epoch 2 Train batch 260/1939 Loss=3.1726 Acc=36.71%\n",
      "Epoch 2 Train batch 270/1939 Loss=3.1715 Acc=36.72%\n",
      "Epoch 2 Train batch 280/1939 Loss=3.1727 Acc=36.71%\n",
      "Epoch 2 Train batch 290/1939 Loss=3.1707 Acc=36.70%\n",
      "Epoch 2 Train batch 300/1939 Loss=3.1698 Acc=36.72%\n",
      "Epoch 2 Train batch 310/1939 Loss=3.1695 Acc=36.74%\n",
      "Epoch 2 Train batch 320/1939 Loss=3.1681 Acc=36.76%\n",
      "Epoch 2 Train batch 330/1939 Loss=3.1690 Acc=36.73%\n",
      "Epoch 2 Train batch 340/1939 Loss=3.1677 Acc=36.73%\n",
      "Epoch 2 Train batch 350/1939 Loss=3.1684 Acc=36.70%\n",
      "Epoch 2 Train batch 360/1939 Loss=3.1691 Acc=36.70%\n",
      "Epoch 2 Train batch 370/1939 Loss=3.1698 Acc=36.68%\n",
      "Epoch 2 Train batch 380/1939 Loss=3.1696 Acc=36.67%\n",
      "Epoch 2 Train batch 390/1939 Loss=3.1690 Acc=36.68%\n",
      "Epoch 2 Train batch 400/1939 Loss=3.1700 Acc=36.67%\n",
      "Epoch 2 Train batch 410/1939 Loss=3.1699 Acc=36.68%\n",
      "Epoch 2 Train batch 420/1939 Loss=3.1688 Acc=36.69%\n",
      "Epoch 2 Train batch 430/1939 Loss=3.1676 Acc=36.70%\n",
      "Epoch 2 Train batch 440/1939 Loss=3.1678 Acc=36.70%\n",
      "Epoch 2 Train batch 450/1939 Loss=3.1663 Acc=36.74%\n",
      "Epoch 2 Train batch 460/1939 Loss=3.1662 Acc=36.75%\n",
      "Epoch 2 Train batch 470/1939 Loss=3.1670 Acc=36.73%\n",
      "Epoch 2 Train batch 480/1939 Loss=3.1661 Acc=36.76%\n",
      "Epoch 2 Train batch 490/1939 Loss=3.1659 Acc=36.76%\n",
      "Epoch 2 Train batch 500/1939 Loss=3.1635 Acc=36.77%\n",
      "Epoch 2 Train batch 510/1939 Loss=3.1630 Acc=36.78%\n",
      "Epoch 2 Train batch 520/1939 Loss=3.1624 Acc=36.77%\n",
      "Epoch 2 Train batch 530/1939 Loss=3.1622 Acc=36.78%\n",
      "Epoch 2 Train batch 540/1939 Loss=3.1628 Acc=36.78%\n",
      "Epoch 2 Train batch 550/1939 Loss=3.1623 Acc=36.78%\n",
      "Epoch 2 Train batch 560/1939 Loss=3.1619 Acc=36.79%\n",
      "Epoch 2 Train batch 570/1939 Loss=3.1619 Acc=36.79%\n",
      "Epoch 2 Train batch 580/1939 Loss=3.1615 Acc=36.79%\n",
      "Epoch 2 Train batch 590/1939 Loss=3.1613 Acc=36.79%\n",
      "Epoch 2 Train batch 600/1939 Loss=3.1609 Acc=36.80%\n",
      "Epoch 2 Train batch 610/1939 Loss=3.1607 Acc=36.80%\n",
      "Epoch 2 Train batch 620/1939 Loss=3.1600 Acc=36.80%\n",
      "Epoch 2 Train batch 630/1939 Loss=3.1608 Acc=36.79%\n",
      "Epoch 2 Train batch 640/1939 Loss=3.1598 Acc=36.80%\n",
      "Epoch 2 Train batch 650/1939 Loss=3.1596 Acc=36.79%\n",
      "Epoch 2 Train batch 660/1939 Loss=3.1597 Acc=36.79%\n",
      "Epoch 2 Train batch 670/1939 Loss=3.1599 Acc=36.79%\n",
      "Epoch 2 Train batch 680/1939 Loss=3.1595 Acc=36.80%\n",
      "Epoch 2 Train batch 690/1939 Loss=3.1592 Acc=36.81%\n",
      "Epoch 2 Train batch 700/1939 Loss=3.1582 Acc=36.81%\n",
      "Epoch 2 Train batch 710/1939 Loss=3.1581 Acc=36.82%\n",
      "Epoch 2 Train batch 720/1939 Loss=3.1573 Acc=36.84%\n",
      "Epoch 2 Train batch 730/1939 Loss=3.1576 Acc=36.84%\n",
      "Epoch 2 Train batch 740/1939 Loss=3.1578 Acc=36.84%\n",
      "Epoch 2 Train batch 750/1939 Loss=3.1580 Acc=36.84%\n",
      "Epoch 2 Train batch 760/1939 Loss=3.1580 Acc=36.85%\n",
      "Epoch 2 Train batch 770/1939 Loss=3.1571 Acc=36.86%\n",
      "Epoch 2 Train batch 780/1939 Loss=3.1568 Acc=36.87%\n",
      "Epoch 2 Train batch 790/1939 Loss=3.1570 Acc=36.87%\n",
      "Epoch 2 Train batch 800/1939 Loss=3.1572 Acc=36.86%\n",
      "Epoch 2 Train batch 810/1939 Loss=3.1578 Acc=36.85%\n",
      "Epoch 2 Train batch 820/1939 Loss=3.1583 Acc=36.85%\n",
      "Epoch 2 Train batch 830/1939 Loss=3.1581 Acc=36.85%\n",
      "Epoch 2 Train batch 840/1939 Loss=3.1583 Acc=36.84%\n",
      "Epoch 2 Train batch 850/1939 Loss=3.1582 Acc=36.83%\n",
      "Epoch 2 Train batch 860/1939 Loss=3.1576 Acc=36.83%\n",
      "Epoch 2 Train batch 870/1939 Loss=3.1578 Acc=36.83%\n",
      "Epoch 2 Train batch 880/1939 Loss=3.1576 Acc=36.84%\n",
      "Epoch 2 Train batch 890/1939 Loss=3.1573 Acc=36.85%\n",
      "Epoch 2 Train batch 900/1939 Loss=3.1574 Acc=36.84%\n",
      "Epoch 2 Train batch 910/1939 Loss=3.1569 Acc=36.85%\n",
      "Epoch 2 Train batch 920/1939 Loss=3.1566 Acc=36.86%\n",
      "Epoch 2 Train batch 930/1939 Loss=3.1567 Acc=36.86%\n",
      "Epoch 2 Train batch 940/1939 Loss=3.1572 Acc=36.86%\n",
      "Epoch 2 Train batch 950/1939 Loss=3.1573 Acc=36.86%\n",
      "Epoch 2 Train batch 960/1939 Loss=3.1577 Acc=36.85%\n",
      "Epoch 2 Train batch 970/1939 Loss=3.1580 Acc=36.84%\n",
      "Epoch 2 Train batch 980/1939 Loss=3.1573 Acc=36.85%\n",
      "Epoch 2 Train batch 990/1939 Loss=3.1572 Acc=36.86%\n",
      "Epoch 2 Train batch 1000/1939 Loss=3.1573 Acc=36.86%\n",
      "Epoch 2 Train batch 1010/1939 Loss=3.1569 Acc=36.86%\n",
      "Epoch 2 Train batch 1020/1939 Loss=3.1569 Acc=36.87%\n",
      "Epoch 2 Train batch 1030/1939 Loss=3.1569 Acc=36.87%\n",
      "Epoch 2 Train batch 1040/1939 Loss=3.1568 Acc=36.86%\n",
      "Epoch 2 Train batch 1050/1939 Loss=3.1564 Acc=36.86%\n",
      "Epoch 2 Train batch 1060/1939 Loss=3.1555 Acc=36.88%\n",
      "Epoch 2 Train batch 1070/1939 Loss=3.1551 Acc=36.89%\n",
      "Epoch 2 Train batch 1080/1939 Loss=3.1547 Acc=36.89%\n",
      "Epoch 2 Train batch 1090/1939 Loss=3.1550 Acc=36.89%\n",
      "Epoch 2 Train batch 1100/1939 Loss=3.1546 Acc=36.90%\n",
      "Epoch 2 Train batch 1110/1939 Loss=3.1547 Acc=36.91%\n",
      "Epoch 2 Train batch 1120/1939 Loss=3.1542 Acc=36.91%\n",
      "Epoch 2 Train batch 1130/1939 Loss=3.1537 Acc=36.92%\n",
      "Epoch 2 Train batch 1140/1939 Loss=3.1535 Acc=36.92%\n",
      "Epoch 2 Train batch 1150/1939 Loss=3.1531 Acc=36.92%\n",
      "Epoch 2 Train batch 1160/1939 Loss=3.1531 Acc=36.93%\n",
      "Epoch 2 Train batch 1170/1939 Loss=3.1529 Acc=36.93%\n",
      "Epoch 2 Train batch 1180/1939 Loss=3.1525 Acc=36.93%\n",
      "Epoch 2 Train batch 1190/1939 Loss=3.1526 Acc=36.93%\n",
      "Epoch 2 Train batch 1200/1939 Loss=3.1522 Acc=36.94%\n",
      "Epoch 2 Train batch 1210/1939 Loss=3.1527 Acc=36.93%\n",
      "Epoch 2 Train batch 1220/1939 Loss=3.1523 Acc=36.94%\n",
      "Epoch 2 Train batch 1230/1939 Loss=3.1523 Acc=36.94%\n",
      "Epoch 2 Train batch 1240/1939 Loss=3.1519 Acc=36.94%\n",
      "Epoch 2 Train batch 1250/1939 Loss=3.1518 Acc=36.94%\n",
      "Epoch 2 Train batch 1260/1939 Loss=3.1517 Acc=36.94%\n",
      "Epoch 2 Train batch 1270/1939 Loss=3.1520 Acc=36.93%\n",
      "Epoch 2 Train batch 1280/1939 Loss=3.1515 Acc=36.94%\n",
      "Epoch 2 Train batch 1290/1939 Loss=3.1515 Acc=36.94%\n",
      "Epoch 2 Train batch 1300/1939 Loss=3.1512 Acc=36.94%\n",
      "Epoch 2 Train batch 1310/1939 Loss=3.1512 Acc=36.94%\n",
      "Epoch 2 Train batch 1320/1939 Loss=3.1507 Acc=36.95%\n",
      "Epoch 2 Train batch 1330/1939 Loss=3.1508 Acc=36.94%\n",
      "Epoch 2 Train batch 1340/1939 Loss=3.1504 Acc=36.94%\n",
      "Epoch 2 Train batch 1350/1939 Loss=3.1500 Acc=36.95%\n",
      "Epoch 2 Train batch 1360/1939 Loss=3.1495 Acc=36.95%\n",
      "Epoch 2 Train batch 1370/1939 Loss=3.1492 Acc=36.95%\n",
      "Epoch 2 Train batch 1380/1939 Loss=3.1488 Acc=36.96%\n",
      "Epoch 2 Train batch 1390/1939 Loss=3.1487 Acc=36.97%\n",
      "Epoch 2 Train batch 1400/1939 Loss=3.1482 Acc=36.97%\n",
      "Epoch 2 Train batch 1410/1939 Loss=3.1476 Acc=36.98%\n",
      "Epoch 2 Train batch 1420/1939 Loss=3.1473 Acc=36.98%\n",
      "Epoch 2 Train batch 1430/1939 Loss=3.1472 Acc=36.98%\n",
      "Epoch 2 Train batch 1440/1939 Loss=3.1468 Acc=36.99%\n",
      "Epoch 2 Train batch 1450/1939 Loss=3.1467 Acc=37.00%\n",
      "Epoch 2 Train batch 1460/1939 Loss=3.1465 Acc=37.00%\n",
      "Epoch 2 Train batch 1470/1939 Loss=3.1462 Acc=37.00%\n",
      "Epoch 2 Train batch 1480/1939 Loss=3.1463 Acc=37.00%\n",
      "Epoch 2 Train batch 1490/1939 Loss=3.1461 Acc=37.00%\n",
      "Epoch 2 Train batch 1500/1939 Loss=3.1461 Acc=37.01%\n",
      "Epoch 2 Train batch 1510/1939 Loss=3.1456 Acc=37.01%\n",
      "Epoch 2 Train batch 1520/1939 Loss=3.1451 Acc=37.02%\n",
      "Epoch 2 Train batch 1530/1939 Loss=3.1445 Acc=37.03%\n",
      "Epoch 2 Train batch 1540/1939 Loss=3.1443 Acc=37.03%\n",
      "Epoch 2 Train batch 1550/1939 Loss=3.1446 Acc=37.03%\n",
      "Epoch 2 Train batch 1560/1939 Loss=3.1440 Acc=37.04%\n",
      "Epoch 2 Train batch 1570/1939 Loss=3.1442 Acc=37.04%\n",
      "Epoch 2 Train batch 1580/1939 Loss=3.1438 Acc=37.04%\n",
      "Epoch 2 Train batch 1590/1939 Loss=3.1434 Acc=37.04%\n",
      "Epoch 2 Train batch 1600/1939 Loss=3.1438 Acc=37.04%\n",
      "Epoch 2 Train batch 1610/1939 Loss=3.1438 Acc=37.05%\n",
      "Epoch 2 Train batch 1620/1939 Loss=3.1439 Acc=37.05%\n",
      "Epoch 2 Train batch 1630/1939 Loss=3.1436 Acc=37.06%\n",
      "Epoch 2 Train batch 1640/1939 Loss=3.1432 Acc=37.06%\n",
      "Epoch 2 Train batch 1650/1939 Loss=3.1425 Acc=37.07%\n",
      "Epoch 2 Train batch 1660/1939 Loss=3.1422 Acc=37.07%\n",
      "Epoch 2 Train batch 1670/1939 Loss=3.1421 Acc=37.08%\n",
      "Epoch 2 Train batch 1680/1939 Loss=3.1420 Acc=37.08%\n",
      "Epoch 2 Train batch 1690/1939 Loss=3.1422 Acc=37.08%\n",
      "Epoch 2 Train batch 1700/1939 Loss=3.1422 Acc=37.08%\n",
      "Epoch 2 Train batch 1710/1939 Loss=3.1418 Acc=37.08%\n",
      "Epoch 2 Train batch 1720/1939 Loss=3.1422 Acc=37.08%\n",
      "Epoch 2 Train batch 1730/1939 Loss=3.1423 Acc=37.08%\n",
      "Epoch 2 Train batch 1740/1939 Loss=3.1419 Acc=37.08%\n",
      "Epoch 2 Train batch 1750/1939 Loss=3.1418 Acc=37.09%\n",
      "Epoch 2 Train batch 1760/1939 Loss=3.1415 Acc=37.09%\n",
      "Epoch 2 Train batch 1770/1939 Loss=3.1410 Acc=37.10%\n",
      "Epoch 2 Train batch 1780/1939 Loss=3.1409 Acc=37.10%\n",
      "Epoch 2 Train batch 1790/1939 Loss=3.1410 Acc=37.10%\n",
      "Epoch 2 Train batch 1800/1939 Loss=3.1405 Acc=37.10%\n",
      "Epoch 2 Train batch 1810/1939 Loss=3.1405 Acc=37.10%\n",
      "Epoch 2 Train batch 1820/1939 Loss=3.1407 Acc=37.10%\n",
      "Epoch 2 Train batch 1830/1939 Loss=3.1403 Acc=37.11%\n",
      "Epoch 2 Train batch 1840/1939 Loss=3.1401 Acc=37.11%\n",
      "Epoch 2 Train batch 1850/1939 Loss=3.1397 Acc=37.11%\n",
      "Epoch 2 Train batch 1860/1939 Loss=3.1398 Acc=37.11%\n",
      "Epoch 2 Train batch 1870/1939 Loss=3.1399 Acc=37.11%\n",
      "Epoch 2 Train batch 1880/1939 Loss=3.1399 Acc=37.11%\n",
      "Epoch 2 Train batch 1890/1939 Loss=3.1394 Acc=37.11%\n",
      "Epoch 2 Train batch 1900/1939 Loss=3.1389 Acc=37.12%\n",
      "Epoch 2 Train batch 1910/1939 Loss=3.1387 Acc=37.13%\n",
      "Epoch 2 Train batch 1920/1939 Loss=3.1390 Acc=37.12%\n",
      "Epoch 2 Train batch 1930/1939 Loss=3.1388 Acc=37.13%\n",
      "Epoch 2 Train batch 1939/1939 Loss=3.1388 Acc=37.13%\n",
      "Epoch 2/5 train_loss=3.1388 train_acc=37.13% val_loss=3.0622 val_acc=38.67%\n",
      "Epoch 3 Train batch 10/1939 Loss=2.9609 Acc=38.27%\n",
      "Epoch 3 Train batch 20/1939 Loss=2.9278 Acc=38.74%\n",
      "Epoch 3 Train batch 30/1939 Loss=2.9314 Acc=38.79%\n",
      "Epoch 3 Train batch 40/1939 Loss=2.9294 Acc=38.70%\n",
      "Epoch 3 Train batch 50/1939 Loss=2.9253 Acc=38.79%\n",
      "Epoch 3 Train batch 60/1939 Loss=2.9328 Acc=38.71%\n",
      "Epoch 3 Train batch 70/1939 Loss=2.9337 Acc=38.68%\n",
      "Epoch 3 Train batch 80/1939 Loss=2.9316 Acc=38.62%\n",
      "Epoch 3 Train batch 90/1939 Loss=2.9344 Acc=38.55%\n",
      "Epoch 3 Train batch 100/1939 Loss=2.9400 Acc=38.43%\n",
      "Epoch 3 Train batch 110/1939 Loss=2.9440 Acc=38.37%\n",
      "Epoch 3 Train batch 120/1939 Loss=2.9450 Acc=38.33%\n",
      "Epoch 3 Train batch 130/1939 Loss=2.9442 Acc=38.31%\n",
      "Epoch 3 Train batch 140/1939 Loss=2.9431 Acc=38.32%\n",
      "Epoch 3 Train batch 150/1939 Loss=2.9468 Acc=38.25%\n",
      "Epoch 3 Train batch 160/1939 Loss=2.9431 Acc=38.32%\n",
      "Epoch 3 Train batch 170/1939 Loss=2.9419 Acc=38.33%\n",
      "Epoch 3 Train batch 180/1939 Loss=2.9412 Acc=38.36%\n",
      "Epoch 3 Train batch 190/1939 Loss=2.9401 Acc=38.37%\n",
      "Epoch 3 Train batch 200/1939 Loss=2.9399 Acc=38.37%\n",
      "Epoch 3 Train batch 210/1939 Loss=2.9416 Acc=38.36%\n",
      "Epoch 3 Train batch 220/1939 Loss=2.9418 Acc=38.37%\n",
      "Epoch 3 Train batch 230/1939 Loss=2.9436 Acc=38.35%\n",
      "Epoch 3 Train batch 240/1939 Loss=2.9429 Acc=38.36%\n",
      "Epoch 3 Train batch 250/1939 Loss=2.9433 Acc=38.36%\n",
      "Epoch 3 Train batch 260/1939 Loss=2.9459 Acc=38.34%\n",
      "Epoch 3 Train batch 270/1939 Loss=2.9457 Acc=38.35%\n",
      "Epoch 3 Train batch 280/1939 Loss=2.9453 Acc=38.39%\n",
      "Epoch 3 Train batch 290/1939 Loss=2.9455 Acc=38.38%\n",
      "Epoch 3 Train batch 300/1939 Loss=2.9447 Acc=38.40%\n",
      "Epoch 3 Train batch 310/1939 Loss=2.9440 Acc=38.41%\n",
      "Epoch 3 Train batch 320/1939 Loss=2.9462 Acc=38.40%\n",
      "Epoch 3 Train batch 330/1939 Loss=2.9466 Acc=38.41%\n",
      "Epoch 3 Train batch 340/1939 Loss=2.9466 Acc=38.42%\n",
      "Epoch 3 Train batch 350/1939 Loss=2.9477 Acc=38.40%\n",
      "Epoch 3 Train batch 360/1939 Loss=2.9475 Acc=38.41%\n",
      "Epoch 3 Train batch 370/1939 Loss=2.9483 Acc=38.40%\n",
      "Epoch 3 Train batch 380/1939 Loss=2.9479 Acc=38.43%\n",
      "Epoch 3 Train batch 390/1939 Loss=2.9491 Acc=38.42%\n",
      "Epoch 3 Train batch 400/1939 Loss=2.9476 Acc=38.44%\n",
      "Epoch 3 Train batch 410/1939 Loss=2.9478 Acc=38.43%\n",
      "Epoch 3 Train batch 420/1939 Loss=2.9476 Acc=38.45%\n",
      "Epoch 3 Train batch 430/1939 Loss=2.9483 Acc=38.44%\n",
      "Epoch 3 Train batch 440/1939 Loss=2.9477 Acc=38.44%\n",
      "Epoch 3 Train batch 450/1939 Loss=2.9479 Acc=38.44%\n",
      "Epoch 3 Train batch 460/1939 Loss=2.9482 Acc=38.43%\n",
      "Epoch 3 Train batch 470/1939 Loss=2.9483 Acc=38.43%\n",
      "Epoch 3 Train batch 480/1939 Loss=2.9496 Acc=38.41%\n",
      "Epoch 3 Train batch 490/1939 Loss=2.9490 Acc=38.41%\n",
      "Epoch 3 Train batch 500/1939 Loss=2.9495 Acc=38.42%\n",
      "Epoch 3 Train batch 510/1939 Loss=2.9495 Acc=38.43%\n",
      "Epoch 3 Train batch 520/1939 Loss=2.9496 Acc=38.43%\n",
      "Epoch 3 Train batch 530/1939 Loss=2.9501 Acc=38.41%\n",
      "Epoch 3 Train batch 540/1939 Loss=2.9502 Acc=38.41%\n",
      "Epoch 3 Train batch 550/1939 Loss=2.9508 Acc=38.42%\n",
      "Epoch 3 Train batch 560/1939 Loss=2.9508 Acc=38.41%\n",
      "Epoch 3 Train batch 570/1939 Loss=2.9508 Acc=38.41%\n",
      "Epoch 3 Train batch 580/1939 Loss=2.9509 Acc=38.41%\n",
      "Epoch 3 Train batch 590/1939 Loss=2.9510 Acc=38.41%\n",
      "Epoch 3 Train batch 600/1939 Loss=2.9519 Acc=38.41%\n",
      "Epoch 3 Train batch 610/1939 Loss=2.9522 Acc=38.42%\n",
      "Epoch 3 Train batch 620/1939 Loss=2.9526 Acc=38.42%\n",
      "Epoch 3 Train batch 630/1939 Loss=2.9534 Acc=38.40%\n",
      "Epoch 3 Train batch 640/1939 Loss=2.9542 Acc=38.39%\n",
      "Epoch 3 Train batch 650/1939 Loss=2.9541 Acc=38.39%\n",
      "Epoch 3 Train batch 660/1939 Loss=2.9545 Acc=38.39%\n",
      "Epoch 3 Train batch 670/1939 Loss=2.9553 Acc=38.39%\n",
      "Epoch 3 Train batch 680/1939 Loss=2.9561 Acc=38.38%\n",
      "Epoch 3 Train batch 690/1939 Loss=2.9565 Acc=38.37%\n",
      "Epoch 3 Train batch 700/1939 Loss=2.9575 Acc=38.37%\n",
      "Epoch 3 Train batch 710/1939 Loss=2.9575 Acc=38.37%\n",
      "Epoch 3 Train batch 720/1939 Loss=2.9568 Acc=38.38%\n",
      "Epoch 3 Train batch 730/1939 Loss=2.9565 Acc=38.38%\n",
      "Epoch 3 Train batch 740/1939 Loss=2.9565 Acc=38.38%\n",
      "Epoch 3 Train batch 750/1939 Loss=2.9567 Acc=38.38%\n",
      "Epoch 3 Train batch 760/1939 Loss=2.9574 Acc=38.38%\n",
      "Epoch 3 Train batch 770/1939 Loss=2.9579 Acc=38.38%\n",
      "Epoch 3 Train batch 780/1939 Loss=2.9577 Acc=38.39%\n",
      "Epoch 3 Train batch 790/1939 Loss=2.9583 Acc=38.38%\n",
      "Epoch 3 Train batch 800/1939 Loss=2.9573 Acc=38.40%\n",
      "Epoch 3 Train batch 810/1939 Loss=2.9583 Acc=38.39%\n",
      "Epoch 3 Train batch 820/1939 Loss=2.9587 Acc=38.38%\n",
      "Epoch 3 Train batch 830/1939 Loss=2.9584 Acc=38.39%\n",
      "Epoch 3 Train batch 840/1939 Loss=2.9585 Acc=38.39%\n",
      "Epoch 3 Train batch 850/1939 Loss=2.9590 Acc=38.39%\n",
      "Epoch 3 Train batch 860/1939 Loss=2.9587 Acc=38.39%\n",
      "Epoch 3 Train batch 870/1939 Loss=2.9588 Acc=38.40%\n",
      "Epoch 3 Train batch 880/1939 Loss=2.9586 Acc=38.41%\n",
      "Epoch 3 Train batch 890/1939 Loss=2.9586 Acc=38.41%\n",
      "Epoch 3 Train batch 900/1939 Loss=2.9590 Acc=38.41%\n",
      "Epoch 3 Train batch 910/1939 Loss=2.9591 Acc=38.41%\n",
      "Epoch 3 Train batch 920/1939 Loss=2.9592 Acc=38.42%\n",
      "Epoch 3 Train batch 930/1939 Loss=2.9594 Acc=38.41%\n",
      "Epoch 3 Train batch 940/1939 Loss=2.9595 Acc=38.41%\n",
      "Epoch 3 Train batch 950/1939 Loss=2.9596 Acc=38.41%\n",
      "Epoch 3 Train batch 960/1939 Loss=2.9592 Acc=38.42%\n",
      "Epoch 3 Train batch 970/1939 Loss=2.9588 Acc=38.42%\n",
      "Epoch 3 Train batch 980/1939 Loss=2.9589 Acc=38.42%\n",
      "Epoch 3 Train batch 990/1939 Loss=2.9588 Acc=38.42%\n",
      "Epoch 3 Train batch 1000/1939 Loss=2.9585 Acc=38.43%\n",
      "Epoch 3 Train batch 1010/1939 Loss=2.9587 Acc=38.44%\n",
      "Epoch 3 Train batch 1020/1939 Loss=2.9585 Acc=38.45%\n",
      "Epoch 3 Train batch 1030/1939 Loss=2.9587 Acc=38.45%\n",
      "Epoch 3 Train batch 1040/1939 Loss=2.9590 Acc=38.45%\n",
      "Epoch 3 Train batch 1050/1939 Loss=2.9587 Acc=38.46%\n",
      "Epoch 3 Train batch 1060/1939 Loss=2.9588 Acc=38.45%\n",
      "Epoch 3 Train batch 1070/1939 Loss=2.9590 Acc=38.45%\n",
      "Epoch 3 Train batch 1080/1939 Loss=2.9584 Acc=38.46%\n",
      "Epoch 3 Train batch 1090/1939 Loss=2.9585 Acc=38.47%\n",
      "Epoch 3 Train batch 1100/1939 Loss=2.9589 Acc=38.46%\n",
      "Epoch 3 Train batch 1110/1939 Loss=2.9594 Acc=38.47%\n",
      "Epoch 3 Train batch 1120/1939 Loss=2.9597 Acc=38.46%\n",
      "Epoch 3 Train batch 1130/1939 Loss=2.9598 Acc=38.46%\n",
      "Epoch 3 Train batch 1140/1939 Loss=2.9599 Acc=38.46%\n",
      "Epoch 3 Train batch 1150/1939 Loss=2.9604 Acc=38.45%\n",
      "Epoch 3 Train batch 1160/1939 Loss=2.9603 Acc=38.45%\n",
      "Epoch 3 Train batch 1170/1939 Loss=2.9599 Acc=38.46%\n",
      "Epoch 3 Train batch 1180/1939 Loss=2.9595 Acc=38.46%\n",
      "Epoch 3 Train batch 1190/1939 Loss=2.9599 Acc=38.46%\n",
      "Epoch 3 Train batch 1200/1939 Loss=2.9605 Acc=38.46%\n",
      "Epoch 3 Train batch 1210/1939 Loss=2.9608 Acc=38.46%\n",
      "Epoch 3 Train batch 1220/1939 Loss=2.9611 Acc=38.46%\n",
      "Epoch 3 Train batch 1230/1939 Loss=2.9610 Acc=38.46%\n",
      "Epoch 3 Train batch 1240/1939 Loss=2.9617 Acc=38.45%\n",
      "Epoch 3 Train batch 1250/1939 Loss=2.9616 Acc=38.46%\n",
      "Epoch 3 Train batch 1260/1939 Loss=2.9618 Acc=38.46%\n",
      "Epoch 3 Train batch 1270/1939 Loss=2.9619 Acc=38.46%\n",
      "Epoch 3 Train batch 1280/1939 Loss=2.9615 Acc=38.46%\n",
      "Epoch 3 Train batch 1290/1939 Loss=2.9618 Acc=38.46%\n",
      "Epoch 3 Train batch 1300/1939 Loss=2.9616 Acc=38.47%\n",
      "Epoch 3 Train batch 1310/1939 Loss=2.9617 Acc=38.47%\n",
      "Epoch 3 Train batch 1320/1939 Loss=2.9618 Acc=38.47%\n",
      "Epoch 3 Train batch 1330/1939 Loss=2.9618 Acc=38.47%\n",
      "Epoch 3 Train batch 1340/1939 Loss=2.9622 Acc=38.47%\n",
      "Epoch 3 Train batch 1350/1939 Loss=2.9624 Acc=38.47%\n",
      "Epoch 3 Train batch 1360/1939 Loss=2.9627 Acc=38.47%\n",
      "Epoch 3 Train batch 1370/1939 Loss=2.9629 Acc=38.46%\n",
      "Epoch 3 Train batch 1380/1939 Loss=2.9629 Acc=38.46%\n",
      "Epoch 3 Train batch 1390/1939 Loss=2.9629 Acc=38.47%\n",
      "Epoch 3 Train batch 1400/1939 Loss=2.9632 Acc=38.47%\n",
      "Epoch 3 Train batch 1410/1939 Loss=2.9631 Acc=38.47%\n",
      "Epoch 3 Train batch 1420/1939 Loss=2.9631 Acc=38.48%\n",
      "Epoch 3 Train batch 1430/1939 Loss=2.9633 Acc=38.48%\n",
      "Epoch 3 Train batch 1440/1939 Loss=2.9635 Acc=38.48%\n",
      "Epoch 3 Train batch 1450/1939 Loss=2.9640 Acc=38.47%\n",
      "Epoch 3 Train batch 1460/1939 Loss=2.9646 Acc=38.47%\n",
      "Epoch 3 Train batch 1470/1939 Loss=2.9648 Acc=38.46%\n",
      "Epoch 3 Train batch 1480/1939 Loss=2.9649 Acc=38.47%\n",
      "Epoch 3 Train batch 1490/1939 Loss=2.9649 Acc=38.47%\n",
      "Epoch 3 Train batch 1500/1939 Loss=2.9650 Acc=38.47%\n",
      "Epoch 3 Train batch 1510/1939 Loss=2.9648 Acc=38.47%\n",
      "Epoch 3 Train batch 1520/1939 Loss=2.9647 Acc=38.47%\n",
      "Epoch 3 Train batch 1530/1939 Loss=2.9645 Acc=38.48%\n",
      "Epoch 3 Train batch 1540/1939 Loss=2.9645 Acc=38.47%\n",
      "Epoch 3 Train batch 1550/1939 Loss=2.9646 Acc=38.48%\n",
      "Epoch 3 Train batch 1560/1939 Loss=2.9643 Acc=38.48%\n",
      "Epoch 3 Train batch 1570/1939 Loss=2.9643 Acc=38.48%\n",
      "Epoch 3 Train batch 1580/1939 Loss=2.9643 Acc=38.49%\n",
      "Epoch 3 Train batch 1590/1939 Loss=2.9646 Acc=38.48%\n",
      "Epoch 3 Train batch 1600/1939 Loss=2.9648 Acc=38.48%\n",
      "Epoch 3 Train batch 1610/1939 Loss=2.9647 Acc=38.49%\n",
      "Epoch 3 Train batch 1620/1939 Loss=2.9650 Acc=38.49%\n",
      "Epoch 3 Train batch 1630/1939 Loss=2.9650 Acc=38.48%\n",
      "Epoch 3 Train batch 1640/1939 Loss=2.9650 Acc=38.49%\n",
      "Epoch 3 Train batch 1650/1939 Loss=2.9649 Acc=38.49%\n",
      "Epoch 3 Train batch 1660/1939 Loss=2.9651 Acc=38.49%\n",
      "Epoch 3 Train batch 1670/1939 Loss=2.9651 Acc=38.49%\n",
      "Epoch 3 Train batch 1680/1939 Loss=2.9655 Acc=38.48%\n",
      "Epoch 3 Train batch 1690/1939 Loss=2.9654 Acc=38.49%\n",
      "Epoch 3 Train batch 1700/1939 Loss=2.9654 Acc=38.49%\n",
      "Epoch 3 Train batch 1710/1939 Loss=2.9654 Acc=38.50%\n",
      "Epoch 3 Train batch 1720/1939 Loss=2.9656 Acc=38.49%\n",
      "Epoch 3 Train batch 1730/1939 Loss=2.9660 Acc=38.49%\n",
      "Epoch 3 Train batch 1740/1939 Loss=2.9661 Acc=38.49%\n",
      "Epoch 3 Train batch 1750/1939 Loss=2.9663 Acc=38.49%\n",
      "Epoch 3 Train batch 1760/1939 Loss=2.9661 Acc=38.49%\n",
      "Epoch 3 Train batch 1770/1939 Loss=2.9665 Acc=38.49%\n",
      "Epoch 3 Train batch 1780/1939 Loss=2.9664 Acc=38.49%\n",
      "Epoch 3 Train batch 1790/1939 Loss=2.9667 Acc=38.49%\n",
      "Epoch 3 Train batch 1800/1939 Loss=2.9666 Acc=38.49%\n",
      "Epoch 3 Train batch 1810/1939 Loss=2.9668 Acc=38.48%\n",
      "Epoch 3 Train batch 1820/1939 Loss=2.9669 Acc=38.48%\n",
      "Epoch 3 Train batch 1830/1939 Loss=2.9670 Acc=38.48%\n",
      "Epoch 3 Train batch 1840/1939 Loss=2.9670 Acc=38.49%\n",
      "Epoch 3 Train batch 1850/1939 Loss=2.9671 Acc=38.48%\n",
      "Epoch 3 Train batch 1860/1939 Loss=2.9670 Acc=38.49%\n",
      "Epoch 3 Train batch 1870/1939 Loss=2.9671 Acc=38.49%\n",
      "Epoch 3 Train batch 1880/1939 Loss=2.9673 Acc=38.48%\n",
      "Epoch 3 Train batch 1890/1939 Loss=2.9674 Acc=38.48%\n",
      "Epoch 3 Train batch 1900/1939 Loss=2.9676 Acc=38.49%\n",
      "Epoch 3 Train batch 1910/1939 Loss=2.9678 Acc=38.48%\n",
      "Epoch 3 Train batch 1920/1939 Loss=2.9681 Acc=38.48%\n",
      "Epoch 3 Train batch 1930/1939 Loss=2.9679 Acc=38.48%\n",
      "Epoch 3 Train batch 1939/1939 Loss=2.9679 Acc=38.49%\n",
      "Epoch 3/5 train_loss=2.9679 train_acc=38.49% val_loss=3.0245 val_acc=39.14%\n",
      "Epoch 4 Train batch 10/1939 Loss=2.7778 Acc=39.79%\n",
      "Epoch 4 Train batch 20/1939 Loss=2.7921 Acc=39.62%\n",
      "Epoch 4 Train batch 30/1939 Loss=2.8010 Acc=39.63%\n",
      "Epoch 4 Train batch 40/1939 Loss=2.7979 Acc=39.89%\n",
      "Epoch 4 Train batch 50/1939 Loss=2.7904 Acc=39.80%\n",
      "Epoch 4 Train batch 60/1939 Loss=2.7889 Acc=39.80%\n",
      "Epoch 4 Train batch 70/1939 Loss=2.7932 Acc=39.85%\n",
      "Epoch 4 Train batch 80/1939 Loss=2.7963 Acc=39.80%\n",
      "Epoch 4 Train batch 90/1939 Loss=2.7938 Acc=39.87%\n",
      "Epoch 4 Train batch 100/1939 Loss=2.7919 Acc=39.86%\n",
      "Epoch 4 Train batch 110/1939 Loss=2.7944 Acc=39.84%\n",
      "Epoch 4 Train batch 120/1939 Loss=2.7950 Acc=39.78%\n",
      "Epoch 4 Train batch 130/1939 Loss=2.7966 Acc=39.77%\n",
      "Epoch 4 Train batch 140/1939 Loss=2.8011 Acc=39.70%\n",
      "Epoch 4 Train batch 150/1939 Loss=2.7999 Acc=39.73%\n",
      "Epoch 4 Train batch 160/1939 Loss=2.8018 Acc=39.70%\n",
      "Epoch 4 Train batch 170/1939 Loss=2.8026 Acc=39.71%\n",
      "Epoch 4 Train batch 180/1939 Loss=2.8053 Acc=39.64%\n",
      "Epoch 4 Train batch 190/1939 Loss=2.8075 Acc=39.62%\n",
      "Epoch 4 Train batch 200/1939 Loss=2.8093 Acc=39.59%\n",
      "Epoch 4 Train batch 210/1939 Loss=2.8105 Acc=39.60%\n",
      "Epoch 4 Train batch 220/1939 Loss=2.8125 Acc=39.59%\n",
      "Epoch 4 Train batch 230/1939 Loss=2.8145 Acc=39.58%\n",
      "Epoch 4 Train batch 240/1939 Loss=2.8140 Acc=39.57%\n",
      "Epoch 4 Train batch 250/1939 Loss=2.8146 Acc=39.55%\n",
      "Epoch 4 Train batch 260/1939 Loss=2.8136 Acc=39.56%\n",
      "Epoch 4 Train batch 270/1939 Loss=2.8135 Acc=39.57%\n",
      "Epoch 4 Train batch 280/1939 Loss=2.8151 Acc=39.54%\n",
      "Epoch 4 Train batch 290/1939 Loss=2.8145 Acc=39.56%\n",
      "Epoch 4 Train batch 300/1939 Loss=2.8154 Acc=39.55%\n",
      "Epoch 4 Train batch 310/1939 Loss=2.8159 Acc=39.58%\n",
      "Epoch 4 Train batch 320/1939 Loss=2.8168 Acc=39.56%\n",
      "Epoch 4 Train batch 330/1939 Loss=2.8177 Acc=39.55%\n",
      "Epoch 4 Train batch 340/1939 Loss=2.8162 Acc=39.57%\n",
      "Epoch 4 Train batch 350/1939 Loss=2.8181 Acc=39.54%\n",
      "Epoch 4 Train batch 360/1939 Loss=2.8184 Acc=39.54%\n",
      "Epoch 4 Train batch 370/1939 Loss=2.8186 Acc=39.52%\n",
      "Epoch 4 Train batch 380/1939 Loss=2.8178 Acc=39.53%\n",
      "Epoch 4 Train batch 390/1939 Loss=2.8178 Acc=39.54%\n",
      "Epoch 4 Train batch 400/1939 Loss=2.8173 Acc=39.55%\n",
      "Epoch 4 Train batch 410/1939 Loss=2.8175 Acc=39.55%\n",
      "Epoch 4 Train batch 420/1939 Loss=2.8187 Acc=39.55%\n",
      "Epoch 4 Train batch 430/1939 Loss=2.8191 Acc=39.56%\n",
      "Epoch 4 Train batch 440/1939 Loss=2.8196 Acc=39.57%\n",
      "Epoch 4 Train batch 450/1939 Loss=2.8199 Acc=39.57%\n",
      "Epoch 4 Train batch 460/1939 Loss=2.8195 Acc=39.56%\n",
      "Epoch 4 Train batch 470/1939 Loss=2.8200 Acc=39.55%\n",
      "Epoch 4 Train batch 480/1939 Loss=2.8199 Acc=39.55%\n",
      "Epoch 4 Train batch 490/1939 Loss=2.8199 Acc=39.56%\n",
      "Epoch 4 Train batch 500/1939 Loss=2.8206 Acc=39.57%\n",
      "Epoch 4 Train batch 510/1939 Loss=2.8203 Acc=39.58%\n",
      "Epoch 4 Train batch 520/1939 Loss=2.8215 Acc=39.57%\n",
      "Epoch 4 Train batch 530/1939 Loss=2.8220 Acc=39.56%\n",
      "Epoch 4 Train batch 540/1939 Loss=2.8222 Acc=39.56%\n",
      "Epoch 4 Train batch 550/1939 Loss=2.8225 Acc=39.55%\n",
      "Epoch 4 Train batch 560/1939 Loss=2.8221 Acc=39.57%\n",
      "Epoch 4 Train batch 570/1939 Loss=2.8223 Acc=39.57%\n",
      "Epoch 4 Train batch 580/1939 Loss=2.8217 Acc=39.57%\n",
      "Epoch 4 Train batch 590/1939 Loss=2.8222 Acc=39.57%\n",
      "Epoch 4 Train batch 600/1939 Loss=2.8222 Acc=39.57%\n",
      "Epoch 4 Train batch 610/1939 Loss=2.8220 Acc=39.59%\n",
      "Epoch 4 Train batch 620/1939 Loss=2.8216 Acc=39.59%\n",
      "Epoch 4 Train batch 630/1939 Loss=2.8217 Acc=39.59%\n",
      "Epoch 4 Train batch 640/1939 Loss=2.8219 Acc=39.58%\n",
      "Epoch 4 Train batch 650/1939 Loss=2.8235 Acc=39.57%\n",
      "Epoch 4 Train batch 660/1939 Loss=2.8241 Acc=39.57%\n",
      "Epoch 4 Train batch 670/1939 Loss=2.8254 Acc=39.55%\n",
      "Epoch 4 Train batch 680/1939 Loss=2.8262 Acc=39.55%\n",
      "Epoch 4 Train batch 690/1939 Loss=2.8271 Acc=39.54%\n",
      "Epoch 4 Train batch 700/1939 Loss=2.8280 Acc=39.54%\n",
      "Epoch 4 Train batch 710/1939 Loss=2.8291 Acc=39.52%\n",
      "Epoch 4 Train batch 720/1939 Loss=2.8297 Acc=39.52%\n",
      "Epoch 4 Train batch 730/1939 Loss=2.8300 Acc=39.52%\n",
      "Epoch 4 Train batch 740/1939 Loss=2.8306 Acc=39.51%\n",
      "Epoch 4 Train batch 750/1939 Loss=2.8306 Acc=39.51%\n",
      "Epoch 4 Train batch 760/1939 Loss=2.8314 Acc=39.50%\n",
      "Epoch 4 Train batch 770/1939 Loss=2.8322 Acc=39.49%\n",
      "Epoch 4 Train batch 780/1939 Loss=2.8330 Acc=39.48%\n",
      "Epoch 4 Train batch 790/1939 Loss=2.8330 Acc=39.48%\n",
      "Epoch 4 Train batch 800/1939 Loss=2.8327 Acc=39.49%\n",
      "Epoch 4 Train batch 810/1939 Loss=2.8329 Acc=39.50%\n",
      "Epoch 4 Train batch 820/1939 Loss=2.8331 Acc=39.50%\n",
      "Epoch 4 Train batch 830/1939 Loss=2.8330 Acc=39.49%\n",
      "Epoch 4 Train batch 840/1939 Loss=2.8341 Acc=39.48%\n",
      "Epoch 4 Train batch 850/1939 Loss=2.8340 Acc=39.48%\n",
      "Epoch 4 Train batch 860/1939 Loss=2.8344 Acc=39.48%\n",
      "Epoch 4 Train batch 870/1939 Loss=2.8350 Acc=39.48%\n",
      "Epoch 4 Train batch 880/1939 Loss=2.8358 Acc=39.47%\n",
      "Epoch 4 Train batch 890/1939 Loss=2.8358 Acc=39.47%\n",
      "Epoch 4 Train batch 900/1939 Loss=2.8366 Acc=39.46%\n",
      "Epoch 4 Train batch 910/1939 Loss=2.8366 Acc=39.45%\n",
      "Epoch 4 Train batch 920/1939 Loss=2.8374 Acc=39.44%\n",
      "Epoch 4 Train batch 930/1939 Loss=2.8375 Acc=39.44%\n",
      "Epoch 4 Train batch 940/1939 Loss=2.8378 Acc=39.44%\n",
      "Epoch 4 Train batch 950/1939 Loss=2.8385 Acc=39.43%\n",
      "Epoch 4 Train batch 960/1939 Loss=2.8390 Acc=39.43%\n",
      "Epoch 4 Train batch 970/1939 Loss=2.8395 Acc=39.43%\n",
      "Epoch 4 Train batch 980/1939 Loss=2.8403 Acc=39.42%\n",
      "Epoch 4 Train batch 990/1939 Loss=2.8402 Acc=39.43%\n",
      "Epoch 4 Train batch 1000/1939 Loss=2.8400 Acc=39.42%\n",
      "Epoch 4 Train batch 1010/1939 Loss=2.8399 Acc=39.42%\n",
      "Epoch 4 Train batch 1020/1939 Loss=2.8400 Acc=39.43%\n",
      "Epoch 4 Train batch 1030/1939 Loss=2.8402 Acc=39.42%\n",
      "Epoch 4 Train batch 1040/1939 Loss=2.8411 Acc=39.41%\n",
      "Epoch 4 Train batch 1050/1939 Loss=2.8418 Acc=39.41%\n",
      "Epoch 4 Train batch 1060/1939 Loss=2.8419 Acc=39.41%\n",
      "Epoch 4 Train batch 1070/1939 Loss=2.8426 Acc=39.40%\n",
      "Epoch 4 Train batch 1080/1939 Loss=2.8426 Acc=39.39%\n",
      "Epoch 4 Train batch 1090/1939 Loss=2.8429 Acc=39.39%\n",
      "Epoch 4 Train batch 1100/1939 Loss=2.8432 Acc=39.39%\n",
      "Epoch 4 Train batch 1110/1939 Loss=2.8436 Acc=39.39%\n",
      "Epoch 4 Train batch 1120/1939 Loss=2.8440 Acc=39.38%\n",
      "Epoch 4 Train batch 1130/1939 Loss=2.8437 Acc=39.38%\n",
      "Epoch 4 Train batch 1140/1939 Loss=2.8435 Acc=39.39%\n",
      "Epoch 4 Train batch 1150/1939 Loss=2.8439 Acc=39.38%\n",
      "Epoch 4 Train batch 1160/1939 Loss=2.8440 Acc=39.38%\n",
      "Epoch 4 Train batch 1170/1939 Loss=2.8446 Acc=39.38%\n",
      "Epoch 4 Train batch 1180/1939 Loss=2.8444 Acc=39.38%\n",
      "Epoch 4 Train batch 1190/1939 Loss=2.8448 Acc=39.38%\n",
      "Epoch 4 Train batch 1200/1939 Loss=2.8450 Acc=39.38%\n",
      "Epoch 4 Train batch 1210/1939 Loss=2.8452 Acc=39.38%\n",
      "Epoch 4 Train batch 1220/1939 Loss=2.8450 Acc=39.38%\n",
      "Epoch 4 Train batch 1230/1939 Loss=2.8453 Acc=39.38%\n",
      "Epoch 4 Train batch 1240/1939 Loss=2.8454 Acc=39.38%\n",
      "Epoch 4 Train batch 1250/1939 Loss=2.8454 Acc=39.39%\n",
      "Epoch 4 Train batch 1260/1939 Loss=2.8455 Acc=39.38%\n",
      "Epoch 4 Train batch 1270/1939 Loss=2.8459 Acc=39.38%\n",
      "Epoch 4 Train batch 1280/1939 Loss=2.8458 Acc=39.38%\n",
      "Epoch 4 Train batch 1290/1939 Loss=2.8462 Acc=39.38%\n",
      "Epoch 4 Train batch 1300/1939 Loss=2.8464 Acc=39.38%\n",
      "Epoch 4 Train batch 1310/1939 Loss=2.8469 Acc=39.37%\n",
      "Epoch 4 Train batch 1320/1939 Loss=2.8469 Acc=39.38%\n",
      "Epoch 4 Train batch 1330/1939 Loss=2.8471 Acc=39.38%\n",
      "Epoch 4 Train batch 1340/1939 Loss=2.8477 Acc=39.37%\n",
      "Epoch 4 Train batch 1350/1939 Loss=2.8474 Acc=39.38%\n",
      "Epoch 4 Train batch 1360/1939 Loss=2.8481 Acc=39.37%\n",
      "Epoch 4 Train batch 1370/1939 Loss=2.8483 Acc=39.37%\n",
      "Epoch 4 Train batch 1380/1939 Loss=2.8488 Acc=39.36%\n",
      "Epoch 4 Train batch 1390/1939 Loss=2.8488 Acc=39.36%\n",
      "Epoch 4 Train batch 1400/1939 Loss=2.8491 Acc=39.36%\n",
      "Epoch 4 Train batch 1410/1939 Loss=2.8492 Acc=39.36%\n",
      "Epoch 4 Train batch 1420/1939 Loss=2.8493 Acc=39.36%\n",
      "Epoch 4 Train batch 1430/1939 Loss=2.8497 Acc=39.35%\n",
      "Epoch 4 Train batch 1440/1939 Loss=2.8503 Acc=39.34%\n",
      "Epoch 4 Train batch 1450/1939 Loss=2.8504 Acc=39.35%\n",
      "Epoch 4 Train batch 1460/1939 Loss=2.8502 Acc=39.35%\n",
      "Epoch 4 Train batch 1470/1939 Loss=2.8500 Acc=39.36%\n",
      "Epoch 4 Train batch 1480/1939 Loss=2.8500 Acc=39.36%\n",
      "Epoch 4 Train batch 1490/1939 Loss=2.8505 Acc=39.35%\n",
      "Epoch 4 Train batch 1500/1939 Loss=2.8509 Acc=39.35%\n",
      "Epoch 4 Train batch 1510/1939 Loss=2.8510 Acc=39.35%\n",
      "Epoch 4 Train batch 1520/1939 Loss=2.8515 Acc=39.35%\n",
      "Epoch 4 Train batch 1530/1939 Loss=2.8516 Acc=39.35%\n",
      "Epoch 4 Train batch 1540/1939 Loss=2.8519 Acc=39.35%\n",
      "Epoch 4 Train batch 1550/1939 Loss=2.8523 Acc=39.34%\n",
      "Epoch 4 Train batch 1560/1939 Loss=2.8523 Acc=39.35%\n",
      "Epoch 4 Train batch 1570/1939 Loss=2.8521 Acc=39.35%\n",
      "Epoch 4 Train batch 1580/1939 Loss=2.8526 Acc=39.34%\n",
      "Epoch 4 Train batch 1590/1939 Loss=2.8527 Acc=39.34%\n",
      "Epoch 4 Train batch 1600/1939 Loss=2.8528 Acc=39.34%\n",
      "Epoch 4 Train batch 1610/1939 Loss=2.8531 Acc=39.34%\n",
      "Epoch 4 Train batch 1620/1939 Loss=2.8530 Acc=39.34%\n",
      "Epoch 4 Train batch 1630/1939 Loss=2.8534 Acc=39.33%\n",
      "Epoch 4 Train batch 1640/1939 Loss=2.8536 Acc=39.33%\n",
      "Epoch 4 Train batch 1650/1939 Loss=2.8535 Acc=39.33%\n",
      "Epoch 4 Train batch 1660/1939 Loss=2.8537 Acc=39.33%\n",
      "Epoch 4 Train batch 1670/1939 Loss=2.8538 Acc=39.33%\n",
      "Epoch 4 Train batch 1680/1939 Loss=2.8539 Acc=39.33%\n",
      "Epoch 4 Train batch 1690/1939 Loss=2.8543 Acc=39.32%\n",
      "Epoch 4 Train batch 1700/1939 Loss=2.8543 Acc=39.33%\n",
      "Epoch 4 Train batch 1710/1939 Loss=2.8545 Acc=39.33%\n",
      "Epoch 4 Train batch 1720/1939 Loss=2.8548 Acc=39.32%\n",
      "Epoch 4 Train batch 1730/1939 Loss=2.8548 Acc=39.33%\n",
      "Epoch 4 Train batch 1740/1939 Loss=2.8552 Acc=39.33%\n",
      "Epoch 4 Train batch 1750/1939 Loss=2.8551 Acc=39.33%\n",
      "Epoch 4 Train batch 1760/1939 Loss=2.8552 Acc=39.33%\n",
      "Epoch 4 Train batch 1770/1939 Loss=2.8554 Acc=39.33%\n",
      "Epoch 4 Train batch 1780/1939 Loss=2.8555 Acc=39.33%\n",
      "Epoch 4 Train batch 1790/1939 Loss=2.8556 Acc=39.33%\n",
      "Epoch 4 Train batch 1800/1939 Loss=2.8560 Acc=39.32%\n",
      "Epoch 4 Train batch 1810/1939 Loss=2.8562 Acc=39.32%\n",
      "Epoch 4 Train batch 1820/1939 Loss=2.8561 Acc=39.32%\n",
      "Epoch 4 Train batch 1830/1939 Loss=2.8563 Acc=39.32%\n",
      "Epoch 4 Train batch 1840/1939 Loss=2.8563 Acc=39.33%\n",
      "Epoch 4 Train batch 1850/1939 Loss=2.8566 Acc=39.32%\n",
      "Epoch 4 Train batch 1860/1939 Loss=2.8568 Acc=39.32%\n",
      "Epoch 4 Train batch 1870/1939 Loss=2.8568 Acc=39.33%\n",
      "Epoch 4 Train batch 1880/1939 Loss=2.8572 Acc=39.32%\n",
      "Epoch 4 Train batch 1890/1939 Loss=2.8575 Acc=39.32%\n",
      "Epoch 4 Train batch 1900/1939 Loss=2.8576 Acc=39.32%\n",
      "Epoch 4 Train batch 1910/1939 Loss=2.8579 Acc=39.32%\n",
      "Epoch 4 Train batch 1920/1939 Loss=2.8579 Acc=39.33%\n",
      "Epoch 4 Train batch 1930/1939 Loss=2.8581 Acc=39.32%\n",
      "Epoch 4 Train batch 1939/1939 Loss=2.8584 Acc=39.32%\n",
      "Epoch 4/5 train_loss=2.8584 train_acc=39.32% val_loss=3.0031 val_acc=39.50%\n",
      "Epoch 5 Train batch 10/1939 Loss=2.7072 Acc=40.34%\n",
      "Epoch 5 Train batch 20/1939 Loss=2.7015 Acc=40.74%\n",
      "Epoch 5 Train batch 30/1939 Loss=2.6969 Acc=40.74%\n",
      "Epoch 5 Train batch 40/1939 Loss=2.6940 Acc=40.77%\n",
      "Epoch 5 Train batch 50/1939 Loss=2.7038 Acc=40.53%\n",
      "Epoch 5 Train batch 60/1939 Loss=2.7067 Acc=40.45%\n",
      "Epoch 5 Train batch 70/1939 Loss=2.7055 Acc=40.37%\n",
      "Epoch 5 Train batch 80/1939 Loss=2.7011 Acc=40.39%\n",
      "Epoch 5 Train batch 90/1939 Loss=2.7029 Acc=40.39%\n",
      "Epoch 5 Train batch 100/1939 Loss=2.7064 Acc=40.30%\n",
      "Epoch 5 Train batch 110/1939 Loss=2.7107 Acc=40.32%\n",
      "Epoch 5 Train batch 120/1939 Loss=2.7138 Acc=40.35%\n",
      "Epoch 5 Train batch 130/1939 Loss=2.7152 Acc=40.29%\n",
      "Epoch 5 Train batch 140/1939 Loss=2.7192 Acc=40.26%\n",
      "Epoch 5 Train batch 150/1939 Loss=2.7174 Acc=40.27%\n",
      "Epoch 5 Train batch 160/1939 Loss=2.7169 Acc=40.24%\n",
      "Epoch 5 Train batch 170/1939 Loss=2.7208 Acc=40.23%\n",
      "Epoch 5 Train batch 180/1939 Loss=2.7197 Acc=40.25%\n",
      "Epoch 5 Train batch 190/1939 Loss=2.7211 Acc=40.24%\n",
      "Epoch 5 Train batch 200/1939 Loss=2.7193 Acc=40.30%\n",
      "Epoch 5 Train batch 210/1939 Loss=2.7192 Acc=40.31%\n",
      "Epoch 5 Train batch 220/1939 Loss=2.7171 Acc=40.36%\n",
      "Epoch 5 Train batch 230/1939 Loss=2.7176 Acc=40.38%\n",
      "Epoch 5 Train batch 240/1939 Loss=2.7182 Acc=40.38%\n",
      "Epoch 5 Train batch 250/1939 Loss=2.7173 Acc=40.39%\n",
      "Epoch 5 Train batch 260/1939 Loss=2.7179 Acc=40.38%\n",
      "Epoch 5 Train batch 270/1939 Loss=2.7187 Acc=40.35%\n",
      "Epoch 5 Train batch 280/1939 Loss=2.7203 Acc=40.35%\n",
      "Epoch 5 Train batch 290/1939 Loss=2.7210 Acc=40.35%\n",
      "Epoch 5 Train batch 300/1939 Loss=2.7217 Acc=40.35%\n",
      "Epoch 5 Train batch 310/1939 Loss=2.7207 Acc=40.34%\n",
      "Epoch 5 Train batch 320/1939 Loss=2.7218 Acc=40.34%\n",
      "Epoch 5 Train batch 330/1939 Loss=2.7218 Acc=40.34%\n",
      "Epoch 5 Train batch 340/1939 Loss=2.7231 Acc=40.32%\n",
      "Epoch 5 Train batch 350/1939 Loss=2.7239 Acc=40.30%\n",
      "Epoch 5 Train batch 360/1939 Loss=2.7237 Acc=40.32%\n",
      "Epoch 5 Train batch 370/1939 Loss=2.7252 Acc=40.30%\n",
      "Epoch 5 Train batch 380/1939 Loss=2.7258 Acc=40.29%\n",
      "Epoch 5 Train batch 390/1939 Loss=2.7269 Acc=40.27%\n",
      "Epoch 5 Train batch 400/1939 Loss=2.7273 Acc=40.26%\n",
      "Epoch 5 Train batch 410/1939 Loss=2.7275 Acc=40.28%\n",
      "Epoch 5 Train batch 420/1939 Loss=2.7282 Acc=40.27%\n",
      "Epoch 5 Train batch 430/1939 Loss=2.7298 Acc=40.24%\n",
      "Epoch 5 Train batch 440/1939 Loss=2.7299 Acc=40.25%\n",
      "Epoch 5 Train batch 450/1939 Loss=2.7304 Acc=40.26%\n",
      "Epoch 5 Train batch 460/1939 Loss=2.7304 Acc=40.27%\n",
      "Epoch 5 Train batch 470/1939 Loss=2.7314 Acc=40.26%\n",
      "Epoch 5 Train batch 480/1939 Loss=2.7314 Acc=40.28%\n",
      "Epoch 5 Train batch 490/1939 Loss=2.7315 Acc=40.30%\n",
      "Epoch 5 Train batch 500/1939 Loss=2.7326 Acc=40.29%\n",
      "Epoch 5 Train batch 510/1939 Loss=2.7334 Acc=40.28%\n",
      "Epoch 5 Train batch 520/1939 Loss=2.7337 Acc=40.27%\n",
      "Epoch 5 Train batch 530/1939 Loss=2.7336 Acc=40.27%\n",
      "Epoch 5 Train batch 540/1939 Loss=2.7338 Acc=40.27%\n",
      "Epoch 5 Train batch 550/1939 Loss=2.7334 Acc=40.26%\n",
      "Epoch 5 Train batch 560/1939 Loss=2.7337 Acc=40.27%\n",
      "Epoch 5 Train batch 570/1939 Loss=2.7353 Acc=40.24%\n",
      "Epoch 5 Train batch 580/1939 Loss=2.7358 Acc=40.23%\n",
      "Epoch 5 Train batch 590/1939 Loss=2.7364 Acc=40.23%\n",
      "Epoch 5 Train batch 600/1939 Loss=2.7373 Acc=40.22%\n",
      "Epoch 5 Train batch 610/1939 Loss=2.7382 Acc=40.21%\n",
      "Epoch 5 Train batch 620/1939 Loss=2.7381 Acc=40.23%\n",
      "Epoch 5 Train batch 630/1939 Loss=2.7387 Acc=40.23%\n",
      "Epoch 5 Train batch 640/1939 Loss=2.7394 Acc=40.22%\n",
      "Epoch 5 Train batch 650/1939 Loss=2.7394 Acc=40.23%\n",
      "Epoch 5 Train batch 660/1939 Loss=2.7396 Acc=40.23%\n",
      "Epoch 5 Train batch 670/1939 Loss=2.7406 Acc=40.21%\n",
      "Epoch 5 Train batch 680/1939 Loss=2.7407 Acc=40.21%\n",
      "Epoch 5 Train batch 690/1939 Loss=2.7419 Acc=40.20%\n",
      "Epoch 5 Train batch 700/1939 Loss=2.7429 Acc=40.18%\n",
      "Epoch 5 Train batch 710/1939 Loss=2.7435 Acc=40.18%\n",
      "Epoch 5 Train batch 720/1939 Loss=2.7446 Acc=40.16%\n",
      "Epoch 5 Train batch 730/1939 Loss=2.7453 Acc=40.15%\n",
      "Epoch 5 Train batch 740/1939 Loss=2.7466 Acc=40.15%\n",
      "Epoch 5 Train batch 750/1939 Loss=2.7477 Acc=40.14%\n",
      "Epoch 5 Train batch 760/1939 Loss=2.7473 Acc=40.15%\n",
      "Epoch 5 Train batch 770/1939 Loss=2.7474 Acc=40.16%\n",
      "Epoch 5 Train batch 780/1939 Loss=2.7482 Acc=40.16%\n",
      "Epoch 5 Train batch 790/1939 Loss=2.7487 Acc=40.16%\n",
      "Epoch 5 Train batch 800/1939 Loss=2.7486 Acc=40.16%\n",
      "Epoch 5 Train batch 810/1939 Loss=2.7493 Acc=40.15%\n",
      "Epoch 5 Train batch 820/1939 Loss=2.7501 Acc=40.15%\n",
      "Epoch 5 Train batch 830/1939 Loss=2.7501 Acc=40.15%\n",
      "Epoch 5 Train batch 840/1939 Loss=2.7503 Acc=40.15%\n",
      "Epoch 5 Train batch 850/1939 Loss=2.7502 Acc=40.15%\n",
      "Epoch 5 Train batch 860/1939 Loss=2.7503 Acc=40.16%\n",
      "Epoch 5 Train batch 870/1939 Loss=2.7507 Acc=40.15%\n",
      "Epoch 5 Train batch 880/1939 Loss=2.7515 Acc=40.14%\n",
      "Epoch 5 Train batch 890/1939 Loss=2.7521 Acc=40.12%\n",
      "Epoch 5 Train batch 900/1939 Loss=2.7516 Acc=40.13%\n",
      "Epoch 5 Train batch 910/1939 Loss=2.7520 Acc=40.13%\n",
      "Epoch 5 Train batch 920/1939 Loss=2.7522 Acc=40.12%\n",
      "Epoch 5 Train batch 930/1939 Loss=2.7527 Acc=40.12%\n",
      "Epoch 5 Train batch 940/1939 Loss=2.7530 Acc=40.12%\n",
      "Epoch 5 Train batch 950/1939 Loss=2.7532 Acc=40.12%\n",
      "Epoch 5 Train batch 960/1939 Loss=2.7534 Acc=40.12%\n",
      "Epoch 5 Train batch 970/1939 Loss=2.7537 Acc=40.12%\n",
      "Epoch 5 Train batch 980/1939 Loss=2.7543 Acc=40.11%\n",
      "Epoch 5 Train batch 990/1939 Loss=2.7548 Acc=40.11%\n",
      "Epoch 5 Train batch 1000/1939 Loss=2.7542 Acc=40.12%\n",
      "Epoch 5 Train batch 1010/1939 Loss=2.7548 Acc=40.11%\n",
      "Epoch 5 Train batch 1020/1939 Loss=2.7552 Acc=40.11%\n",
      "Epoch 5 Train batch 1030/1939 Loss=2.7553 Acc=40.11%\n",
      "Epoch 5 Train batch 1040/1939 Loss=2.7558 Acc=40.10%\n",
      "Epoch 5 Train batch 1050/1939 Loss=2.7562 Acc=40.10%\n",
      "Epoch 5 Train batch 1060/1939 Loss=2.7566 Acc=40.09%\n",
      "Epoch 5 Train batch 1070/1939 Loss=2.7570 Acc=40.09%\n",
      "Epoch 5 Train batch 1080/1939 Loss=2.7572 Acc=40.09%\n",
      "Epoch 5 Train batch 1090/1939 Loss=2.7576 Acc=40.10%\n",
      "Epoch 5 Train batch 1100/1939 Loss=2.7582 Acc=40.09%\n",
      "Epoch 5 Train batch 1110/1939 Loss=2.7585 Acc=40.10%\n",
      "Epoch 5 Train batch 1120/1939 Loss=2.7583 Acc=40.10%\n",
      "Epoch 5 Train batch 1130/1939 Loss=2.7581 Acc=40.11%\n",
      "Epoch 5 Train batch 1140/1939 Loss=2.7583 Acc=40.10%\n",
      "Epoch 5 Train batch 1150/1939 Loss=2.7582 Acc=40.10%\n",
      "Epoch 5 Train batch 1160/1939 Loss=2.7587 Acc=40.10%\n",
      "Epoch 5 Train batch 1170/1939 Loss=2.7591 Acc=40.10%\n",
      "Epoch 5 Train batch 1180/1939 Loss=2.7602 Acc=40.09%\n",
      "Epoch 5 Train batch 1190/1939 Loss=2.7609 Acc=40.08%\n",
      "Epoch 5 Train batch 1200/1939 Loss=2.7609 Acc=40.08%\n",
      "Epoch 5 Train batch 1210/1939 Loss=2.7611 Acc=40.08%\n",
      "Epoch 5 Train batch 1220/1939 Loss=2.7619 Acc=40.07%\n",
      "Epoch 5 Train batch 1230/1939 Loss=2.7621 Acc=40.07%\n",
      "Epoch 5 Train batch 1240/1939 Loss=2.7623 Acc=40.07%\n",
      "Epoch 5 Train batch 1250/1939 Loss=2.7628 Acc=40.07%\n",
      "Epoch 5 Train batch 1260/1939 Loss=2.7630 Acc=40.06%\n",
      "Epoch 5 Train batch 1270/1939 Loss=2.7636 Acc=40.06%\n",
      "Epoch 5 Train batch 1280/1939 Loss=2.7637 Acc=40.06%\n",
      "Epoch 5 Train batch 1290/1939 Loss=2.7638 Acc=40.06%\n",
      "Epoch 5 Train batch 1300/1939 Loss=2.7640 Acc=40.06%\n",
      "Epoch 5 Train batch 1310/1939 Loss=2.7646 Acc=40.05%\n",
      "Epoch 5 Train batch 1320/1939 Loss=2.7644 Acc=40.06%\n",
      "Epoch 5 Train batch 1330/1939 Loss=2.7642 Acc=40.06%\n",
      "Epoch 5 Train batch 1340/1939 Loss=2.7645 Acc=40.05%\n",
      "Epoch 5 Train batch 1350/1939 Loss=2.7645 Acc=40.06%\n",
      "Epoch 5 Train batch 1360/1939 Loss=2.7649 Acc=40.05%\n",
      "Epoch 5 Train batch 1370/1939 Loss=2.7650 Acc=40.05%\n",
      "Epoch 5 Train batch 1380/1939 Loss=2.7654 Acc=40.05%\n",
      "Epoch 5 Train batch 1390/1939 Loss=2.7657 Acc=40.04%\n",
      "Epoch 5 Train batch 1400/1939 Loss=2.7658 Acc=40.04%\n",
      "Epoch 5 Train batch 1410/1939 Loss=2.7660 Acc=40.04%\n",
      "Epoch 5 Train batch 1420/1939 Loss=2.7663 Acc=40.04%\n",
      "Epoch 5 Train batch 1430/1939 Loss=2.7661 Acc=40.04%\n",
      "Epoch 5 Train batch 1440/1939 Loss=2.7666 Acc=40.04%\n",
      "Epoch 5 Train batch 1450/1939 Loss=2.7668 Acc=40.04%\n",
      "Epoch 5 Train batch 1460/1939 Loss=2.7672 Acc=40.03%\n",
      "Epoch 5 Train batch 1470/1939 Loss=2.7672 Acc=40.04%\n",
      "Epoch 5 Train batch 1480/1939 Loss=2.7677 Acc=40.03%\n",
      "Epoch 5 Train batch 1490/1939 Loss=2.7681 Acc=40.03%\n",
      "Epoch 5 Train batch 1500/1939 Loss=2.7683 Acc=40.03%\n",
      "Epoch 5 Train batch 1510/1939 Loss=2.7684 Acc=40.03%\n",
      "Epoch 5 Train batch 1520/1939 Loss=2.7687 Acc=40.03%\n",
      "Epoch 5 Train batch 1530/1939 Loss=2.7691 Acc=40.02%\n",
      "Epoch 5 Train batch 1540/1939 Loss=2.7694 Acc=40.02%\n",
      "Epoch 5 Train batch 1550/1939 Loss=2.7696 Acc=40.02%\n",
      "Epoch 5 Train batch 1560/1939 Loss=2.7697 Acc=40.02%\n",
      "Epoch 5 Train batch 1570/1939 Loss=2.7698 Acc=40.02%\n",
      "Epoch 5 Train batch 1580/1939 Loss=2.7703 Acc=40.02%\n",
      "Epoch 5 Train batch 1590/1939 Loss=2.7708 Acc=40.01%\n",
      "Epoch 5 Train batch 1600/1939 Loss=2.7709 Acc=40.01%\n",
      "Epoch 5 Train batch 1610/1939 Loss=2.7713 Acc=40.01%\n",
      "Epoch 5 Train batch 1620/1939 Loss=2.7716 Acc=40.01%\n",
      "Epoch 5 Train batch 1630/1939 Loss=2.7718 Acc=40.01%\n",
      "Epoch 5 Train batch 1640/1939 Loss=2.7722 Acc=40.00%\n",
      "Epoch 5 Train batch 1650/1939 Loss=2.7725 Acc=40.00%\n",
      "Epoch 5 Train batch 1660/1939 Loss=2.7727 Acc=40.00%\n",
      "Epoch 5 Train batch 1670/1939 Loss=2.7730 Acc=40.00%\n",
      "Epoch 5 Train batch 1680/1939 Loss=2.7731 Acc=40.00%\n",
      "Epoch 5 Train batch 1690/1939 Loss=2.7734 Acc=40.00%\n",
      "Epoch 5 Train batch 1700/1939 Loss=2.7737 Acc=40.00%\n",
      "Epoch 5 Train batch 1710/1939 Loss=2.7738 Acc=39.99%\n",
      "Epoch 5 Train batch 1720/1939 Loss=2.7739 Acc=39.99%\n",
      "Epoch 5 Train batch 1730/1939 Loss=2.7741 Acc=39.99%\n",
      "Epoch 5 Train batch 1740/1939 Loss=2.7741 Acc=39.99%\n",
      "Epoch 5 Train batch 1750/1939 Loss=2.7745 Acc=39.99%\n",
      "Epoch 5 Train batch 1760/1939 Loss=2.7750 Acc=39.98%\n",
      "Epoch 5 Train batch 1770/1939 Loss=2.7751 Acc=39.98%\n",
      "Epoch 5 Train batch 1780/1939 Loss=2.7754 Acc=39.98%\n",
      "Epoch 5 Train batch 1790/1939 Loss=2.7758 Acc=39.98%\n",
      "Epoch 5 Train batch 1800/1939 Loss=2.7762 Acc=39.98%\n",
      "Epoch 5 Train batch 1810/1939 Loss=2.7763 Acc=39.98%\n",
      "Epoch 5 Train batch 1820/1939 Loss=2.7765 Acc=39.98%\n",
      "Epoch 5 Train batch 1830/1939 Loss=2.7769 Acc=39.98%\n",
      "Epoch 5 Train batch 1840/1939 Loss=2.7774 Acc=39.97%\n",
      "Epoch 5 Train batch 1850/1939 Loss=2.7777 Acc=39.97%\n",
      "Epoch 5 Train batch 1860/1939 Loss=2.7776 Acc=39.97%\n",
      "Epoch 5 Train batch 1870/1939 Loss=2.7778 Acc=39.97%\n",
      "Epoch 5 Train batch 1880/1939 Loss=2.7778 Acc=39.98%\n",
      "Epoch 5 Train batch 1890/1939 Loss=2.7780 Acc=39.98%\n",
      "Epoch 5 Train batch 1900/1939 Loss=2.7781 Acc=39.98%\n",
      "Epoch 5 Train batch 1910/1939 Loss=2.7783 Acc=39.98%\n",
      "Epoch 5 Train batch 1920/1939 Loss=2.7790 Acc=39.97%\n",
      "Epoch 5 Train batch 1930/1939 Loss=2.7792 Acc=39.97%\n",
      "Epoch 5 Train batch 1939/1939 Loss=2.7794 Acc=39.97%\n",
      "Epoch 5/5 train_loss=2.7794 train_acc=39.97% val_loss=3.0031 val_acc=39.72%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model 2: ViT trained from scratch",
   "id": "82eb4f9c519c051"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Image caption model with transformers trained from scratch.\n",
    "\n",
    "Encoder: Visual transformer (ViT), no transfer learning.\n",
    "\n",
    "Decoder: Small text transformer, no transfer learning."
   ],
   "id": "48aaf7e1f14ee57c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-21T12:31:33.257299Z",
     "start_time": "2025-10-21T10:04:28.223023Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------- Encoder: ---------------\n",
    "\n",
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\"Simple patch embedding: conv with stride=patch_size.\"\"\"\n",
    "    def __init__(self, in_ch=3, embed_dim=256, patch_size=16):\n",
    "        super().__init__()\n",
    "        assert embed_dim % 1 == 0\n",
    "        self.proj = nn.Conv2d(in_ch, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, H, W)\n",
    "        x = self.proj(x)                     # (B, E, Hp, Wp)\n",
    "        x = x.flatten(2).transpose(1, 2)     # (B, S, E) where S = Hp*Wp\n",
    "        return x\n",
    "\n",
    "\n",
    "class ViTEncoder(nn.Module):\n",
    "    def __init__(self, embed_dim=256, patch_size=16, num_layers=4, num_heads=4, mlp_dim=512, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbed(in_ch=3, embed_dim=embed_dim, patch_size=patch_size)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1,1,embed_dim))\n",
    "        self.pos_embed = None  # created lazily based on sequence length\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=mlp_dim, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B,C,H,W)\n",
    "        x = self.patch_embed(x)   # (B, S, E)\n",
    "        B, S, E = x.shape\n",
    "        if self.pos_embed is None or self.pos_embed.size(1) != (S+1):\n",
    "            # initialize positional embedding (1, S+1, E)\n",
    "            self.pos_embed = nn.Parameter(torch.zeros(1, S+1, E).to(x.device))\n",
    "            nn.init.trunc_normal_(self.pos_embed, std=0.02)\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)  # (B,1,E)\n",
    "        x = torch.cat([cls_tokens, x], dim=1)          # (B, S+1, E)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.transformer_encoder(x)                # (B, S+1, E)\n",
    "        x = self.norm(x)\n",
    "        cls_out = x[:, 0]                              # (B, E) - pooled\n",
    "        return cls_out\n",
    "\n",
    "# --------------- Decoder: ---------------\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(1)  # (max_len, 1, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (T, B, D)\n",
    "        seq_len = x.size(0)\n",
    "        return x + self.pe[:seq_len, :]\n",
    "\n",
    "\n",
    "class TransformerDecoderAdapter(DecoderBase):\n",
    "    def __init__(self, embed_size, vocab_size, nhead=8, num_layers=3, dim_feedforward=2048, dropout=0.2, max_len=50):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.pos_enc = PositionalEncoding(embed_size, max_len=max_len)\n",
    "        self.feature_proj = nn.Linear(embed_size, embed_size)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=embed_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=False)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "        self.linear_out = nn.Linear(embed_size, vocab_size)\n",
    "        self.embed_size = embed_size\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz, device):\n",
    "        mask = torch.triu(torch.ones(sz, sz, device=device) * float('-inf'), diagonal=1)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        # features: (B, E)\n",
    "        device = features.device\n",
    "        B, L = captions.size()\n",
    "        memory = self.feature_proj(features).unsqueeze(0)  # (1, B, E)\n",
    "        tgt = self.embed(captions).permute(1, 0, 2)        # (L, B, E)\n",
    "        tgt = self.pos_enc(tgt)\n",
    "        tgt_mask = self._generate_square_subsequent_mask(L, device)\n",
    "        out = self.transformer_decoder(tgt, memory, tgt_mask=tgt_mask)  # (L, B, E)\n",
    "        out = out.permute(1, 0, 2)  # (B, L, E)\n",
    "        logits = self.linear_out(out)  # (B, L, V)\n",
    "        return logits\n",
    "\n",
    "    def sample(self, features, start_id=None, max_len=None):\n",
    "        if max_len is None:\n",
    "            max_len = self.max_len\n",
    "        assert start_id is not None, \"start_id must be provided for transformer sampling\"\n",
    "        device = features.device\n",
    "        B = features.size(0)\n",
    "        memory = self.feature_proj(features).unsqueeze(0)  # (1, B, E)\n",
    "        generated = torch.full((B, 1), fill_value=start_id, dtype=torch.long, device=device)\n",
    "        ids = []\n",
    "        for t in range(max_len):\n",
    "            tgt = self.embed(generated).permute(1, 0, 2)   # (T, B, E)\n",
    "            tgt = self.pos_enc(tgt)\n",
    "            tgt_mask = self._generate_square_subsequent_mask(tgt.size(0), device)\n",
    "            out = self.transformer_decoder(tgt, memory, tgt_mask=tgt_mask)  # (T, B, E)\n",
    "            last = out[-1]  # (B, E)\n",
    "            logits = self.linear_out(last)  # (B, V)\n",
    "            pred = logits.argmax(dim=1)     # (B,)\n",
    "            ids.append(pred)\n",
    "            generated = torch.cat([generated, pred.unsqueeze(1)], dim=1)\n",
    "        ids = torch.stack(ids, dim=1)  # (B, max_len)\n",
    "        return ids\n",
    "\n",
    "# --------------- Training: ---------------\n",
    "\n",
    "clear_cache()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "ENC_LR = 5e-5\n",
    "DEC_LR = 1e-4\n",
    "DROPOUT = 0.2\n",
    "\n",
    "EMBED_SIZE = 768\n",
    "ENC_NUM_LAYERS = 6\n",
    "DEC_NUM_LAYERS = 3\n",
    "NUM_HEADS = 8\n",
    "DIM_FEEDFORWARD = 2048\n",
    "\n",
    "OUTPUT_DIR = \"./models_vit_no_tl\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "# Instantiate models\n",
    "enc = ViTEncoder(\n",
    "    embed_dim=EMBED_SIZE,\n",
    "    patch_size=16,\n",
    "    num_layers=ENC_NUM_LAYERS,\n",
    "    num_heads=NUM_HEADS,\n",
    "    mlp_dim=DIM_FEEDFORWARD,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "dec = TransformerDecoderAdapter(\n",
    "    embed_size=EMBED_SIZE,\n",
    "    vocab_size=len(vocab),\n",
    "    nhead=NUM_HEADS,\n",
    "    num_layers=DEC_NUM_LAYERS,\n",
    "    dim_feedforward=DIM_FEEDFORWARD,\n",
    "    dropout=DROPOUT,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "# Optimizers and loss\n",
    "enc_opt = optim.Adam(enc.parameters(), lr=ENC_LR)\n",
    "dec_opt = optim.Adam(dec.parameters(), lr=DEC_LR)\n",
    "\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "\n",
    "# Train\n",
    "history = fit_model(\n",
    "    enc=enc, dec=dec,\n",
    "    train_loader=train_loader, val_loader=val_loader,\n",
    "    enc_opt=enc_opt, dec_opt=dec_opt,\n",
    "    device=DEVICE,\n",
    "    vocab=vocab,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_epochs=NUM_EPOCHS\n",
    ")"
   ],
   "id": "3e4340c01d6f5a1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 6989\n",
      "Epoch 1 Train batch 10/3877 Loss=7.3667 Acc=11.46%\n",
      "Epoch 1 Train batch 20/3877 Loss=6.8680 Acc=13.04%\n",
      "Epoch 1 Train batch 30/3877 Loss=6.5542 Acc=14.46%\n",
      "Epoch 1 Train batch 40/3877 Loss=6.3288 Acc=15.52%\n",
      "Epoch 1 Train batch 50/3877 Loss=6.1537 Acc=16.47%\n",
      "Epoch 1 Train batch 60/3877 Loss=6.0051 Acc=17.20%\n",
      "Epoch 1 Train batch 70/3877 Loss=5.8712 Acc=17.88%\n",
      "Epoch 1 Train batch 80/3877 Loss=5.7756 Acc=18.54%\n",
      "Epoch 1 Train batch 90/3877 Loss=5.6883 Acc=19.06%\n",
      "Epoch 1 Train batch 100/3877 Loss=5.6142 Acc=19.67%\n",
      "Epoch 1 Train batch 110/3877 Loss=5.5442 Acc=20.14%\n",
      "Epoch 1 Train batch 120/3877 Loss=5.4803 Acc=20.59%\n",
      "Epoch 1 Train batch 130/3877 Loss=5.4160 Acc=21.06%\n",
      "Epoch 1 Train batch 140/3877 Loss=5.3679 Acc=21.41%\n",
      "Epoch 1 Train batch 150/3877 Loss=5.3183 Acc=21.81%\n",
      "Epoch 1 Train batch 160/3877 Loss=5.2825 Acc=22.08%\n",
      "Epoch 1 Train batch 170/3877 Loss=5.2438 Acc=22.36%\n",
      "Epoch 1 Train batch 180/3877 Loss=5.2044 Acc=22.67%\n",
      "Epoch 1 Train batch 190/3877 Loss=5.1720 Acc=22.88%\n",
      "Epoch 1 Train batch 200/3877 Loss=5.1441 Acc=23.10%\n",
      "Epoch 1 Train batch 210/3877 Loss=5.1147 Acc=23.33%\n",
      "Epoch 1 Train batch 220/3877 Loss=5.0868 Acc=23.52%\n",
      "Epoch 1 Train batch 230/3877 Loss=5.0603 Acc=23.72%\n",
      "Epoch 1 Train batch 240/3877 Loss=5.0356 Acc=23.88%\n",
      "Epoch 1 Train batch 250/3877 Loss=5.0091 Acc=24.05%\n",
      "Epoch 1 Train batch 260/3877 Loss=4.9808 Acc=24.22%\n",
      "Epoch 1 Train batch 270/3877 Loss=4.9626 Acc=24.32%\n",
      "Epoch 1 Train batch 280/3877 Loss=4.9401 Acc=24.49%\n",
      "Epoch 1 Train batch 290/3877 Loss=4.9225 Acc=24.59%\n",
      "Epoch 1 Train batch 300/3877 Loss=4.8991 Acc=24.73%\n",
      "Epoch 1 Train batch 310/3877 Loss=4.8852 Acc=24.81%\n",
      "Epoch 1 Train batch 320/3877 Loss=4.8658 Acc=24.95%\n",
      "Epoch 1 Train batch 330/3877 Loss=4.8486 Acc=25.05%\n",
      "Epoch 1 Train batch 340/3877 Loss=4.8319 Acc=25.15%\n",
      "Epoch 1 Train batch 350/3877 Loss=4.8159 Acc=25.29%\n",
      "Epoch 1 Train batch 360/3877 Loss=4.7990 Acc=25.41%\n",
      "Epoch 1 Train batch 370/3877 Loss=4.7868 Acc=25.51%\n",
      "Epoch 1 Train batch 380/3877 Loss=4.7722 Acc=25.60%\n",
      "Epoch 1 Train batch 390/3877 Loss=4.7570 Acc=25.72%\n",
      "Epoch 1 Train batch 400/3877 Loss=4.7418 Acc=25.85%\n",
      "Epoch 1 Train batch 410/3877 Loss=4.7302 Acc=25.92%\n",
      "Epoch 1 Train batch 420/3877 Loss=4.7183 Acc=25.98%\n",
      "Epoch 1 Train batch 430/3877 Loss=4.7094 Acc=26.02%\n",
      "Epoch 1 Train batch 440/3877 Loss=4.6991 Acc=26.09%\n",
      "Epoch 1 Train batch 450/3877 Loss=4.6852 Acc=26.18%\n",
      "Epoch 1 Train batch 460/3877 Loss=4.6750 Acc=26.25%\n",
      "Epoch 1 Train batch 470/3877 Loss=4.6635 Acc=26.33%\n",
      "Epoch 1 Train batch 480/3877 Loss=4.6528 Acc=26.41%\n",
      "Epoch 1 Train batch 490/3877 Loss=4.6418 Acc=26.48%\n",
      "Epoch 1 Train batch 500/3877 Loss=4.6322 Acc=26.53%\n",
      "Epoch 1 Train batch 510/3877 Loss=4.6230 Acc=26.59%\n",
      "Epoch 1 Train batch 520/3877 Loss=4.6139 Acc=26.65%\n",
      "Epoch 1 Train batch 530/3877 Loss=4.6054 Acc=26.70%\n",
      "Epoch 1 Train batch 540/3877 Loss=4.5962 Acc=26.77%\n",
      "Epoch 1 Train batch 550/3877 Loss=4.5856 Acc=26.85%\n",
      "Epoch 1 Train batch 560/3877 Loss=4.5753 Acc=26.94%\n",
      "Epoch 1 Train batch 570/3877 Loss=4.5679 Acc=26.98%\n",
      "Epoch 1 Train batch 580/3877 Loss=4.5586 Acc=27.05%\n",
      "Epoch 1 Train batch 590/3877 Loss=4.5495 Acc=27.12%\n",
      "Epoch 1 Train batch 600/3877 Loss=4.5411 Acc=27.17%\n",
      "Epoch 1 Train batch 610/3877 Loss=4.5331 Acc=27.22%\n",
      "Epoch 1 Train batch 620/3877 Loss=4.5264 Acc=27.26%\n",
      "Epoch 1 Train batch 630/3877 Loss=4.5187 Acc=27.31%\n",
      "Epoch 1 Train batch 640/3877 Loss=4.5127 Acc=27.35%\n",
      "Epoch 1 Train batch 650/3877 Loss=4.5062 Acc=27.39%\n",
      "Epoch 1 Train batch 660/3877 Loss=4.4984 Acc=27.46%\n",
      "Epoch 1 Train batch 670/3877 Loss=4.4922 Acc=27.51%\n",
      "Epoch 1 Train batch 680/3877 Loss=4.4860 Acc=27.54%\n",
      "Epoch 1 Train batch 690/3877 Loss=4.4800 Acc=27.57%\n",
      "Epoch 1 Train batch 700/3877 Loss=4.4729 Acc=27.63%\n",
      "Epoch 1 Train batch 710/3877 Loss=4.4648 Acc=27.69%\n",
      "Epoch 1 Train batch 720/3877 Loss=4.4581 Acc=27.74%\n",
      "Epoch 1 Train batch 730/3877 Loss=4.4524 Acc=27.77%\n",
      "Epoch 1 Train batch 740/3877 Loss=4.4471 Acc=27.82%\n",
      "Epoch 1 Train batch 750/3877 Loss=4.4421 Acc=27.85%\n",
      "Epoch 1 Train batch 760/3877 Loss=4.4356 Acc=27.89%\n",
      "Epoch 1 Train batch 770/3877 Loss=4.4303 Acc=27.93%\n",
      "Epoch 1 Train batch 780/3877 Loss=4.4247 Acc=27.96%\n",
      "Epoch 1 Train batch 790/3877 Loss=4.4183 Acc=28.01%\n",
      "Epoch 1 Train batch 800/3877 Loss=4.4127 Acc=28.03%\n",
      "Epoch 1 Train batch 810/3877 Loss=4.4093 Acc=28.05%\n",
      "Epoch 1 Train batch 820/3877 Loss=4.4042 Acc=28.09%\n",
      "Epoch 1 Train batch 830/3877 Loss=4.3989 Acc=28.12%\n",
      "Epoch 1 Train batch 840/3877 Loss=4.3942 Acc=28.13%\n",
      "Epoch 1 Train batch 850/3877 Loss=4.3896 Acc=28.16%\n",
      "Epoch 1 Train batch 860/3877 Loss=4.3839 Acc=28.20%\n",
      "Epoch 1 Train batch 870/3877 Loss=4.3787 Acc=28.23%\n",
      "Epoch 1 Train batch 880/3877 Loss=4.3736 Acc=28.28%\n",
      "Epoch 1 Train batch 890/3877 Loss=4.3681 Acc=28.31%\n",
      "Epoch 1 Train batch 900/3877 Loss=4.3623 Acc=28.35%\n",
      "Epoch 1 Train batch 910/3877 Loss=4.3576 Acc=28.39%\n",
      "Epoch 1 Train batch 920/3877 Loss=4.3528 Acc=28.42%\n",
      "Epoch 1 Train batch 930/3877 Loss=4.3478 Acc=28.45%\n",
      "Epoch 1 Train batch 940/3877 Loss=4.3447 Acc=28.47%\n",
      "Epoch 1 Train batch 950/3877 Loss=4.3399 Acc=28.50%\n",
      "Epoch 1 Train batch 960/3877 Loss=4.3359 Acc=28.52%\n",
      "Epoch 1 Train batch 970/3877 Loss=4.3314 Acc=28.55%\n",
      "Epoch 1 Train batch 980/3877 Loss=4.3270 Acc=28.58%\n",
      "Epoch 1 Train batch 990/3877 Loss=4.3232 Acc=28.60%\n",
      "Epoch 1 Train batch 1000/3877 Loss=4.3186 Acc=28.63%\n",
      "Epoch 1 Train batch 1010/3877 Loss=4.3143 Acc=28.65%\n",
      "Epoch 1 Train batch 1020/3877 Loss=4.3102 Acc=28.68%\n",
      "Epoch 1 Train batch 1030/3877 Loss=4.3060 Acc=28.71%\n",
      "Epoch 1 Train batch 1040/3877 Loss=4.3020 Acc=28.73%\n",
      "Epoch 1 Train batch 1050/3877 Loss=4.2982 Acc=28.75%\n",
      "Epoch 1 Train batch 1060/3877 Loss=4.2945 Acc=28.77%\n",
      "Epoch 1 Train batch 1070/3877 Loss=4.2910 Acc=28.79%\n",
      "Epoch 1 Train batch 1080/3877 Loss=4.2871 Acc=28.83%\n",
      "Epoch 1 Train batch 1090/3877 Loss=4.2836 Acc=28.86%\n",
      "Epoch 1 Train batch 1100/3877 Loss=4.2793 Acc=28.90%\n",
      "Epoch 1 Train batch 1110/3877 Loss=4.2756 Acc=28.91%\n",
      "Epoch 1 Train batch 1120/3877 Loss=4.2727 Acc=28.93%\n",
      "Epoch 1 Train batch 1130/3877 Loss=4.2692 Acc=28.96%\n",
      "Epoch 1 Train batch 1140/3877 Loss=4.2646 Acc=28.99%\n",
      "Epoch 1 Train batch 1150/3877 Loss=4.2618 Acc=29.01%\n",
      "Epoch 1 Train batch 1160/3877 Loss=4.2587 Acc=29.03%\n",
      "Epoch 1 Train batch 1170/3877 Loss=4.2549 Acc=29.05%\n",
      "Epoch 1 Train batch 1180/3877 Loss=4.2521 Acc=29.06%\n",
      "Epoch 1 Train batch 1190/3877 Loss=4.2487 Acc=29.09%\n",
      "Epoch 1 Train batch 1200/3877 Loss=4.2454 Acc=29.10%\n",
      "Epoch 1 Train batch 1210/3877 Loss=4.2427 Acc=29.12%\n",
      "Epoch 1 Train batch 1220/3877 Loss=4.2385 Acc=29.15%\n",
      "Epoch 1 Train batch 1230/3877 Loss=4.2354 Acc=29.17%\n",
      "Epoch 1 Train batch 1240/3877 Loss=4.2319 Acc=29.19%\n",
      "Epoch 1 Train batch 1250/3877 Loss=4.2290 Acc=29.22%\n",
      "Epoch 1 Train batch 1260/3877 Loss=4.2258 Acc=29.24%\n",
      "Epoch 1 Train batch 1270/3877 Loss=4.2218 Acc=29.26%\n",
      "Epoch 1 Train batch 1280/3877 Loss=4.2187 Acc=29.28%\n",
      "Epoch 1 Train batch 1290/3877 Loss=4.2153 Acc=29.30%\n",
      "Epoch 1 Train batch 1300/3877 Loss=4.2122 Acc=29.32%\n",
      "Epoch 1 Train batch 1310/3877 Loss=4.2097 Acc=29.33%\n",
      "Epoch 1 Train batch 1320/3877 Loss=4.2060 Acc=29.36%\n",
      "Epoch 1 Train batch 1330/3877 Loss=4.2029 Acc=29.38%\n",
      "Epoch 1 Train batch 1340/3877 Loss=4.1997 Acc=29.41%\n",
      "Epoch 1 Train batch 1350/3877 Loss=4.1961 Acc=29.43%\n",
      "Epoch 1 Train batch 1360/3877 Loss=4.1930 Acc=29.46%\n",
      "Epoch 1 Train batch 1370/3877 Loss=4.1896 Acc=29.48%\n",
      "Epoch 1 Train batch 1380/3877 Loss=4.1865 Acc=29.50%\n",
      "Epoch 1 Train batch 1390/3877 Loss=4.1835 Acc=29.52%\n",
      "Epoch 1 Train batch 1400/3877 Loss=4.1806 Acc=29.54%\n",
      "Epoch 1 Train batch 1410/3877 Loss=4.1779 Acc=29.56%\n",
      "Epoch 1 Train batch 1420/3877 Loss=4.1746 Acc=29.58%\n",
      "Epoch 1 Train batch 1430/3877 Loss=4.1715 Acc=29.61%\n",
      "Epoch 1 Train batch 1440/3877 Loss=4.1694 Acc=29.62%\n",
      "Epoch 1 Train batch 1450/3877 Loss=4.1662 Acc=29.64%\n",
      "Epoch 1 Train batch 1460/3877 Loss=4.1633 Acc=29.66%\n",
      "Epoch 1 Train batch 1470/3877 Loss=4.1605 Acc=29.68%\n",
      "Epoch 1 Train batch 1480/3877 Loss=4.1575 Acc=29.70%\n",
      "Epoch 1 Train batch 1490/3877 Loss=4.1546 Acc=29.73%\n",
      "Epoch 1 Train batch 1500/3877 Loss=4.1524 Acc=29.74%\n",
      "Epoch 1 Train batch 1510/3877 Loss=4.1496 Acc=29.76%\n",
      "Epoch 1 Train batch 1520/3877 Loss=4.1466 Acc=29.78%\n",
      "Epoch 1 Train batch 1530/3877 Loss=4.1439 Acc=29.80%\n",
      "Epoch 1 Train batch 1540/3877 Loss=4.1418 Acc=29.82%\n",
      "Epoch 1 Train batch 1550/3877 Loss=4.1391 Acc=29.84%\n",
      "Epoch 1 Train batch 1560/3877 Loss=4.1361 Acc=29.86%\n",
      "Epoch 1 Train batch 1570/3877 Loss=4.1343 Acc=29.86%\n",
      "Epoch 1 Train batch 1580/3877 Loss=4.1310 Acc=29.89%\n",
      "Epoch 1 Train batch 1590/3877 Loss=4.1288 Acc=29.91%\n",
      "Epoch 1 Train batch 1600/3877 Loss=4.1268 Acc=29.92%\n",
      "Epoch 1 Train batch 1610/3877 Loss=4.1244 Acc=29.94%\n",
      "Epoch 1 Train batch 1620/3877 Loss=4.1217 Acc=29.96%\n",
      "Epoch 1 Train batch 1630/3877 Loss=4.1196 Acc=29.97%\n",
      "Epoch 1 Train batch 1640/3877 Loss=4.1177 Acc=29.98%\n",
      "Epoch 1 Train batch 1650/3877 Loss=4.1150 Acc=30.00%\n",
      "Epoch 1 Train batch 1660/3877 Loss=4.1128 Acc=30.01%\n",
      "Epoch 1 Train batch 1670/3877 Loss=4.1107 Acc=30.02%\n",
      "Epoch 1 Train batch 1680/3877 Loss=4.1083 Acc=30.04%\n",
      "Epoch 1 Train batch 1690/3877 Loss=4.1057 Acc=30.06%\n",
      "Epoch 1 Train batch 1700/3877 Loss=4.1031 Acc=30.07%\n",
      "Epoch 1 Train batch 1710/3877 Loss=4.1012 Acc=30.08%\n",
      "Epoch 1 Train batch 1720/3877 Loss=4.0984 Acc=30.10%\n",
      "Epoch 1 Train batch 1730/3877 Loss=4.0962 Acc=30.12%\n",
      "Epoch 1 Train batch 1740/3877 Loss=4.0939 Acc=30.13%\n",
      "Epoch 1 Train batch 1750/3877 Loss=4.0916 Acc=30.14%\n",
      "Epoch 1 Train batch 1760/3877 Loss=4.0891 Acc=30.16%\n",
      "Epoch 1 Train batch 1770/3877 Loss=4.0866 Acc=30.18%\n",
      "Epoch 1 Train batch 1780/3877 Loss=4.0842 Acc=30.20%\n",
      "Epoch 1 Train batch 1790/3877 Loss=4.0817 Acc=30.21%\n",
      "Epoch 1 Train batch 1800/3877 Loss=4.0798 Acc=30.23%\n",
      "Epoch 1 Train batch 1810/3877 Loss=4.0771 Acc=30.25%\n",
      "Epoch 1 Train batch 1820/3877 Loss=4.0744 Acc=30.27%\n",
      "Epoch 1 Train batch 1830/3877 Loss=4.0720 Acc=30.29%\n",
      "Epoch 1 Train batch 1840/3877 Loss=4.0703 Acc=30.31%\n",
      "Epoch 1 Train batch 1850/3877 Loss=4.0680 Acc=30.32%\n",
      "Epoch 1 Train batch 1860/3877 Loss=4.0656 Acc=30.34%\n",
      "Epoch 1 Train batch 1870/3877 Loss=4.0637 Acc=30.35%\n",
      "Epoch 1 Train batch 1880/3877 Loss=4.0625 Acc=30.36%\n",
      "Epoch 1 Train batch 1890/3877 Loss=4.0607 Acc=30.37%\n",
      "Epoch 1 Train batch 1900/3877 Loss=4.0585 Acc=30.39%\n",
      "Epoch 1 Train batch 1910/3877 Loss=4.0559 Acc=30.41%\n",
      "Epoch 1 Train batch 1920/3877 Loss=4.0532 Acc=30.43%\n",
      "Epoch 1 Train batch 1930/3877 Loss=4.0513 Acc=30.44%\n",
      "Epoch 1 Train batch 1940/3877 Loss=4.0498 Acc=30.45%\n",
      "Epoch 1 Train batch 1950/3877 Loss=4.0482 Acc=30.46%\n",
      "Epoch 1 Train batch 1960/3877 Loss=4.0461 Acc=30.47%\n",
      "Epoch 1 Train batch 1970/3877 Loss=4.0440 Acc=30.48%\n",
      "Epoch 1 Train batch 1980/3877 Loss=4.0422 Acc=30.50%\n",
      "Epoch 1 Train batch 1990/3877 Loss=4.0401 Acc=30.51%\n",
      "Epoch 1 Train batch 2000/3877 Loss=4.0385 Acc=30.53%\n",
      "Epoch 1 Train batch 2010/3877 Loss=4.0364 Acc=30.54%\n",
      "Epoch 1 Train batch 2020/3877 Loss=4.0345 Acc=30.55%\n",
      "Epoch 1 Train batch 2030/3877 Loss=4.0328 Acc=30.56%\n",
      "Epoch 1 Train batch 2040/3877 Loss=4.0309 Acc=30.57%\n",
      "Epoch 1 Train batch 2050/3877 Loss=4.0292 Acc=30.58%\n",
      "Epoch 1 Train batch 2060/3877 Loss=4.0274 Acc=30.59%\n",
      "Epoch 1 Train batch 2070/3877 Loss=4.0255 Acc=30.61%\n",
      "Epoch 1 Train batch 2080/3877 Loss=4.0239 Acc=30.62%\n",
      "Epoch 1 Train batch 2090/3877 Loss=4.0220 Acc=30.63%\n",
      "Epoch 1 Train batch 2100/3877 Loss=4.0206 Acc=30.64%\n",
      "Epoch 1 Train batch 2110/3877 Loss=4.0188 Acc=30.65%\n",
      "Epoch 1 Train batch 2120/3877 Loss=4.0172 Acc=30.66%\n",
      "Epoch 1 Train batch 2130/3877 Loss=4.0159 Acc=30.67%\n",
      "Epoch 1 Train batch 2140/3877 Loss=4.0139 Acc=30.68%\n",
      "Epoch 1 Train batch 2150/3877 Loss=4.0121 Acc=30.69%\n",
      "Epoch 1 Train batch 2160/3877 Loss=4.0103 Acc=30.70%\n",
      "Epoch 1 Train batch 2170/3877 Loss=4.0085 Acc=30.71%\n",
      "Epoch 1 Train batch 2180/3877 Loss=4.0071 Acc=30.72%\n",
      "Epoch 1 Train batch 2190/3877 Loss=4.0055 Acc=30.74%\n",
      "Epoch 1 Train batch 2200/3877 Loss=4.0039 Acc=30.75%\n",
      "Epoch 1 Train batch 2210/3877 Loss=4.0023 Acc=30.76%\n",
      "Epoch 1 Train batch 2220/3877 Loss=4.0005 Acc=30.77%\n",
      "Epoch 1 Train batch 2230/3877 Loss=3.9987 Acc=30.79%\n",
      "Epoch 1 Train batch 2240/3877 Loss=3.9968 Acc=30.80%\n",
      "Epoch 1 Train batch 2250/3877 Loss=3.9947 Acc=30.82%\n",
      "Epoch 1 Train batch 2260/3877 Loss=3.9929 Acc=30.84%\n",
      "Epoch 1 Train batch 2270/3877 Loss=3.9913 Acc=30.85%\n",
      "Epoch 1 Train batch 2280/3877 Loss=3.9896 Acc=30.87%\n",
      "Epoch 1 Train batch 2290/3877 Loss=3.9884 Acc=30.87%\n",
      "Epoch 1 Train batch 2300/3877 Loss=3.9866 Acc=30.89%\n",
      "Epoch 1 Train batch 2310/3877 Loss=3.9850 Acc=30.90%\n",
      "Epoch 1 Train batch 2320/3877 Loss=3.9833 Acc=30.90%\n",
      "Epoch 1 Train batch 2330/3877 Loss=3.9817 Acc=30.92%\n",
      "Epoch 1 Train batch 2340/3877 Loss=3.9802 Acc=30.92%\n",
      "Epoch 1 Train batch 2350/3877 Loss=3.9784 Acc=30.94%\n",
      "Epoch 1 Train batch 2360/3877 Loss=3.9771 Acc=30.95%\n",
      "Epoch 1 Train batch 2370/3877 Loss=3.9756 Acc=30.96%\n",
      "Epoch 1 Train batch 2380/3877 Loss=3.9738 Acc=30.97%\n",
      "Epoch 1 Train batch 2390/3877 Loss=3.9721 Acc=30.98%\n",
      "Epoch 1 Train batch 2400/3877 Loss=3.9706 Acc=30.99%\n",
      "Epoch 1 Train batch 2410/3877 Loss=3.9689 Acc=31.00%\n",
      "Epoch 1 Train batch 2420/3877 Loss=3.9672 Acc=31.02%\n",
      "Epoch 1 Train batch 2430/3877 Loss=3.9652 Acc=31.03%\n",
      "Epoch 1 Train batch 2440/3877 Loss=3.9639 Acc=31.04%\n",
      "Epoch 1 Train batch 2450/3877 Loss=3.9624 Acc=31.05%\n",
      "Epoch 1 Train batch 2460/3877 Loss=3.9607 Acc=31.06%\n",
      "Epoch 1 Train batch 2470/3877 Loss=3.9591 Acc=31.07%\n",
      "Epoch 1 Train batch 2480/3877 Loss=3.9572 Acc=31.08%\n",
      "Epoch 1 Train batch 2490/3877 Loss=3.9556 Acc=31.09%\n",
      "Epoch 1 Train batch 2500/3877 Loss=3.9541 Acc=31.10%\n",
      "Epoch 1 Train batch 2510/3877 Loss=3.9526 Acc=31.11%\n",
      "Epoch 1 Train batch 2520/3877 Loss=3.9511 Acc=31.12%\n",
      "Epoch 1 Train batch 2530/3877 Loss=3.9498 Acc=31.13%\n",
      "Epoch 1 Train batch 2540/3877 Loss=3.9483 Acc=31.14%\n",
      "Epoch 1 Train batch 2550/3877 Loss=3.9467 Acc=31.16%\n",
      "Epoch 1 Train batch 2560/3877 Loss=3.9455 Acc=31.16%\n",
      "Epoch 1 Train batch 2570/3877 Loss=3.9441 Acc=31.17%\n",
      "Epoch 1 Train batch 2580/3877 Loss=3.9426 Acc=31.18%\n",
      "Epoch 1 Train batch 2590/3877 Loss=3.9410 Acc=31.19%\n",
      "Epoch 1 Train batch 2600/3877 Loss=3.9395 Acc=31.20%\n",
      "Epoch 1 Train batch 2610/3877 Loss=3.9382 Acc=31.21%\n",
      "Epoch 1 Train batch 2620/3877 Loss=3.9370 Acc=31.22%\n",
      "Epoch 1 Train batch 2630/3877 Loss=3.9352 Acc=31.24%\n",
      "Epoch 1 Train batch 2640/3877 Loss=3.9336 Acc=31.25%\n",
      "Epoch 1 Train batch 2650/3877 Loss=3.9324 Acc=31.26%\n",
      "Epoch 1 Train batch 2660/3877 Loss=3.9308 Acc=31.27%\n",
      "Epoch 1 Train batch 2670/3877 Loss=3.9297 Acc=31.28%\n",
      "Epoch 1 Train batch 2680/3877 Loss=3.9285 Acc=31.28%\n",
      "Epoch 1 Train batch 2690/3877 Loss=3.9270 Acc=31.30%\n",
      "Epoch 1 Train batch 2700/3877 Loss=3.9258 Acc=31.31%\n",
      "Epoch 1 Train batch 2710/3877 Loss=3.9246 Acc=31.31%\n",
      "Epoch 1 Train batch 2720/3877 Loss=3.9232 Acc=31.33%\n",
      "Epoch 1 Train batch 2730/3877 Loss=3.9221 Acc=31.34%\n",
      "Epoch 1 Train batch 2740/3877 Loss=3.9209 Acc=31.34%\n",
      "Epoch 1 Train batch 2750/3877 Loss=3.9194 Acc=31.35%\n",
      "Epoch 1 Train batch 2760/3877 Loss=3.9183 Acc=31.36%\n",
      "Epoch 1 Train batch 2770/3877 Loss=3.9169 Acc=31.37%\n",
      "Epoch 1 Train batch 2780/3877 Loss=3.9156 Acc=31.38%\n",
      "Epoch 1 Train batch 2790/3877 Loss=3.9139 Acc=31.39%\n",
      "Epoch 1 Train batch 2800/3877 Loss=3.9126 Acc=31.40%\n",
      "Epoch 1 Train batch 2810/3877 Loss=3.9111 Acc=31.41%\n",
      "Epoch 1 Train batch 2820/3877 Loss=3.9101 Acc=31.42%\n",
      "Epoch 1 Train batch 2830/3877 Loss=3.9089 Acc=31.43%\n",
      "Epoch 1 Train batch 2840/3877 Loss=3.9074 Acc=31.44%\n",
      "Epoch 1 Train batch 2850/3877 Loss=3.9059 Acc=31.45%\n",
      "Epoch 1 Train batch 2860/3877 Loss=3.9046 Acc=31.46%\n",
      "Epoch 1 Train batch 2870/3877 Loss=3.9034 Acc=31.46%\n",
      "Epoch 1 Train batch 2880/3877 Loss=3.9023 Acc=31.47%\n",
      "Epoch 1 Train batch 2890/3877 Loss=3.9010 Acc=31.49%\n",
      "Epoch 1 Train batch 2900/3877 Loss=3.8996 Acc=31.49%\n",
      "Epoch 1 Train batch 2910/3877 Loss=3.8985 Acc=31.50%\n",
      "Epoch 1 Train batch 2920/3877 Loss=3.8973 Acc=31.51%\n",
      "Epoch 1 Train batch 2930/3877 Loss=3.8961 Acc=31.52%\n",
      "Epoch 1 Train batch 2940/3877 Loss=3.8950 Acc=31.53%\n",
      "Epoch 1 Train batch 2950/3877 Loss=3.8937 Acc=31.54%\n",
      "Epoch 1 Train batch 2960/3877 Loss=3.8923 Acc=31.55%\n",
      "Epoch 1 Train batch 2970/3877 Loss=3.8911 Acc=31.56%\n",
      "Epoch 1 Train batch 2980/3877 Loss=3.8900 Acc=31.57%\n",
      "Epoch 1 Train batch 2990/3877 Loss=3.8887 Acc=31.58%\n",
      "Epoch 1 Train batch 3000/3877 Loss=3.8875 Acc=31.59%\n",
      "Epoch 1 Train batch 3010/3877 Loss=3.8860 Acc=31.60%\n",
      "Epoch 1 Train batch 3020/3877 Loss=3.8848 Acc=31.60%\n",
      "Epoch 1 Train batch 3030/3877 Loss=3.8832 Acc=31.62%\n",
      "Epoch 1 Train batch 3040/3877 Loss=3.8820 Acc=31.62%\n",
      "Epoch 1 Train batch 3050/3877 Loss=3.8809 Acc=31.63%\n",
      "Epoch 1 Train batch 3060/3877 Loss=3.8797 Acc=31.64%\n",
      "Epoch 1 Train batch 3070/3877 Loss=3.8781 Acc=31.65%\n",
      "Epoch 1 Train batch 3080/3877 Loss=3.8769 Acc=31.66%\n",
      "Epoch 1 Train batch 3090/3877 Loss=3.8755 Acc=31.66%\n",
      "Epoch 1 Train batch 3100/3877 Loss=3.8744 Acc=31.67%\n",
      "Epoch 1 Train batch 3110/3877 Loss=3.8730 Acc=31.69%\n",
      "Epoch 1 Train batch 3120/3877 Loss=3.8717 Acc=31.70%\n",
      "Epoch 1 Train batch 3130/3877 Loss=3.8706 Acc=31.71%\n",
      "Epoch 1 Train batch 3140/3877 Loss=3.8693 Acc=31.71%\n",
      "Epoch 1 Train batch 3150/3877 Loss=3.8684 Acc=31.72%\n",
      "Epoch 1 Train batch 3160/3877 Loss=3.8672 Acc=31.73%\n",
      "Epoch 1 Train batch 3170/3877 Loss=3.8661 Acc=31.74%\n",
      "Epoch 1 Train batch 3180/3877 Loss=3.8648 Acc=31.75%\n",
      "Epoch 1 Train batch 3190/3877 Loss=3.8637 Acc=31.76%\n",
      "Epoch 1 Train batch 3200/3877 Loss=3.8627 Acc=31.76%\n",
      "Epoch 1 Train batch 3210/3877 Loss=3.8619 Acc=31.77%\n",
      "Epoch 1 Train batch 3220/3877 Loss=3.8610 Acc=31.77%\n",
      "Epoch 1 Train batch 3230/3877 Loss=3.8599 Acc=31.78%\n",
      "Epoch 1 Train batch 3240/3877 Loss=3.8585 Acc=31.79%\n",
      "Epoch 1 Train batch 3250/3877 Loss=3.8575 Acc=31.79%\n",
      "Epoch 1 Train batch 3260/3877 Loss=3.8561 Acc=31.80%\n",
      "Epoch 1 Train batch 3270/3877 Loss=3.8554 Acc=31.81%\n",
      "Epoch 1 Train batch 3280/3877 Loss=3.8544 Acc=31.82%\n",
      "Epoch 1 Train batch 3290/3877 Loss=3.8531 Acc=31.82%\n",
      "Epoch 1 Train batch 3300/3877 Loss=3.8519 Acc=31.83%\n",
      "Epoch 1 Train batch 3310/3877 Loss=3.8510 Acc=31.84%\n",
      "Epoch 1 Train batch 3320/3877 Loss=3.8498 Acc=31.85%\n",
      "Epoch 1 Train batch 3330/3877 Loss=3.8488 Acc=31.86%\n",
      "Epoch 1 Train batch 3340/3877 Loss=3.8476 Acc=31.86%\n",
      "Epoch 1 Train batch 3350/3877 Loss=3.8462 Acc=31.88%\n",
      "Epoch 1 Train batch 3360/3877 Loss=3.8451 Acc=31.89%\n",
      "Epoch 1 Train batch 3370/3877 Loss=3.8442 Acc=31.89%\n",
      "Epoch 1 Train batch 3380/3877 Loss=3.8430 Acc=31.90%\n",
      "Epoch 1 Train batch 3390/3877 Loss=3.8420 Acc=31.91%\n",
      "Epoch 1 Train batch 3400/3877 Loss=3.8408 Acc=31.92%\n",
      "Epoch 1 Train batch 3410/3877 Loss=3.8397 Acc=31.93%\n",
      "Epoch 1 Train batch 3420/3877 Loss=3.8386 Acc=31.94%\n",
      "Epoch 1 Train batch 3430/3877 Loss=3.8376 Acc=31.94%\n",
      "Epoch 1 Train batch 3440/3877 Loss=3.8368 Acc=31.95%\n",
      "Epoch 1 Train batch 3450/3877 Loss=3.8359 Acc=31.96%\n",
      "Epoch 1 Train batch 3460/3877 Loss=3.8351 Acc=31.96%\n",
      "Epoch 1 Train batch 3470/3877 Loss=3.8340 Acc=31.97%\n",
      "Epoch 1 Train batch 3480/3877 Loss=3.8327 Acc=31.98%\n",
      "Epoch 1 Train batch 3490/3877 Loss=3.8317 Acc=31.99%\n",
      "Epoch 1 Train batch 3500/3877 Loss=3.8307 Acc=31.99%\n",
      "Epoch 1 Train batch 3510/3877 Loss=3.8296 Acc=32.00%\n",
      "Epoch 1 Train batch 3520/3877 Loss=3.8285 Acc=32.01%\n",
      "Epoch 1 Train batch 3530/3877 Loss=3.8274 Acc=32.02%\n",
      "Epoch 1 Train batch 3540/3877 Loss=3.8265 Acc=32.02%\n",
      "Epoch 1 Train batch 3550/3877 Loss=3.8255 Acc=32.03%\n",
      "Epoch 1 Train batch 3560/3877 Loss=3.8247 Acc=32.04%\n",
      "Epoch 1 Train batch 3570/3877 Loss=3.8239 Acc=32.04%\n",
      "Epoch 1 Train batch 3580/3877 Loss=3.8228 Acc=32.05%\n",
      "Epoch 1 Train batch 3590/3877 Loss=3.8218 Acc=32.06%\n",
      "Epoch 1 Train batch 3600/3877 Loss=3.8206 Acc=32.07%\n",
      "Epoch 1 Train batch 3610/3877 Loss=3.8196 Acc=32.07%\n",
      "Epoch 1 Train batch 3620/3877 Loss=3.8187 Acc=32.08%\n",
      "Epoch 1 Train batch 3630/3877 Loss=3.8176 Acc=32.08%\n",
      "Epoch 1 Train batch 3640/3877 Loss=3.8166 Acc=32.09%\n",
      "Epoch 1 Train batch 3650/3877 Loss=3.8157 Acc=32.10%\n",
      "Epoch 1 Train batch 3660/3877 Loss=3.8147 Acc=32.10%\n",
      "Epoch 1 Train batch 3670/3877 Loss=3.8137 Acc=32.11%\n",
      "Epoch 1 Train batch 3680/3877 Loss=3.8128 Acc=32.12%\n",
      "Epoch 1 Train batch 3690/3877 Loss=3.8119 Acc=32.13%\n",
      "Epoch 1 Train batch 3700/3877 Loss=3.8111 Acc=32.13%\n",
      "Epoch 1 Train batch 3710/3877 Loss=3.8100 Acc=32.14%\n",
      "Epoch 1 Train batch 3720/3877 Loss=3.8092 Acc=32.15%\n",
      "Epoch 1 Train batch 3730/3877 Loss=3.8083 Acc=32.15%\n",
      "Epoch 1 Train batch 3740/3877 Loss=3.8072 Acc=32.16%\n",
      "Epoch 1 Train batch 3750/3877 Loss=3.8063 Acc=32.17%\n",
      "Epoch 1 Train batch 3760/3877 Loss=3.8051 Acc=32.18%\n",
      "Epoch 1 Train batch 3770/3877 Loss=3.8042 Acc=32.18%\n",
      "Epoch 1 Train batch 3780/3877 Loss=3.8033 Acc=32.19%\n",
      "Epoch 1 Train batch 3790/3877 Loss=3.8022 Acc=32.20%\n",
      "Epoch 1 Train batch 3800/3877 Loss=3.8012 Acc=32.20%\n",
      "Epoch 1 Train batch 3810/3877 Loss=3.8001 Acc=32.21%\n",
      "Epoch 1 Train batch 3820/3877 Loss=3.7991 Acc=32.22%\n",
      "Epoch 1 Train batch 3830/3877 Loss=3.7982 Acc=32.23%\n",
      "Epoch 1 Train batch 3840/3877 Loss=3.7972 Acc=32.23%\n",
      "Epoch 1 Train batch 3850/3877 Loss=3.7962 Acc=32.24%\n",
      "Epoch 1 Train batch 3860/3877 Loss=3.7953 Acc=32.24%\n",
      "Epoch 1 Train batch 3870/3877 Loss=3.7947 Acc=32.25%\n",
      "Epoch 1 Train batch 3877/3877 Loss=3.7940 Acc=32.25%\n",
      "Epoch 1/5 train_loss=3.7940 train_acc=32.25% val_loss=3.3922 val_acc=35.53%\n",
      "Epoch 2 Train batch 10/3877 Loss=3.3139 Acc=35.57%\n",
      "Epoch 2 Train batch 20/3877 Loss=3.3057 Acc=35.85%\n",
      "Epoch 2 Train batch 30/3877 Loss=3.3114 Acc=35.67%\n",
      "Epoch 2 Train batch 40/3877 Loss=3.3522 Acc=34.97%\n",
      "Epoch 2 Train batch 50/3877 Loss=3.3586 Acc=35.06%\n",
      "Epoch 2 Train batch 60/3877 Loss=3.3523 Acc=35.15%\n",
      "Epoch 2 Train batch 70/3877 Loss=3.3545 Acc=34.93%\n",
      "Epoch 2 Train batch 80/3877 Loss=3.3574 Acc=35.00%\n",
      "Epoch 2 Train batch 90/3877 Loss=3.3581 Acc=35.06%\n",
      "Epoch 2 Train batch 100/3877 Loss=3.3601 Acc=35.06%\n",
      "Epoch 2 Train batch 110/3877 Loss=3.3582 Acc=35.07%\n",
      "Epoch 2 Train batch 120/3877 Loss=3.3612 Acc=35.04%\n",
      "Epoch 2 Train batch 130/3877 Loss=3.3576 Acc=35.01%\n",
      "Epoch 2 Train batch 140/3877 Loss=3.3588 Acc=35.02%\n",
      "Epoch 2 Train batch 150/3877 Loss=3.3576 Acc=34.94%\n",
      "Epoch 2 Train batch 160/3877 Loss=3.3665 Acc=34.89%\n",
      "Epoch 2 Train batch 170/3877 Loss=3.3647 Acc=34.94%\n",
      "Epoch 2 Train batch 180/3877 Loss=3.3627 Acc=35.01%\n",
      "Epoch 2 Train batch 190/3877 Loss=3.3635 Acc=35.07%\n",
      "Epoch 2 Train batch 200/3877 Loss=3.3641 Acc=35.07%\n",
      "Epoch 2 Train batch 210/3877 Loss=3.3599 Acc=35.14%\n",
      "Epoch 2 Train batch 220/3877 Loss=3.3571 Acc=35.18%\n",
      "Epoch 2 Train batch 230/3877 Loss=3.3558 Acc=35.23%\n",
      "Epoch 2 Train batch 240/3877 Loss=3.3566 Acc=35.22%\n",
      "Epoch 2 Train batch 250/3877 Loss=3.3570 Acc=35.23%\n",
      "Epoch 2 Train batch 260/3877 Loss=3.3565 Acc=35.23%\n",
      "Epoch 2 Train batch 270/3877 Loss=3.3571 Acc=35.25%\n",
      "Epoch 2 Train batch 280/3877 Loss=3.3580 Acc=35.24%\n",
      "Epoch 2 Train batch 290/3877 Loss=3.3578 Acc=35.24%\n",
      "Epoch 2 Train batch 300/3877 Loss=3.3590 Acc=35.25%\n",
      "Epoch 2 Train batch 310/3877 Loss=3.3588 Acc=35.24%\n",
      "Epoch 2 Train batch 320/3877 Loss=3.3587 Acc=35.25%\n",
      "Epoch 2 Train batch 330/3877 Loss=3.3591 Acc=35.24%\n",
      "Epoch 2 Train batch 340/3877 Loss=3.3561 Acc=35.28%\n",
      "Epoch 2 Train batch 350/3877 Loss=3.3545 Acc=35.32%\n",
      "Epoch 2 Train batch 360/3877 Loss=3.3570 Acc=35.31%\n",
      "Epoch 2 Train batch 370/3877 Loss=3.3562 Acc=35.34%\n",
      "Epoch 2 Train batch 380/3877 Loss=3.3556 Acc=35.35%\n",
      "Epoch 2 Train batch 390/3877 Loss=3.3565 Acc=35.35%\n",
      "Epoch 2 Train batch 400/3877 Loss=3.3564 Acc=35.35%\n",
      "Epoch 2 Train batch 410/3877 Loss=3.3555 Acc=35.35%\n",
      "Epoch 2 Train batch 420/3877 Loss=3.3565 Acc=35.35%\n",
      "Epoch 2 Train batch 430/3877 Loss=3.3582 Acc=35.33%\n",
      "Epoch 2 Train batch 440/3877 Loss=3.3595 Acc=35.29%\n",
      "Epoch 2 Train batch 450/3877 Loss=3.3563 Acc=35.32%\n",
      "Epoch 2 Train batch 460/3877 Loss=3.3571 Acc=35.33%\n",
      "Epoch 2 Train batch 470/3877 Loss=3.3565 Acc=35.33%\n",
      "Epoch 2 Train batch 480/3877 Loss=3.3563 Acc=35.34%\n",
      "Epoch 2 Train batch 490/3877 Loss=3.3565 Acc=35.35%\n",
      "Epoch 2 Train batch 500/3877 Loss=3.3548 Acc=35.36%\n",
      "Epoch 2 Train batch 510/3877 Loss=3.3547 Acc=35.36%\n",
      "Epoch 2 Train batch 520/3877 Loss=3.3548 Acc=35.36%\n",
      "Epoch 2 Train batch 530/3877 Loss=3.3546 Acc=35.37%\n",
      "Epoch 2 Train batch 540/3877 Loss=3.3540 Acc=35.36%\n",
      "Epoch 2 Train batch 550/3877 Loss=3.3523 Acc=35.38%\n",
      "Epoch 2 Train batch 560/3877 Loss=3.3499 Acc=35.40%\n",
      "Epoch 2 Train batch 570/3877 Loss=3.3496 Acc=35.41%\n",
      "Epoch 2 Train batch 580/3877 Loss=3.3494 Acc=35.43%\n",
      "Epoch 2 Train batch 590/3877 Loss=3.3501 Acc=35.41%\n",
      "Epoch 2 Train batch 600/3877 Loss=3.3495 Acc=35.42%\n",
      "Epoch 2 Train batch 610/3877 Loss=3.3482 Acc=35.44%\n",
      "Epoch 2 Train batch 620/3877 Loss=3.3495 Acc=35.44%\n",
      "Epoch 2 Train batch 630/3877 Loss=3.3493 Acc=35.43%\n",
      "Epoch 2 Train batch 640/3877 Loss=3.3502 Acc=35.43%\n",
      "Epoch 2 Train batch 650/3877 Loss=3.3497 Acc=35.44%\n",
      "Epoch 2 Train batch 660/3877 Loss=3.3492 Acc=35.44%\n",
      "Epoch 2 Train batch 670/3877 Loss=3.3472 Acc=35.46%\n",
      "Epoch 2 Train batch 680/3877 Loss=3.3465 Acc=35.47%\n",
      "Epoch 2 Train batch 690/3877 Loss=3.3473 Acc=35.46%\n",
      "Epoch 2 Train batch 700/3877 Loss=3.3482 Acc=35.46%\n",
      "Epoch 2 Train batch 710/3877 Loss=3.3482 Acc=35.46%\n",
      "Epoch 2 Train batch 720/3877 Loss=3.3492 Acc=35.45%\n",
      "Epoch 2 Train batch 730/3877 Loss=3.3475 Acc=35.47%\n",
      "Epoch 2 Train batch 740/3877 Loss=3.3468 Acc=35.49%\n",
      "Epoch 2 Train batch 750/3877 Loss=3.3468 Acc=35.48%\n",
      "Epoch 2 Train batch 760/3877 Loss=3.3456 Acc=35.49%\n",
      "Epoch 2 Train batch 770/3877 Loss=3.3464 Acc=35.47%\n",
      "Epoch 2 Train batch 780/3877 Loss=3.3454 Acc=35.49%\n",
      "Epoch 2 Train batch 790/3877 Loss=3.3458 Acc=35.48%\n",
      "Epoch 2 Train batch 800/3877 Loss=3.3442 Acc=35.50%\n",
      "Epoch 2 Train batch 810/3877 Loss=3.3445 Acc=35.50%\n",
      "Epoch 2 Train batch 820/3877 Loss=3.3445 Acc=35.50%\n",
      "Epoch 2 Train batch 830/3877 Loss=3.3441 Acc=35.50%\n",
      "Epoch 2 Train batch 840/3877 Loss=3.3436 Acc=35.50%\n",
      "Epoch 2 Train batch 850/3877 Loss=3.3433 Acc=35.50%\n",
      "Epoch 2 Train batch 860/3877 Loss=3.3427 Acc=35.51%\n",
      "Epoch 2 Train batch 870/3877 Loss=3.3424 Acc=35.50%\n",
      "Epoch 2 Train batch 880/3877 Loss=3.3423 Acc=35.50%\n",
      "Epoch 2 Train batch 890/3877 Loss=3.3427 Acc=35.50%\n",
      "Epoch 2 Train batch 900/3877 Loss=3.3426 Acc=35.49%\n",
      "Epoch 2 Train batch 910/3877 Loss=3.3418 Acc=35.50%\n",
      "Epoch 2 Train batch 920/3877 Loss=3.3423 Acc=35.50%\n",
      "Epoch 2 Train batch 930/3877 Loss=3.3429 Acc=35.49%\n",
      "Epoch 2 Train batch 940/3877 Loss=3.3427 Acc=35.48%\n",
      "Epoch 2 Train batch 950/3877 Loss=3.3430 Acc=35.48%\n",
      "Epoch 2 Train batch 960/3877 Loss=3.3423 Acc=35.49%\n",
      "Epoch 2 Train batch 970/3877 Loss=3.3420 Acc=35.50%\n",
      "Epoch 2 Train batch 980/3877 Loss=3.3420 Acc=35.50%\n",
      "Epoch 2 Train batch 990/3877 Loss=3.3418 Acc=35.50%\n",
      "Epoch 2 Train batch 1000/3877 Loss=3.3424 Acc=35.48%\n",
      "Epoch 2 Train batch 1010/3877 Loss=3.3425 Acc=35.48%\n",
      "Epoch 2 Train batch 1020/3877 Loss=3.3417 Acc=35.49%\n",
      "Epoch 2 Train batch 1030/3877 Loss=3.3417 Acc=35.49%\n",
      "Epoch 2 Train batch 1040/3877 Loss=3.3416 Acc=35.48%\n",
      "Epoch 2 Train batch 1050/3877 Loss=3.3415 Acc=35.49%\n",
      "Epoch 2 Train batch 1060/3877 Loss=3.3419 Acc=35.48%\n",
      "Epoch 2 Train batch 1070/3877 Loss=3.3416 Acc=35.48%\n",
      "Epoch 2 Train batch 1080/3877 Loss=3.3412 Acc=35.49%\n",
      "Epoch 2 Train batch 1090/3877 Loss=3.3407 Acc=35.49%\n",
      "Epoch 2 Train batch 1100/3877 Loss=3.3397 Acc=35.50%\n",
      "Epoch 2 Train batch 1110/3877 Loss=3.3401 Acc=35.50%\n",
      "Epoch 2 Train batch 1120/3877 Loss=3.3409 Acc=35.49%\n",
      "Epoch 2 Train batch 1130/3877 Loss=3.3412 Acc=35.50%\n",
      "Epoch 2 Train batch 1140/3877 Loss=3.3404 Acc=35.51%\n",
      "Epoch 2 Train batch 1150/3877 Loss=3.3402 Acc=35.51%\n",
      "Epoch 2 Train batch 1160/3877 Loss=3.3406 Acc=35.50%\n",
      "Epoch 2 Train batch 1170/3877 Loss=3.3406 Acc=35.51%\n",
      "Epoch 2 Train batch 1180/3877 Loss=3.3397 Acc=35.52%\n",
      "Epoch 2 Train batch 1190/3877 Loss=3.3394 Acc=35.53%\n",
      "Epoch 2 Train batch 1200/3877 Loss=3.3393 Acc=35.53%\n",
      "Epoch 2 Train batch 1210/3877 Loss=3.3392 Acc=35.54%\n",
      "Epoch 2 Train batch 1220/3877 Loss=3.3387 Acc=35.54%\n",
      "Epoch 2 Train batch 1230/3877 Loss=3.3386 Acc=35.54%\n",
      "Epoch 2 Train batch 1240/3877 Loss=3.3383 Acc=35.54%\n",
      "Epoch 2 Train batch 1250/3877 Loss=3.3381 Acc=35.55%\n",
      "Epoch 2 Train batch 1260/3877 Loss=3.3382 Acc=35.55%\n",
      "Epoch 2 Train batch 1270/3877 Loss=3.3379 Acc=35.56%\n",
      "Epoch 2 Train batch 1280/3877 Loss=3.3378 Acc=35.56%\n",
      "Epoch 2 Train batch 1290/3877 Loss=3.3377 Acc=35.56%\n",
      "Epoch 2 Train batch 1300/3877 Loss=3.3373 Acc=35.57%\n",
      "Epoch 2 Train batch 1310/3877 Loss=3.3379 Acc=35.56%\n",
      "Epoch 2 Train batch 1320/3877 Loss=3.3374 Acc=35.57%\n",
      "Epoch 2 Train batch 1330/3877 Loss=3.3385 Acc=35.56%\n",
      "Epoch 2 Train batch 1340/3877 Loss=3.3385 Acc=35.56%\n",
      "Epoch 2 Train batch 1350/3877 Loss=3.3392 Acc=35.56%\n",
      "Epoch 2 Train batch 1360/3877 Loss=3.3384 Acc=35.57%\n",
      "Epoch 2 Train batch 1370/3877 Loss=3.3379 Acc=35.58%\n",
      "Epoch 2 Train batch 1380/3877 Loss=3.3374 Acc=35.58%\n",
      "Epoch 2 Train batch 1390/3877 Loss=3.3372 Acc=35.58%\n",
      "Epoch 2 Train batch 1400/3877 Loss=3.3368 Acc=35.58%\n",
      "Epoch 2 Train batch 1410/3877 Loss=3.3368 Acc=35.58%\n",
      "Epoch 2 Train batch 1420/3877 Loss=3.3364 Acc=35.58%\n",
      "Epoch 2 Train batch 1430/3877 Loss=3.3359 Acc=35.59%\n",
      "Epoch 2 Train batch 1440/3877 Loss=3.3352 Acc=35.59%\n",
      "Epoch 2 Train batch 1450/3877 Loss=3.3351 Acc=35.59%\n",
      "Epoch 2 Train batch 1460/3877 Loss=3.3353 Acc=35.59%\n",
      "Epoch 2 Train batch 1470/3877 Loss=3.3353 Acc=35.59%\n",
      "Epoch 2 Train batch 1480/3877 Loss=3.3350 Acc=35.60%\n",
      "Epoch 2 Train batch 1490/3877 Loss=3.3351 Acc=35.59%\n",
      "Epoch 2 Train batch 1500/3877 Loss=3.3347 Acc=35.59%\n",
      "Epoch 2 Train batch 1510/3877 Loss=3.3341 Acc=35.59%\n",
      "Epoch 2 Train batch 1520/3877 Loss=3.3343 Acc=35.58%\n",
      "Epoch 2 Train batch 1530/3877 Loss=3.3345 Acc=35.58%\n",
      "Epoch 2 Train batch 1540/3877 Loss=3.3342 Acc=35.58%\n",
      "Epoch 2 Train batch 1550/3877 Loss=3.3339 Acc=35.59%\n",
      "Epoch 2 Train batch 1560/3877 Loss=3.3334 Acc=35.60%\n",
      "Epoch 2 Train batch 1570/3877 Loss=3.3331 Acc=35.60%\n",
      "Epoch 2 Train batch 1580/3877 Loss=3.3328 Acc=35.60%\n",
      "Epoch 2 Train batch 1590/3877 Loss=3.3329 Acc=35.60%\n",
      "Epoch 2 Train batch 1600/3877 Loss=3.3321 Acc=35.61%\n",
      "Epoch 2 Train batch 1610/3877 Loss=3.3316 Acc=35.61%\n",
      "Epoch 2 Train batch 1620/3877 Loss=3.3312 Acc=35.62%\n",
      "Epoch 2 Train batch 1630/3877 Loss=3.3311 Acc=35.63%\n",
      "Epoch 2 Train batch 1640/3877 Loss=3.3307 Acc=35.63%\n",
      "Epoch 2 Train batch 1650/3877 Loss=3.3301 Acc=35.64%\n",
      "Epoch 2 Train batch 1660/3877 Loss=3.3298 Acc=35.64%\n",
      "Epoch 2 Train batch 1670/3877 Loss=3.3297 Acc=35.64%\n",
      "Epoch 2 Train batch 1680/3877 Loss=3.3293 Acc=35.64%\n",
      "Epoch 2 Train batch 1690/3877 Loss=3.3294 Acc=35.65%\n",
      "Epoch 2 Train batch 1700/3877 Loss=3.3295 Acc=35.64%\n",
      "Epoch 2 Train batch 1710/3877 Loss=3.3291 Acc=35.65%\n",
      "Epoch 2 Train batch 1720/3877 Loss=3.3291 Acc=35.65%\n",
      "Epoch 2 Train batch 1730/3877 Loss=3.3292 Acc=35.65%\n",
      "Epoch 2 Train batch 1740/3877 Loss=3.3291 Acc=35.65%\n",
      "Epoch 2 Train batch 1750/3877 Loss=3.3288 Acc=35.66%\n",
      "Epoch 2 Train batch 1760/3877 Loss=3.3288 Acc=35.66%\n",
      "Epoch 2 Train batch 1770/3877 Loss=3.3285 Acc=35.66%\n",
      "Epoch 2 Train batch 1780/3877 Loss=3.3282 Acc=35.66%\n",
      "Epoch 2 Train batch 1790/3877 Loss=3.3276 Acc=35.67%\n",
      "Epoch 2 Train batch 1800/3877 Loss=3.3272 Acc=35.67%\n",
      "Epoch 2 Train batch 1810/3877 Loss=3.3270 Acc=35.67%\n",
      "Epoch 2 Train batch 1820/3877 Loss=3.3270 Acc=35.67%\n",
      "Epoch 2 Train batch 1830/3877 Loss=3.3267 Acc=35.68%\n",
      "Epoch 2 Train batch 1840/3877 Loss=3.3267 Acc=35.68%\n",
      "Epoch 2 Train batch 1850/3877 Loss=3.3269 Acc=35.68%\n",
      "Epoch 2 Train batch 1860/3877 Loss=3.3266 Acc=35.68%\n",
      "Epoch 2 Train batch 1870/3877 Loss=3.3266 Acc=35.68%\n",
      "Epoch 2 Train batch 1880/3877 Loss=3.3263 Acc=35.68%\n",
      "Epoch 2 Train batch 1890/3877 Loss=3.3263 Acc=35.68%\n",
      "Epoch 2 Train batch 1900/3877 Loss=3.3258 Acc=35.69%\n",
      "Epoch 2 Train batch 1910/3877 Loss=3.3254 Acc=35.69%\n",
      "Epoch 2 Train batch 1920/3877 Loss=3.3249 Acc=35.70%\n",
      "Epoch 2 Train batch 1930/3877 Loss=3.3249 Acc=35.70%\n",
      "Epoch 2 Train batch 1940/3877 Loss=3.3252 Acc=35.69%\n",
      "Epoch 2 Train batch 1950/3877 Loss=3.3251 Acc=35.69%\n",
      "Epoch 2 Train batch 1960/3877 Loss=3.3248 Acc=35.69%\n",
      "Epoch 2 Train batch 1970/3877 Loss=3.3245 Acc=35.69%\n",
      "Epoch 2 Train batch 1980/3877 Loss=3.3243 Acc=35.70%\n",
      "Epoch 2 Train batch 1990/3877 Loss=3.3243 Acc=35.70%\n",
      "Epoch 2 Train batch 2000/3877 Loss=3.3239 Acc=35.70%\n",
      "Epoch 2 Train batch 2010/3877 Loss=3.3239 Acc=35.70%\n",
      "Epoch 2 Train batch 2020/3877 Loss=3.3238 Acc=35.70%\n",
      "Epoch 2 Train batch 2030/3877 Loss=3.3232 Acc=35.71%\n",
      "Epoch 2 Train batch 2040/3877 Loss=3.3229 Acc=35.71%\n",
      "Epoch 2 Train batch 2050/3877 Loss=3.3226 Acc=35.71%\n",
      "Epoch 2 Train batch 2060/3877 Loss=3.3224 Acc=35.71%\n",
      "Epoch 2 Train batch 2070/3877 Loss=3.3221 Acc=35.71%\n",
      "Epoch 2 Train batch 2080/3877 Loss=3.3217 Acc=35.72%\n",
      "Epoch 2 Train batch 2090/3877 Loss=3.3219 Acc=35.72%\n",
      "Epoch 2 Train batch 2100/3877 Loss=3.3214 Acc=35.72%\n",
      "Epoch 2 Train batch 2110/3877 Loss=3.3211 Acc=35.72%\n",
      "Epoch 2 Train batch 2120/3877 Loss=3.3208 Acc=35.73%\n",
      "Epoch 2 Train batch 2130/3877 Loss=3.3207 Acc=35.73%\n",
      "Epoch 2 Train batch 2140/3877 Loss=3.3203 Acc=35.74%\n",
      "Epoch 2 Train batch 2150/3877 Loss=3.3200 Acc=35.74%\n",
      "Epoch 2 Train batch 2160/3877 Loss=3.3199 Acc=35.74%\n",
      "Epoch 2 Train batch 2170/3877 Loss=3.3197 Acc=35.74%\n",
      "Epoch 2 Train batch 2180/3877 Loss=3.3194 Acc=35.75%\n",
      "Epoch 2 Train batch 2190/3877 Loss=3.3190 Acc=35.75%\n",
      "Epoch 2 Train batch 2200/3877 Loss=3.3190 Acc=35.75%\n",
      "Epoch 2 Train batch 2210/3877 Loss=3.3192 Acc=35.75%\n",
      "Epoch 2 Train batch 2220/3877 Loss=3.3190 Acc=35.75%\n",
      "Epoch 2 Train batch 2230/3877 Loss=3.3188 Acc=35.75%\n",
      "Epoch 2 Train batch 2240/3877 Loss=3.3186 Acc=35.75%\n",
      "Epoch 2 Train batch 2250/3877 Loss=3.3186 Acc=35.75%\n",
      "Epoch 2 Train batch 2260/3877 Loss=3.3186 Acc=35.76%\n",
      "Epoch 2 Train batch 2270/3877 Loss=3.3181 Acc=35.76%\n",
      "Epoch 2 Train batch 2280/3877 Loss=3.3181 Acc=35.76%\n",
      "Epoch 2 Train batch 2290/3877 Loss=3.3176 Acc=35.76%\n",
      "Epoch 2 Train batch 2300/3877 Loss=3.3172 Acc=35.77%\n",
      "Epoch 2 Train batch 2310/3877 Loss=3.3169 Acc=35.77%\n",
      "Epoch 2 Train batch 2320/3877 Loss=3.3163 Acc=35.78%\n",
      "Epoch 2 Train batch 2330/3877 Loss=3.3157 Acc=35.79%\n",
      "Epoch 2 Train batch 2340/3877 Loss=3.3156 Acc=35.78%\n",
      "Epoch 2 Train batch 2350/3877 Loss=3.3152 Acc=35.79%\n",
      "Epoch 2 Train batch 2360/3877 Loss=3.3148 Acc=35.79%\n",
      "Epoch 2 Train batch 2370/3877 Loss=3.3143 Acc=35.79%\n",
      "Epoch 2 Train batch 2380/3877 Loss=3.3141 Acc=35.80%\n",
      "Epoch 2 Train batch 2390/3877 Loss=3.3139 Acc=35.80%\n",
      "Epoch 2 Train batch 2400/3877 Loss=3.3134 Acc=35.80%\n",
      "Epoch 2 Train batch 2410/3877 Loss=3.3130 Acc=35.81%\n",
      "Epoch 2 Train batch 2420/3877 Loss=3.3129 Acc=35.81%\n",
      "Epoch 2 Train batch 2430/3877 Loss=3.3122 Acc=35.82%\n",
      "Epoch 2 Train batch 2440/3877 Loss=3.3120 Acc=35.82%\n",
      "Epoch 2 Train batch 2450/3877 Loss=3.3117 Acc=35.82%\n",
      "Epoch 2 Train batch 2460/3877 Loss=3.3114 Acc=35.83%\n",
      "Epoch 2 Train batch 2470/3877 Loss=3.3113 Acc=35.83%\n",
      "Epoch 2 Train batch 2480/3877 Loss=3.3112 Acc=35.83%\n",
      "Epoch 2 Train batch 2490/3877 Loss=3.3109 Acc=35.83%\n",
      "Epoch 2 Train batch 2500/3877 Loss=3.3108 Acc=35.83%\n",
      "Epoch 2 Train batch 2510/3877 Loss=3.3107 Acc=35.83%\n",
      "Epoch 2 Train batch 2520/3877 Loss=3.3105 Acc=35.83%\n",
      "Epoch 2 Train batch 2530/3877 Loss=3.3104 Acc=35.83%\n",
      "Epoch 2 Train batch 2540/3877 Loss=3.3097 Acc=35.83%\n",
      "Epoch 2 Train batch 2550/3877 Loss=3.3092 Acc=35.84%\n",
      "Epoch 2 Train batch 2560/3877 Loss=3.3088 Acc=35.85%\n",
      "Epoch 2 Train batch 2570/3877 Loss=3.3082 Acc=35.85%\n",
      "Epoch 2 Train batch 2580/3877 Loss=3.3082 Acc=35.85%\n",
      "Epoch 2 Train batch 2590/3877 Loss=3.3077 Acc=35.85%\n",
      "Epoch 2 Train batch 2600/3877 Loss=3.3076 Acc=35.86%\n",
      "Epoch 2 Train batch 2610/3877 Loss=3.3071 Acc=35.86%\n",
      "Epoch 2 Train batch 2620/3877 Loss=3.3069 Acc=35.86%\n",
      "Epoch 2 Train batch 2630/3877 Loss=3.3068 Acc=35.86%\n",
      "Epoch 2 Train batch 2640/3877 Loss=3.3066 Acc=35.86%\n",
      "Epoch 2 Train batch 2650/3877 Loss=3.3064 Acc=35.87%\n",
      "Epoch 2 Train batch 2660/3877 Loss=3.3061 Acc=35.87%\n",
      "Epoch 2 Train batch 2670/3877 Loss=3.3062 Acc=35.87%\n",
      "Epoch 2 Train batch 2680/3877 Loss=3.3059 Acc=35.87%\n",
      "Epoch 2 Train batch 2690/3877 Loss=3.3056 Acc=35.87%\n",
      "Epoch 2 Train batch 2700/3877 Loss=3.3056 Acc=35.87%\n",
      "Epoch 2 Train batch 2710/3877 Loss=3.3055 Acc=35.87%\n",
      "Epoch 2 Train batch 2720/3877 Loss=3.3051 Acc=35.87%\n",
      "Epoch 2 Train batch 2730/3877 Loss=3.3048 Acc=35.87%\n",
      "Epoch 2 Train batch 2740/3877 Loss=3.3046 Acc=35.87%\n",
      "Epoch 2 Train batch 2750/3877 Loss=3.3045 Acc=35.88%\n",
      "Epoch 2 Train batch 2760/3877 Loss=3.3041 Acc=35.88%\n",
      "Epoch 2 Train batch 2770/3877 Loss=3.3038 Acc=35.88%\n",
      "Epoch 2 Train batch 2780/3877 Loss=3.3035 Acc=35.88%\n",
      "Epoch 2 Train batch 2790/3877 Loss=3.3033 Acc=35.89%\n",
      "Epoch 2 Train batch 2800/3877 Loss=3.3033 Acc=35.89%\n",
      "Epoch 2 Train batch 2810/3877 Loss=3.3030 Acc=35.89%\n",
      "Epoch 2 Train batch 2820/3877 Loss=3.3028 Acc=35.90%\n",
      "Epoch 2 Train batch 2830/3877 Loss=3.3026 Acc=35.89%\n",
      "Epoch 2 Train batch 2840/3877 Loss=3.3026 Acc=35.89%\n",
      "Epoch 2 Train batch 2850/3877 Loss=3.3024 Acc=35.90%\n",
      "Epoch 2 Train batch 2860/3877 Loss=3.3021 Acc=35.90%\n",
      "Epoch 2 Train batch 2870/3877 Loss=3.3016 Acc=35.90%\n",
      "Epoch 2 Train batch 2880/3877 Loss=3.3019 Acc=35.89%\n",
      "Epoch 2 Train batch 2890/3877 Loss=3.3018 Acc=35.89%\n",
      "Epoch 2 Train batch 2900/3877 Loss=3.3019 Acc=35.89%\n",
      "Epoch 2 Train batch 2910/3877 Loss=3.3016 Acc=35.90%\n",
      "Epoch 2 Train batch 2920/3877 Loss=3.3017 Acc=35.89%\n",
      "Epoch 2 Train batch 2930/3877 Loss=3.3013 Acc=35.89%\n",
      "Epoch 2 Train batch 2940/3877 Loss=3.3011 Acc=35.90%\n",
      "Epoch 2 Train batch 2950/3877 Loss=3.3007 Acc=35.90%\n",
      "Epoch 2 Train batch 2960/3877 Loss=3.3004 Acc=35.90%\n",
      "Epoch 2 Train batch 2970/3877 Loss=3.3003 Acc=35.90%\n",
      "Epoch 2 Train batch 2980/3877 Loss=3.3002 Acc=35.90%\n",
      "Epoch 2 Train batch 2990/3877 Loss=3.3002 Acc=35.90%\n",
      "Epoch 2 Train batch 3000/3877 Loss=3.3001 Acc=35.90%\n",
      "Epoch 2 Train batch 3010/3877 Loss=3.2997 Acc=35.90%\n",
      "Epoch 2 Train batch 3020/3877 Loss=3.2997 Acc=35.90%\n",
      "Epoch 2 Train batch 3030/3877 Loss=3.2995 Acc=35.90%\n",
      "Epoch 2 Train batch 3040/3877 Loss=3.2995 Acc=35.90%\n",
      "Epoch 2 Train batch 3050/3877 Loss=3.2992 Acc=35.90%\n",
      "Epoch 2 Train batch 3060/3877 Loss=3.2990 Acc=35.90%\n",
      "Epoch 2 Train batch 3070/3877 Loss=3.2986 Acc=35.90%\n",
      "Epoch 2 Train batch 3080/3877 Loss=3.2986 Acc=35.90%\n",
      "Epoch 2 Train batch 3090/3877 Loss=3.2983 Acc=35.91%\n",
      "Epoch 2 Train batch 3100/3877 Loss=3.2981 Acc=35.91%\n",
      "Epoch 2 Train batch 3110/3877 Loss=3.2979 Acc=35.91%\n",
      "Epoch 2 Train batch 3120/3877 Loss=3.2976 Acc=35.91%\n",
      "Epoch 2 Train batch 3130/3877 Loss=3.2973 Acc=35.92%\n",
      "Epoch 2 Train batch 3140/3877 Loss=3.2971 Acc=35.92%\n",
      "Epoch 2 Train batch 3150/3877 Loss=3.2969 Acc=35.92%\n",
      "Epoch 2 Train batch 3160/3877 Loss=3.2966 Acc=35.93%\n",
      "Epoch 2 Train batch 3170/3877 Loss=3.2966 Acc=35.93%\n",
      "Epoch 2 Train batch 3180/3877 Loss=3.2967 Acc=35.94%\n",
      "Epoch 2 Train batch 3190/3877 Loss=3.2965 Acc=35.94%\n",
      "Epoch 2 Train batch 3200/3877 Loss=3.2962 Acc=35.94%\n",
      "Epoch 2 Train batch 3210/3877 Loss=3.2961 Acc=35.94%\n",
      "Epoch 2 Train batch 3220/3877 Loss=3.2959 Acc=35.95%\n",
      "Epoch 2 Train batch 3230/3877 Loss=3.2957 Acc=35.95%\n",
      "Epoch 2 Train batch 3240/3877 Loss=3.2956 Acc=35.95%\n",
      "Epoch 2 Train batch 3250/3877 Loss=3.2954 Acc=35.95%\n",
      "Epoch 2 Train batch 3260/3877 Loss=3.2950 Acc=35.96%\n",
      "Epoch 2 Train batch 3270/3877 Loss=3.2946 Acc=35.96%\n",
      "Epoch 2 Train batch 3280/3877 Loss=3.2944 Acc=35.96%\n",
      "Epoch 2 Train batch 3290/3877 Loss=3.2942 Acc=35.96%\n",
      "Epoch 2 Train batch 3300/3877 Loss=3.2939 Acc=35.96%\n",
      "Epoch 2 Train batch 3310/3877 Loss=3.2938 Acc=35.96%\n",
      "Epoch 2 Train batch 3320/3877 Loss=3.2936 Acc=35.96%\n",
      "Epoch 2 Train batch 3330/3877 Loss=3.2933 Acc=35.96%\n",
      "Epoch 2 Train batch 3340/3877 Loss=3.2934 Acc=35.96%\n",
      "Epoch 2 Train batch 3350/3877 Loss=3.2933 Acc=35.96%\n",
      "Epoch 2 Train batch 3360/3877 Loss=3.2932 Acc=35.96%\n",
      "Epoch 2 Train batch 3370/3877 Loss=3.2930 Acc=35.96%\n",
      "Epoch 2 Train batch 3380/3877 Loss=3.2930 Acc=35.96%\n",
      "Epoch 2 Train batch 3390/3877 Loss=3.2926 Acc=35.97%\n",
      "Epoch 2 Train batch 3400/3877 Loss=3.2922 Acc=35.97%\n",
      "Epoch 2 Train batch 3410/3877 Loss=3.2922 Acc=35.98%\n",
      "Epoch 2 Train batch 3420/3877 Loss=3.2919 Acc=35.98%\n",
      "Epoch 2 Train batch 3430/3877 Loss=3.2916 Acc=35.98%\n",
      "Epoch 2 Train batch 3440/3877 Loss=3.2914 Acc=35.98%\n",
      "Epoch 2 Train batch 3450/3877 Loss=3.2914 Acc=35.98%\n",
      "Epoch 2 Train batch 3460/3877 Loss=3.2912 Acc=35.98%\n",
      "Epoch 2 Train batch 3470/3877 Loss=3.2911 Acc=35.98%\n",
      "Epoch 2 Train batch 3480/3877 Loss=3.2909 Acc=35.98%\n",
      "Epoch 2 Train batch 3490/3877 Loss=3.2907 Acc=35.99%\n",
      "Epoch 2 Train batch 3500/3877 Loss=3.2905 Acc=35.99%\n",
      "Epoch 2 Train batch 3510/3877 Loss=3.2906 Acc=35.99%\n",
      "Epoch 2 Train batch 3520/3877 Loss=3.2906 Acc=35.99%\n",
      "Epoch 2 Train batch 3530/3877 Loss=3.2902 Acc=35.99%\n",
      "Epoch 2 Train batch 3540/3877 Loss=3.2900 Acc=36.00%\n",
      "Epoch 2 Train batch 3550/3877 Loss=3.2897 Acc=36.00%\n",
      "Epoch 2 Train batch 3560/3877 Loss=3.2894 Acc=36.00%\n",
      "Epoch 2 Train batch 3570/3877 Loss=3.2894 Acc=36.00%\n",
      "Epoch 2 Train batch 3580/3877 Loss=3.2892 Acc=36.00%\n",
      "Epoch 2 Train batch 3590/3877 Loss=3.2888 Acc=36.00%\n",
      "Epoch 2 Train batch 3600/3877 Loss=3.2889 Acc=36.00%\n",
      "Epoch 2 Train batch 3610/3877 Loss=3.2886 Acc=36.01%\n",
      "Epoch 2 Train batch 3620/3877 Loss=3.2885 Acc=36.01%\n",
      "Epoch 2 Train batch 3630/3877 Loss=3.2883 Acc=36.01%\n",
      "Epoch 2 Train batch 3640/3877 Loss=3.2879 Acc=36.02%\n",
      "Epoch 2 Train batch 3650/3877 Loss=3.2880 Acc=36.01%\n",
      "Epoch 2 Train batch 3660/3877 Loss=3.2879 Acc=36.02%\n",
      "Epoch 2 Train batch 3670/3877 Loss=3.2879 Acc=36.01%\n",
      "Epoch 2 Train batch 3680/3877 Loss=3.2879 Acc=36.01%\n",
      "Epoch 2 Train batch 3690/3877 Loss=3.2877 Acc=36.02%\n",
      "Epoch 2 Train batch 3700/3877 Loss=3.2878 Acc=36.01%\n",
      "Epoch 2 Train batch 3710/3877 Loss=3.2875 Acc=36.02%\n",
      "Epoch 2 Train batch 3720/3877 Loss=3.2872 Acc=36.02%\n",
      "Epoch 2 Train batch 3730/3877 Loss=3.2872 Acc=36.02%\n",
      "Epoch 2 Train batch 3740/3877 Loss=3.2870 Acc=36.02%\n",
      "Epoch 2 Train batch 3750/3877 Loss=3.2871 Acc=36.02%\n",
      "Epoch 2 Train batch 3760/3877 Loss=3.2869 Acc=36.02%\n",
      "Epoch 2 Train batch 3770/3877 Loss=3.2867 Acc=36.02%\n",
      "Epoch 2 Train batch 3780/3877 Loss=3.2867 Acc=36.02%\n",
      "Epoch 2 Train batch 3790/3877 Loss=3.2864 Acc=36.03%\n",
      "Epoch 2 Train batch 3800/3877 Loss=3.2864 Acc=36.03%\n",
      "Epoch 2 Train batch 3810/3877 Loss=3.2861 Acc=36.03%\n",
      "Epoch 2 Train batch 3820/3877 Loss=3.2859 Acc=36.03%\n",
      "Epoch 2 Train batch 3830/3877 Loss=3.2857 Acc=36.03%\n",
      "Epoch 2 Train batch 3840/3877 Loss=3.2854 Acc=36.03%\n",
      "Epoch 2 Train batch 3850/3877 Loss=3.2851 Acc=36.04%\n",
      "Epoch 2 Train batch 3860/3877 Loss=3.2850 Acc=36.04%\n",
      "Epoch 2 Train batch 3870/3877 Loss=3.2847 Acc=36.04%\n",
      "Epoch 2 Train batch 3877/3877 Loss=3.2846 Acc=36.04%\n",
      "Epoch 2/5 train_loss=3.2846 train_acc=36.04% val_loss=3.2089 val_acc=37.12%\n",
      "Epoch 3 Train batch 10/3877 Loss=3.0750 Acc=38.32%\n",
      "Epoch 3 Train batch 20/3877 Loss=3.0919 Acc=37.62%\n",
      "Epoch 3 Train batch 30/3877 Loss=3.1274 Acc=37.53%\n",
      "Epoch 3 Train batch 40/3877 Loss=3.1303 Acc=37.40%\n",
      "Epoch 3 Train batch 50/3877 Loss=3.1186 Acc=37.47%\n",
      "Epoch 3 Train batch 60/3877 Loss=3.1146 Acc=37.62%\n",
      "Epoch 3 Train batch 70/3877 Loss=3.1242 Acc=37.42%\n",
      "Epoch 3 Train batch 80/3877 Loss=3.1203 Acc=37.50%\n",
      "Epoch 3 Train batch 90/3877 Loss=3.1150 Acc=37.58%\n",
      "Epoch 3 Train batch 100/3877 Loss=3.1056 Acc=37.66%\n",
      "Epoch 3 Train batch 110/3877 Loss=3.1055 Acc=37.68%\n",
      "Epoch 3 Train batch 120/3877 Loss=3.1103 Acc=37.65%\n",
      "Epoch 3 Train batch 130/3877 Loss=3.1078 Acc=37.68%\n",
      "Epoch 3 Train batch 140/3877 Loss=3.1011 Acc=37.78%\n",
      "Epoch 3 Train batch 150/3877 Loss=3.0999 Acc=37.78%\n",
      "Epoch 3 Train batch 160/3877 Loss=3.1008 Acc=37.79%\n",
      "Epoch 3 Train batch 170/3877 Loss=3.1033 Acc=37.76%\n",
      "Epoch 3 Train batch 180/3877 Loss=3.1027 Acc=37.74%\n",
      "Epoch 3 Train batch 190/3877 Loss=3.0995 Acc=37.76%\n",
      "Epoch 3 Train batch 200/3877 Loss=3.0927 Acc=37.88%\n",
      "Epoch 3 Train batch 210/3877 Loss=3.0878 Acc=37.90%\n",
      "Epoch 3 Train batch 220/3877 Loss=3.0881 Acc=37.92%\n",
      "Epoch 3 Train batch 230/3877 Loss=3.0918 Acc=37.89%\n",
      "Epoch 3 Train batch 240/3877 Loss=3.0941 Acc=37.86%\n",
      "Epoch 3 Train batch 250/3877 Loss=3.0951 Acc=37.86%\n",
      "Epoch 3 Train batch 260/3877 Loss=3.0937 Acc=37.87%\n",
      "Epoch 3 Train batch 270/3877 Loss=3.0940 Acc=37.86%\n",
      "Epoch 3 Train batch 280/3877 Loss=3.0915 Acc=37.85%\n",
      "Epoch 3 Train batch 290/3877 Loss=3.0912 Acc=37.86%\n",
      "Epoch 3 Train batch 300/3877 Loss=3.0922 Acc=37.87%\n",
      "Epoch 3 Train batch 310/3877 Loss=3.0921 Acc=37.85%\n",
      "Epoch 3 Train batch 320/3877 Loss=3.0916 Acc=37.84%\n",
      "Epoch 3 Train batch 330/3877 Loss=3.0925 Acc=37.82%\n",
      "Epoch 3 Train batch 340/3877 Loss=3.0947 Acc=37.80%\n",
      "Epoch 3 Train batch 350/3877 Loss=3.0940 Acc=37.80%\n",
      "Epoch 3 Train batch 360/3877 Loss=3.0939 Acc=37.83%\n",
      "Epoch 3 Train batch 370/3877 Loss=3.0934 Acc=37.82%\n",
      "Epoch 3 Train batch 380/3877 Loss=3.0931 Acc=37.79%\n",
      "Epoch 3 Train batch 390/3877 Loss=3.0932 Acc=37.80%\n",
      "Epoch 3 Train batch 400/3877 Loss=3.0938 Acc=37.80%\n",
      "Epoch 3 Train batch 410/3877 Loss=3.0939 Acc=37.83%\n",
      "Epoch 3 Train batch 420/3877 Loss=3.0961 Acc=37.80%\n",
      "Epoch 3 Train batch 430/3877 Loss=3.0954 Acc=37.80%\n",
      "Epoch 3 Train batch 440/3877 Loss=3.0952 Acc=37.82%\n",
      "Epoch 3 Train batch 450/3877 Loss=3.0982 Acc=37.78%\n",
      "Epoch 3 Train batch 460/3877 Loss=3.0984 Acc=37.79%\n",
      "Epoch 3 Train batch 470/3877 Loss=3.0997 Acc=37.78%\n",
      "Epoch 3 Train batch 480/3877 Loss=3.1006 Acc=37.78%\n",
      "Epoch 3 Train batch 490/3877 Loss=3.1004 Acc=37.78%\n",
      "Epoch 3 Train batch 500/3877 Loss=3.1012 Acc=37.75%\n",
      "Epoch 3 Train batch 510/3877 Loss=3.1012 Acc=37.77%\n",
      "Epoch 3 Train batch 520/3877 Loss=3.1022 Acc=37.76%\n",
      "Epoch 3 Train batch 530/3877 Loss=3.1027 Acc=37.75%\n",
      "Epoch 3 Train batch 540/3877 Loss=3.1038 Acc=37.74%\n",
      "Epoch 3 Train batch 550/3877 Loss=3.1028 Acc=37.76%\n",
      "Epoch 3 Train batch 560/3877 Loss=3.1028 Acc=37.76%\n",
      "Epoch 3 Train batch 570/3877 Loss=3.1029 Acc=37.77%\n",
      "Epoch 3 Train batch 580/3877 Loss=3.1032 Acc=37.78%\n",
      "Epoch 3 Train batch 590/3877 Loss=3.1019 Acc=37.79%\n",
      "Epoch 3 Train batch 600/3877 Loss=3.1019 Acc=37.80%\n",
      "Epoch 3 Train batch 610/3877 Loss=3.1020 Acc=37.79%\n",
      "Epoch 3 Train batch 620/3877 Loss=3.1034 Acc=37.75%\n",
      "Epoch 3 Train batch 630/3877 Loss=3.1035 Acc=37.75%\n",
      "Epoch 3 Train batch 640/3877 Loss=3.1026 Acc=37.76%\n",
      "Epoch 3 Train batch 650/3877 Loss=3.1022 Acc=37.77%\n",
      "Epoch 3 Train batch 660/3877 Loss=3.1024 Acc=37.78%\n",
      "Epoch 3 Train batch 670/3877 Loss=3.1033 Acc=37.77%\n",
      "Epoch 3 Train batch 680/3877 Loss=3.1039 Acc=37.76%\n",
      "Epoch 3 Train batch 690/3877 Loss=3.1044 Acc=37.76%\n",
      "Epoch 3 Train batch 700/3877 Loss=3.1050 Acc=37.74%\n",
      "Epoch 3 Train batch 710/3877 Loss=3.1064 Acc=37.73%\n",
      "Epoch 3 Train batch 720/3877 Loss=3.1060 Acc=37.73%\n",
      "Epoch 3 Train batch 730/3877 Loss=3.1057 Acc=37.72%\n",
      "Epoch 3 Train batch 740/3877 Loss=3.1058 Acc=37.72%\n",
      "Epoch 3 Train batch 750/3877 Loss=3.1047 Acc=37.74%\n",
      "Epoch 3 Train batch 760/3877 Loss=3.1038 Acc=37.74%\n",
      "Epoch 3 Train batch 770/3877 Loss=3.1033 Acc=37.76%\n",
      "Epoch 3 Train batch 780/3877 Loss=3.1044 Acc=37.74%\n",
      "Epoch 3 Train batch 790/3877 Loss=3.1036 Acc=37.74%\n",
      "Epoch 3 Train batch 800/3877 Loss=3.1032 Acc=37.74%\n",
      "Epoch 3 Train batch 810/3877 Loss=3.1021 Acc=37.75%\n",
      "Epoch 3 Train batch 820/3877 Loss=3.1022 Acc=37.75%\n",
      "Epoch 3 Train batch 830/3877 Loss=3.1028 Acc=37.74%\n",
      "Epoch 3 Train batch 840/3877 Loss=3.1033 Acc=37.73%\n",
      "Epoch 3 Train batch 850/3877 Loss=3.1038 Acc=37.73%\n",
      "Epoch 3 Train batch 860/3877 Loss=3.1036 Acc=37.74%\n",
      "Epoch 3 Train batch 870/3877 Loss=3.1033 Acc=37.74%\n",
      "Epoch 3 Train batch 880/3877 Loss=3.1043 Acc=37.72%\n",
      "Epoch 3 Train batch 890/3877 Loss=3.1036 Acc=37.73%\n",
      "Epoch 3 Train batch 900/3877 Loss=3.1033 Acc=37.73%\n",
      "Epoch 3 Train batch 910/3877 Loss=3.1032 Acc=37.73%\n",
      "Epoch 3 Train batch 920/3877 Loss=3.1028 Acc=37.73%\n",
      "Epoch 3 Train batch 930/3877 Loss=3.1034 Acc=37.71%\n",
      "Epoch 3 Train batch 940/3877 Loss=3.1039 Acc=37.70%\n",
      "Epoch 3 Train batch 950/3877 Loss=3.1031 Acc=37.70%\n",
      "Epoch 3 Train batch 960/3877 Loss=3.1035 Acc=37.69%\n",
      "Epoch 3 Train batch 970/3877 Loss=3.1038 Acc=37.70%\n",
      "Epoch 3 Train batch 980/3877 Loss=3.1039 Acc=37.69%\n",
      "Epoch 3 Train batch 990/3877 Loss=3.1039 Acc=37.68%\n",
      "Epoch 3 Train batch 1000/3877 Loss=3.1036 Acc=37.69%\n",
      "Epoch 3 Train batch 1010/3877 Loss=3.1040 Acc=37.68%\n",
      "Epoch 3 Train batch 1020/3877 Loss=3.1041 Acc=37.68%\n",
      "Epoch 3 Train batch 1030/3877 Loss=3.1046 Acc=37.69%\n",
      "Epoch 3 Train batch 1040/3877 Loss=3.1044 Acc=37.68%\n",
      "Epoch 3 Train batch 1050/3877 Loss=3.1048 Acc=37.67%\n",
      "Epoch 3 Train batch 1060/3877 Loss=3.1048 Acc=37.67%\n",
      "Epoch 3 Train batch 1070/3877 Loss=3.1049 Acc=37.66%\n",
      "Epoch 3 Train batch 1080/3877 Loss=3.1048 Acc=37.66%\n",
      "Epoch 3 Train batch 1090/3877 Loss=3.1048 Acc=37.66%\n",
      "Epoch 3 Train batch 1100/3877 Loss=3.1039 Acc=37.67%\n",
      "Epoch 3 Train batch 1110/3877 Loss=3.1039 Acc=37.67%\n",
      "Epoch 3 Train batch 1120/3877 Loss=3.1042 Acc=37.66%\n",
      "Epoch 3 Train batch 1130/3877 Loss=3.1040 Acc=37.66%\n",
      "Epoch 3 Train batch 1140/3877 Loss=3.1042 Acc=37.66%\n",
      "Epoch 3 Train batch 1150/3877 Loss=3.1041 Acc=37.66%\n",
      "Epoch 3 Train batch 1160/3877 Loss=3.1033 Acc=37.67%\n",
      "Epoch 3 Train batch 1170/3877 Loss=3.1032 Acc=37.67%\n",
      "Epoch 3 Train batch 1180/3877 Loss=3.1032 Acc=37.67%\n",
      "Epoch 3 Train batch 1190/3877 Loss=3.1040 Acc=37.66%\n",
      "Epoch 3 Train batch 1200/3877 Loss=3.1043 Acc=37.65%\n",
      "Epoch 3 Train batch 1210/3877 Loss=3.1048 Acc=37.64%\n",
      "Epoch 3 Train batch 1220/3877 Loss=3.1056 Acc=37.63%\n",
      "Epoch 3 Train batch 1230/3877 Loss=3.1053 Acc=37.64%\n",
      "Epoch 3 Train batch 1240/3877 Loss=3.1057 Acc=37.62%\n",
      "Epoch 3 Train batch 1250/3877 Loss=3.1051 Acc=37.63%\n",
      "Epoch 3 Train batch 1260/3877 Loss=3.1053 Acc=37.61%\n",
      "Epoch 3 Train batch 1270/3877 Loss=3.1047 Acc=37.63%\n",
      "Epoch 3 Train batch 1280/3877 Loss=3.1057 Acc=37.63%\n",
      "Epoch 3 Train batch 1290/3877 Loss=3.1054 Acc=37.64%\n",
      "Epoch 3 Train batch 1300/3877 Loss=3.1053 Acc=37.63%\n",
      "Epoch 3 Train batch 1310/3877 Loss=3.1053 Acc=37.64%\n",
      "Epoch 3 Train batch 1320/3877 Loss=3.1049 Acc=37.65%\n",
      "Epoch 3 Train batch 1330/3877 Loss=3.1056 Acc=37.64%\n",
      "Epoch 3 Train batch 1340/3877 Loss=3.1055 Acc=37.64%\n",
      "Epoch 3 Train batch 1350/3877 Loss=3.1056 Acc=37.64%\n",
      "Epoch 3 Train batch 1360/3877 Loss=3.1054 Acc=37.64%\n",
      "Epoch 3 Train batch 1370/3877 Loss=3.1052 Acc=37.65%\n",
      "Epoch 3 Train batch 1380/3877 Loss=3.1053 Acc=37.65%\n",
      "Epoch 3 Train batch 1390/3877 Loss=3.1055 Acc=37.65%\n",
      "Epoch 3 Train batch 1400/3877 Loss=3.1052 Acc=37.66%\n",
      "Epoch 3 Train batch 1410/3877 Loss=3.1053 Acc=37.65%\n",
      "Epoch 3 Train batch 1420/3877 Loss=3.1057 Acc=37.65%\n",
      "Epoch 3 Train batch 1430/3877 Loss=3.1061 Acc=37.64%\n",
      "Epoch 3 Train batch 1440/3877 Loss=3.1063 Acc=37.63%\n",
      "Epoch 3 Train batch 1450/3877 Loss=3.1058 Acc=37.63%\n",
      "Epoch 3 Train batch 1460/3877 Loss=3.1062 Acc=37.63%\n",
      "Epoch 3 Train batch 1470/3877 Loss=3.1060 Acc=37.63%\n",
      "Epoch 3 Train batch 1480/3877 Loss=3.1057 Acc=37.63%\n",
      "Epoch 3 Train batch 1490/3877 Loss=3.1053 Acc=37.64%\n",
      "Epoch 3 Train batch 1500/3877 Loss=3.1050 Acc=37.64%\n",
      "Epoch 3 Train batch 1510/3877 Loss=3.1047 Acc=37.65%\n",
      "Epoch 3 Train batch 1520/3877 Loss=3.1045 Acc=37.66%\n",
      "Epoch 3 Train batch 1530/3877 Loss=3.1045 Acc=37.65%\n",
      "Epoch 3 Train batch 1540/3877 Loss=3.1045 Acc=37.66%\n",
      "Epoch 3 Train batch 1550/3877 Loss=3.1040 Acc=37.67%\n",
      "Epoch 3 Train batch 1560/3877 Loss=3.1041 Acc=37.66%\n",
      "Epoch 3 Train batch 1570/3877 Loss=3.1041 Acc=37.67%\n",
      "Epoch 3 Train batch 1580/3877 Loss=3.1037 Acc=37.67%\n",
      "Epoch 3 Train batch 1590/3877 Loss=3.1038 Acc=37.67%\n",
      "Epoch 3 Train batch 1600/3877 Loss=3.1037 Acc=37.67%\n",
      "Epoch 3 Train batch 1610/3877 Loss=3.1034 Acc=37.67%\n",
      "Epoch 3 Train batch 1620/3877 Loss=3.1036 Acc=37.66%\n",
      "Epoch 3 Train batch 1630/3877 Loss=3.1034 Acc=37.66%\n",
      "Epoch 3 Train batch 1640/3877 Loss=3.1035 Acc=37.66%\n",
      "Epoch 3 Train batch 1650/3877 Loss=3.1035 Acc=37.65%\n",
      "Epoch 3 Train batch 1660/3877 Loss=3.1032 Acc=37.65%\n",
      "Epoch 3 Train batch 1670/3877 Loss=3.1024 Acc=37.66%\n",
      "Epoch 3 Train batch 1680/3877 Loss=3.1019 Acc=37.67%\n",
      "Epoch 3 Train batch 1690/3877 Loss=3.1019 Acc=37.67%\n",
      "Epoch 3 Train batch 1700/3877 Loss=3.1021 Acc=37.66%\n",
      "Epoch 3 Train batch 1710/3877 Loss=3.1021 Acc=37.66%\n",
      "Epoch 3 Train batch 1720/3877 Loss=3.1020 Acc=37.66%\n",
      "Epoch 3 Train batch 1730/3877 Loss=3.1021 Acc=37.66%\n",
      "Epoch 3 Train batch 1740/3877 Loss=3.1021 Acc=37.66%\n",
      "Epoch 3 Train batch 1750/3877 Loss=3.1020 Acc=37.66%\n",
      "Epoch 3 Train batch 1760/3877 Loss=3.1017 Acc=37.66%\n",
      "Epoch 3 Train batch 1770/3877 Loss=3.1018 Acc=37.66%\n",
      "Epoch 3 Train batch 1780/3877 Loss=3.1017 Acc=37.66%\n",
      "Epoch 3 Train batch 1790/3877 Loss=3.1021 Acc=37.66%\n",
      "Epoch 3 Train batch 1800/3877 Loss=3.1022 Acc=37.66%\n",
      "Epoch 3 Train batch 1810/3877 Loss=3.1026 Acc=37.65%\n",
      "Epoch 3 Train batch 1820/3877 Loss=3.1027 Acc=37.65%\n",
      "Epoch 3 Train batch 1830/3877 Loss=3.1023 Acc=37.66%\n",
      "Epoch 3 Train batch 1840/3877 Loss=3.1021 Acc=37.66%\n",
      "Epoch 3 Train batch 1850/3877 Loss=3.1025 Acc=37.66%\n",
      "Epoch 3 Train batch 1860/3877 Loss=3.1027 Acc=37.66%\n",
      "Epoch 3 Train batch 1870/3877 Loss=3.1024 Acc=37.66%\n",
      "Epoch 3 Train batch 1880/3877 Loss=3.1026 Acc=37.66%\n",
      "Epoch 3 Train batch 1890/3877 Loss=3.1024 Acc=37.66%\n",
      "Epoch 3 Train batch 1900/3877 Loss=3.1023 Acc=37.66%\n",
      "Epoch 3 Train batch 1910/3877 Loss=3.1023 Acc=37.66%\n",
      "Epoch 3 Train batch 1920/3877 Loss=3.1024 Acc=37.67%\n",
      "Epoch 3 Train batch 1930/3877 Loss=3.1020 Acc=37.67%\n",
      "Epoch 3 Train batch 1940/3877 Loss=3.1020 Acc=37.67%\n",
      "Epoch 3 Train batch 1950/3877 Loss=3.1020 Acc=37.66%\n",
      "Epoch 3 Train batch 1960/3877 Loss=3.1019 Acc=37.67%\n",
      "Epoch 3 Train batch 1970/3877 Loss=3.1022 Acc=37.66%\n",
      "Epoch 3 Train batch 1980/3877 Loss=3.1019 Acc=37.67%\n",
      "Epoch 3 Train batch 1990/3877 Loss=3.1017 Acc=37.66%\n",
      "Epoch 3 Train batch 2000/3877 Loss=3.1019 Acc=37.66%\n",
      "Epoch 3 Train batch 2010/3877 Loss=3.1016 Acc=37.66%\n",
      "Epoch 3 Train batch 2020/3877 Loss=3.1018 Acc=37.66%\n",
      "Epoch 3 Train batch 2030/3877 Loss=3.1017 Acc=37.66%\n",
      "Epoch 3 Train batch 2040/3877 Loss=3.1017 Acc=37.66%\n",
      "Epoch 3 Train batch 2050/3877 Loss=3.1015 Acc=37.66%\n",
      "Epoch 3 Train batch 2060/3877 Loss=3.1014 Acc=37.66%\n",
      "Epoch 3 Train batch 2070/3877 Loss=3.1014 Acc=37.65%\n",
      "Epoch 3 Train batch 2080/3877 Loss=3.1015 Acc=37.65%\n",
      "Epoch 3 Train batch 2090/3877 Loss=3.1014 Acc=37.65%\n",
      "Epoch 3 Train batch 2100/3877 Loss=3.1012 Acc=37.65%\n",
      "Epoch 3 Train batch 2110/3877 Loss=3.1013 Acc=37.65%\n",
      "Epoch 3 Train batch 2120/3877 Loss=3.1013 Acc=37.65%\n",
      "Epoch 3 Train batch 2130/3877 Loss=3.1010 Acc=37.65%\n",
      "Epoch 3 Train batch 2140/3877 Loss=3.1013 Acc=37.64%\n",
      "Epoch 3 Train batch 2150/3877 Loss=3.1016 Acc=37.64%\n",
      "Epoch 3 Train batch 2160/3877 Loss=3.1018 Acc=37.64%\n",
      "Epoch 3 Train batch 2170/3877 Loss=3.1018 Acc=37.64%\n",
      "Epoch 3 Train batch 2180/3877 Loss=3.1022 Acc=37.63%\n",
      "Epoch 3 Train batch 2190/3877 Loss=3.1021 Acc=37.64%\n",
      "Epoch 3 Train batch 2200/3877 Loss=3.1021 Acc=37.63%\n",
      "Epoch 3 Train batch 2210/3877 Loss=3.1015 Acc=37.64%\n",
      "Epoch 3 Train batch 2220/3877 Loss=3.1016 Acc=37.64%\n",
      "Epoch 3 Train batch 2230/3877 Loss=3.1018 Acc=37.63%\n",
      "Epoch 3 Train batch 2240/3877 Loss=3.1015 Acc=37.63%\n",
      "Epoch 3 Train batch 2250/3877 Loss=3.1017 Acc=37.63%\n",
      "Epoch 3 Train batch 2260/3877 Loss=3.1016 Acc=37.63%\n",
      "Epoch 3 Train batch 2270/3877 Loss=3.1015 Acc=37.63%\n",
      "Epoch 3 Train batch 2280/3877 Loss=3.1015 Acc=37.63%\n",
      "Epoch 3 Train batch 2290/3877 Loss=3.1018 Acc=37.63%\n",
      "Epoch 3 Train batch 2300/3877 Loss=3.1017 Acc=37.63%\n",
      "Epoch 3 Train batch 2310/3877 Loss=3.1018 Acc=37.63%\n",
      "Epoch 3 Train batch 2320/3877 Loss=3.1016 Acc=37.63%\n",
      "Epoch 3 Train batch 2330/3877 Loss=3.1014 Acc=37.63%\n",
      "Epoch 3 Train batch 2340/3877 Loss=3.1018 Acc=37.63%\n",
      "Epoch 3 Train batch 2350/3877 Loss=3.1021 Acc=37.62%\n",
      "Epoch 3 Train batch 2360/3877 Loss=3.1021 Acc=37.62%\n",
      "Epoch 3 Train batch 2370/3877 Loss=3.1019 Acc=37.62%\n",
      "Epoch 3 Train batch 2380/3877 Loss=3.1017 Acc=37.62%\n",
      "Epoch 3 Train batch 2390/3877 Loss=3.1017 Acc=37.62%\n",
      "Epoch 3 Train batch 2400/3877 Loss=3.1014 Acc=37.62%\n",
      "Epoch 3 Train batch 2410/3877 Loss=3.1015 Acc=37.62%\n",
      "Epoch 3 Train batch 2420/3877 Loss=3.1013 Acc=37.62%\n",
      "Epoch 3 Train batch 2430/3877 Loss=3.1013 Acc=37.62%\n",
      "Epoch 3 Train batch 2440/3877 Loss=3.1012 Acc=37.62%\n",
      "Epoch 3 Train batch 2450/3877 Loss=3.1011 Acc=37.62%\n",
      "Epoch 3 Train batch 2460/3877 Loss=3.1009 Acc=37.62%\n",
      "Epoch 3 Train batch 2470/3877 Loss=3.1007 Acc=37.62%\n",
      "Epoch 3 Train batch 2480/3877 Loss=3.1009 Acc=37.62%\n",
      "Epoch 3 Train batch 2490/3877 Loss=3.1008 Acc=37.61%\n",
      "Epoch 3 Train batch 2500/3877 Loss=3.1009 Acc=37.62%\n",
      "Epoch 3 Train batch 2510/3877 Loss=3.1010 Acc=37.61%\n",
      "Epoch 3 Train batch 2520/3877 Loss=3.1008 Acc=37.61%\n",
      "Epoch 3 Train batch 2530/3877 Loss=3.1010 Acc=37.61%\n",
      "Epoch 3 Train batch 2540/3877 Loss=3.1011 Acc=37.61%\n",
      "Epoch 3 Train batch 2550/3877 Loss=3.1014 Acc=37.61%\n",
      "Epoch 3 Train batch 2560/3877 Loss=3.1015 Acc=37.61%\n",
      "Epoch 3 Train batch 2570/3877 Loss=3.1016 Acc=37.61%\n",
      "Epoch 3 Train batch 2580/3877 Loss=3.1017 Acc=37.61%\n",
      "Epoch 3 Train batch 2590/3877 Loss=3.1018 Acc=37.61%\n",
      "Epoch 3 Train batch 2600/3877 Loss=3.1018 Acc=37.61%\n",
      "Epoch 3 Train batch 2610/3877 Loss=3.1017 Acc=37.61%\n",
      "Epoch 3 Train batch 2620/3877 Loss=3.1018 Acc=37.60%\n",
      "Epoch 3 Train batch 2630/3877 Loss=3.1018 Acc=37.60%\n",
      "Epoch 3 Train batch 2640/3877 Loss=3.1019 Acc=37.60%\n",
      "Epoch 3 Train batch 2650/3877 Loss=3.1017 Acc=37.60%\n",
      "Epoch 3 Train batch 2660/3877 Loss=3.1016 Acc=37.60%\n",
      "Epoch 3 Train batch 2670/3877 Loss=3.1013 Acc=37.61%\n",
      "Epoch 3 Train batch 2680/3877 Loss=3.1016 Acc=37.61%\n",
      "Epoch 3 Train batch 2690/3877 Loss=3.1013 Acc=37.61%\n",
      "Epoch 3 Train batch 2700/3877 Loss=3.1015 Acc=37.61%\n",
      "Epoch 3 Train batch 2710/3877 Loss=3.1014 Acc=37.60%\n",
      "Epoch 3 Train batch 2720/3877 Loss=3.1016 Acc=37.60%\n",
      "Epoch 3 Train batch 2730/3877 Loss=3.1012 Acc=37.60%\n",
      "Epoch 3 Train batch 2740/3877 Loss=3.1013 Acc=37.60%\n",
      "Epoch 3 Train batch 2750/3877 Loss=3.1014 Acc=37.60%\n",
      "Epoch 3 Train batch 2760/3877 Loss=3.1012 Acc=37.60%\n",
      "Epoch 3 Train batch 2770/3877 Loss=3.1012 Acc=37.60%\n",
      "Epoch 3 Train batch 2780/3877 Loss=3.1013 Acc=37.59%\n",
      "Epoch 3 Train batch 2790/3877 Loss=3.1012 Acc=37.60%\n",
      "Epoch 3 Train batch 2800/3877 Loss=3.1010 Acc=37.60%\n",
      "Epoch 3 Train batch 2810/3877 Loss=3.1009 Acc=37.60%\n",
      "Epoch 3 Train batch 2820/3877 Loss=3.1012 Acc=37.60%\n",
      "Epoch 3 Train batch 2830/3877 Loss=3.1014 Acc=37.60%\n",
      "Epoch 3 Train batch 2840/3877 Loss=3.1014 Acc=37.60%\n",
      "Epoch 3 Train batch 2850/3877 Loss=3.1015 Acc=37.59%\n",
      "Epoch 3 Train batch 2860/3877 Loss=3.1015 Acc=37.59%\n",
      "Epoch 3 Train batch 2870/3877 Loss=3.1014 Acc=37.59%\n",
      "Epoch 3 Train batch 2880/3877 Loss=3.1016 Acc=37.59%\n",
      "Epoch 3 Train batch 2890/3877 Loss=3.1018 Acc=37.59%\n",
      "Epoch 3 Train batch 2900/3877 Loss=3.1017 Acc=37.59%\n",
      "Epoch 3 Train batch 2910/3877 Loss=3.1017 Acc=37.59%\n",
      "Epoch 3 Train batch 2920/3877 Loss=3.1016 Acc=37.59%\n",
      "Epoch 3 Train batch 2930/3877 Loss=3.1013 Acc=37.59%\n",
      "Epoch 3 Train batch 2940/3877 Loss=3.1013 Acc=37.59%\n",
      "Epoch 3 Train batch 2950/3877 Loss=3.1013 Acc=37.59%\n",
      "Epoch 3 Train batch 2960/3877 Loss=3.1010 Acc=37.59%\n",
      "Epoch 3 Train batch 2970/3877 Loss=3.1009 Acc=37.59%\n",
      "Epoch 3 Train batch 2980/3877 Loss=3.1007 Acc=37.59%\n",
      "Epoch 3 Train batch 2990/3877 Loss=3.1005 Acc=37.59%\n",
      "Epoch 3 Train batch 3000/3877 Loss=3.1004 Acc=37.59%\n",
      "Epoch 3 Train batch 3010/3877 Loss=3.1004 Acc=37.59%\n",
      "Epoch 3 Train batch 3020/3877 Loss=3.1005 Acc=37.59%\n",
      "Epoch 3 Train batch 3030/3877 Loss=3.1004 Acc=37.59%\n",
      "Epoch 3 Train batch 3040/3877 Loss=3.1004 Acc=37.59%\n",
      "Epoch 3 Train batch 3050/3877 Loss=3.1002 Acc=37.60%\n",
      "Epoch 3 Train batch 3060/3877 Loss=3.1002 Acc=37.60%\n",
      "Epoch 3 Train batch 3070/3877 Loss=3.1001 Acc=37.59%\n",
      "Epoch 3 Train batch 3080/3877 Loss=3.1001 Acc=37.59%\n",
      "Epoch 3 Train batch 3090/3877 Loss=3.0999 Acc=37.60%\n",
      "Epoch 3 Train batch 3100/3877 Loss=3.0998 Acc=37.60%\n",
      "Epoch 3 Train batch 3110/3877 Loss=3.1000 Acc=37.59%\n",
      "Epoch 3 Train batch 3120/3877 Loss=3.1002 Acc=37.59%\n",
      "Epoch 3 Train batch 3130/3877 Loss=3.1002 Acc=37.59%\n",
      "Epoch 3 Train batch 3140/3877 Loss=3.1002 Acc=37.59%\n",
      "Epoch 3 Train batch 3150/3877 Loss=3.1004 Acc=37.59%\n",
      "Epoch 3 Train batch 3160/3877 Loss=3.1005 Acc=37.59%\n",
      "Epoch 3 Train batch 3170/3877 Loss=3.1003 Acc=37.59%\n",
      "Epoch 3 Train batch 3180/3877 Loss=3.1005 Acc=37.59%\n",
      "Epoch 3 Train batch 3190/3877 Loss=3.1005 Acc=37.59%\n",
      "Epoch 3 Train batch 3200/3877 Loss=3.1003 Acc=37.59%\n",
      "Epoch 3 Train batch 3210/3877 Loss=3.1001 Acc=37.59%\n",
      "Epoch 3 Train batch 3220/3877 Loss=3.1000 Acc=37.60%\n",
      "Epoch 3 Train batch 3230/3877 Loss=3.0999 Acc=37.60%\n",
      "Epoch 3 Train batch 3240/3877 Loss=3.0996 Acc=37.60%\n",
      "Epoch 3 Train batch 3250/3877 Loss=3.0999 Acc=37.60%\n",
      "Epoch 3 Train batch 3260/3877 Loss=3.0999 Acc=37.60%\n",
      "Epoch 3 Train batch 3270/3877 Loss=3.0998 Acc=37.60%\n",
      "Epoch 3 Train batch 3280/3877 Loss=3.0999 Acc=37.60%\n",
      "Epoch 3 Train batch 3290/3877 Loss=3.0998 Acc=37.60%\n",
      "Epoch 3 Train batch 3300/3877 Loss=3.0997 Acc=37.60%\n",
      "Epoch 3 Train batch 3310/3877 Loss=3.1001 Acc=37.59%\n",
      "Epoch 3 Train batch 3320/3877 Loss=3.1001 Acc=37.60%\n",
      "Epoch 3 Train batch 3330/3877 Loss=3.0998 Acc=37.60%\n",
      "Epoch 3 Train batch 3340/3877 Loss=3.0995 Acc=37.60%\n",
      "Epoch 3 Train batch 3350/3877 Loss=3.0997 Acc=37.60%\n",
      "Epoch 3 Train batch 3360/3877 Loss=3.0997 Acc=37.60%\n",
      "Epoch 3 Train batch 3370/3877 Loss=3.0997 Acc=37.60%\n",
      "Epoch 3 Train batch 3380/3877 Loss=3.0994 Acc=37.60%\n",
      "Epoch 3 Train batch 3390/3877 Loss=3.0994 Acc=37.60%\n",
      "Epoch 3 Train batch 3400/3877 Loss=3.0994 Acc=37.60%\n",
      "Epoch 3 Train batch 3410/3877 Loss=3.0994 Acc=37.60%\n",
      "Epoch 3 Train batch 3420/3877 Loss=3.0993 Acc=37.60%\n",
      "Epoch 3 Train batch 3430/3877 Loss=3.0992 Acc=37.60%\n",
      "Epoch 3 Train batch 3440/3877 Loss=3.0993 Acc=37.60%\n",
      "Epoch 3 Train batch 3450/3877 Loss=3.0993 Acc=37.60%\n",
      "Epoch 3 Train batch 3460/3877 Loss=3.0992 Acc=37.60%\n",
      "Epoch 3 Train batch 3470/3877 Loss=3.0990 Acc=37.60%\n",
      "Epoch 3 Train batch 3480/3877 Loss=3.0991 Acc=37.60%\n",
      "Epoch 3 Train batch 3490/3877 Loss=3.0989 Acc=37.60%\n",
      "Epoch 3 Train batch 3500/3877 Loss=3.0987 Acc=37.60%\n",
      "Epoch 3 Train batch 3510/3877 Loss=3.0988 Acc=37.60%\n",
      "Epoch 3 Train batch 3520/3877 Loss=3.0986 Acc=37.60%\n",
      "Epoch 3 Train batch 3530/3877 Loss=3.0986 Acc=37.60%\n",
      "Epoch 3 Train batch 3540/3877 Loss=3.0985 Acc=37.60%\n",
      "Epoch 3 Train batch 3550/3877 Loss=3.0983 Acc=37.61%\n",
      "Epoch 3 Train batch 3560/3877 Loss=3.0981 Acc=37.61%\n",
      "Epoch 3 Train batch 3570/3877 Loss=3.0980 Acc=37.61%\n",
      "Epoch 3 Train batch 3580/3877 Loss=3.0975 Acc=37.61%\n",
      "Epoch 3 Train batch 3590/3877 Loss=3.0971 Acc=37.62%\n",
      "Epoch 3 Train batch 3600/3877 Loss=3.0971 Acc=37.62%\n",
      "Epoch 3 Train batch 3610/3877 Loss=3.0971 Acc=37.62%\n",
      "Epoch 3 Train batch 3620/3877 Loss=3.0970 Acc=37.62%\n",
      "Epoch 3 Train batch 3630/3877 Loss=3.0968 Acc=37.62%\n",
      "Epoch 3 Train batch 3640/3877 Loss=3.0968 Acc=37.63%\n",
      "Epoch 3 Train batch 3650/3877 Loss=3.0966 Acc=37.63%\n",
      "Epoch 3 Train batch 3660/3877 Loss=3.0966 Acc=37.63%\n",
      "Epoch 3 Train batch 3670/3877 Loss=3.0965 Acc=37.63%\n",
      "Epoch 3 Train batch 3680/3877 Loss=3.0966 Acc=37.63%\n",
      "Epoch 3 Train batch 3690/3877 Loss=3.0966 Acc=37.63%\n",
      "Epoch 3 Train batch 3700/3877 Loss=3.0964 Acc=37.63%\n",
      "Epoch 3 Train batch 3710/3877 Loss=3.0962 Acc=37.64%\n",
      "Epoch 3 Train batch 3720/3877 Loss=3.0961 Acc=37.64%\n",
      "Epoch 3 Train batch 3730/3877 Loss=3.0961 Acc=37.64%\n",
      "Epoch 3 Train batch 3740/3877 Loss=3.0960 Acc=37.63%\n",
      "Epoch 3 Train batch 3750/3877 Loss=3.0960 Acc=37.63%\n",
      "Epoch 3 Train batch 3760/3877 Loss=3.0961 Acc=37.63%\n",
      "Epoch 3 Train batch 3770/3877 Loss=3.0961 Acc=37.64%\n",
      "Epoch 3 Train batch 3780/3877 Loss=3.0959 Acc=37.63%\n",
      "Epoch 3 Train batch 3790/3877 Loss=3.0959 Acc=37.63%\n",
      "Epoch 3 Train batch 3800/3877 Loss=3.0960 Acc=37.63%\n",
      "Epoch 3 Train batch 3810/3877 Loss=3.0963 Acc=37.63%\n",
      "Epoch 3 Train batch 3820/3877 Loss=3.0962 Acc=37.62%\n",
      "Epoch 3 Train batch 3830/3877 Loss=3.0961 Acc=37.63%\n",
      "Epoch 3 Train batch 3840/3877 Loss=3.0958 Acc=37.63%\n",
      "Epoch 3 Train batch 3850/3877 Loss=3.0957 Acc=37.63%\n",
      "Epoch 3 Train batch 3860/3877 Loss=3.0957 Acc=37.63%\n",
      "Epoch 3 Train batch 3870/3877 Loss=3.0956 Acc=37.63%\n",
      "Epoch 3 Train batch 3877/3877 Loss=3.0955 Acc=37.63%\n",
      "Epoch 3/5 train_loss=3.0955 train_acc=37.63% val_loss=3.1255 val_acc=37.89%\n",
      "Epoch 4 Train batch 10/3877 Loss=2.9221 Acc=38.88%\n",
      "Epoch 4 Train batch 20/3877 Loss=2.9320 Acc=38.68%\n",
      "Epoch 4 Train batch 30/3877 Loss=2.9516 Acc=38.47%\n",
      "Epoch 4 Train batch 40/3877 Loss=2.9288 Acc=38.74%\n",
      "Epoch 4 Train batch 50/3877 Loss=2.9302 Acc=38.85%\n",
      "Epoch 4 Train batch 60/3877 Loss=2.9347 Acc=38.83%\n",
      "Epoch 4 Train batch 70/3877 Loss=2.9375 Acc=38.86%\n",
      "Epoch 4 Train batch 80/3877 Loss=2.9333 Acc=38.92%\n",
      "Epoch 4 Train batch 90/3877 Loss=2.9398 Acc=38.78%\n",
      "Epoch 4 Train batch 100/3877 Loss=2.9342 Acc=38.89%\n",
      "Epoch 4 Train batch 110/3877 Loss=2.9362 Acc=38.90%\n",
      "Epoch 4 Train batch 120/3877 Loss=2.9435 Acc=38.83%\n",
      "Epoch 4 Train batch 130/3877 Loss=2.9455 Acc=38.77%\n",
      "Epoch 4 Train batch 140/3877 Loss=2.9462 Acc=38.81%\n",
      "Epoch 4 Train batch 150/3877 Loss=2.9435 Acc=38.85%\n",
      "Epoch 4 Train batch 160/3877 Loss=2.9412 Acc=38.85%\n",
      "Epoch 4 Train batch 170/3877 Loss=2.9371 Acc=38.89%\n",
      "Epoch 4 Train batch 180/3877 Loss=2.9407 Acc=38.83%\n",
      "Epoch 4 Train batch 190/3877 Loss=2.9397 Acc=38.87%\n",
      "Epoch 4 Train batch 200/3877 Loss=2.9440 Acc=38.87%\n",
      "Epoch 4 Train batch 210/3877 Loss=2.9445 Acc=38.87%\n",
      "Epoch 4 Train batch 220/3877 Loss=2.9426 Acc=38.89%\n",
      "Epoch 4 Train batch 230/3877 Loss=2.9436 Acc=38.88%\n",
      "Epoch 4 Train batch 240/3877 Loss=2.9447 Acc=38.90%\n",
      "Epoch 4 Train batch 250/3877 Loss=2.9473 Acc=38.85%\n",
      "Epoch 4 Train batch 260/3877 Loss=2.9506 Acc=38.79%\n",
      "Epoch 4 Train batch 270/3877 Loss=2.9503 Acc=38.80%\n",
      "Epoch 4 Train batch 280/3877 Loss=2.9498 Acc=38.78%\n",
      "Epoch 4 Train batch 290/3877 Loss=2.9501 Acc=38.82%\n",
      "Epoch 4 Train batch 300/3877 Loss=2.9504 Acc=38.83%\n",
      "Epoch 4 Train batch 310/3877 Loss=2.9495 Acc=38.87%\n",
      "Epoch 4 Train batch 320/3877 Loss=2.9486 Acc=38.86%\n",
      "Epoch 4 Train batch 330/3877 Loss=2.9461 Acc=38.90%\n",
      "Epoch 4 Train batch 340/3877 Loss=2.9463 Acc=38.90%\n",
      "Epoch 4 Train batch 350/3877 Loss=2.9465 Acc=38.91%\n",
      "Epoch 4 Train batch 360/3877 Loss=2.9467 Acc=38.88%\n",
      "Epoch 4 Train batch 370/3877 Loss=2.9460 Acc=38.88%\n",
      "Epoch 4 Train batch 380/3877 Loss=2.9488 Acc=38.87%\n",
      "Epoch 4 Train batch 390/3877 Loss=2.9483 Acc=38.87%\n",
      "Epoch 4 Train batch 400/3877 Loss=2.9472 Acc=38.90%\n",
      "Epoch 4 Train batch 410/3877 Loss=2.9476 Acc=38.90%\n",
      "Epoch 4 Train batch 420/3877 Loss=2.9490 Acc=38.87%\n",
      "Epoch 4 Train batch 430/3877 Loss=2.9478 Acc=38.89%\n",
      "Epoch 4 Train batch 440/3877 Loss=2.9480 Acc=38.90%\n",
      "Epoch 4 Train batch 450/3877 Loss=2.9497 Acc=38.86%\n",
      "Epoch 4 Train batch 460/3877 Loss=2.9499 Acc=38.86%\n",
      "Epoch 4 Train batch 470/3877 Loss=2.9494 Acc=38.86%\n",
      "Epoch 4 Train batch 480/3877 Loss=2.9503 Acc=38.84%\n",
      "Epoch 4 Train batch 490/3877 Loss=2.9495 Acc=38.87%\n",
      "Epoch 4 Train batch 500/3877 Loss=2.9504 Acc=38.85%\n",
      "Epoch 4 Train batch 510/3877 Loss=2.9492 Acc=38.87%\n",
      "Epoch 4 Train batch 520/3877 Loss=2.9500 Acc=38.87%\n",
      "Epoch 4 Train batch 530/3877 Loss=2.9523 Acc=38.84%\n",
      "Epoch 4 Train batch 540/3877 Loss=2.9524 Acc=38.84%\n",
      "Epoch 4 Train batch 550/3877 Loss=2.9531 Acc=38.86%\n",
      "Epoch 4 Train batch 560/3877 Loss=2.9528 Acc=38.88%\n",
      "Epoch 4 Train batch 570/3877 Loss=2.9519 Acc=38.89%\n",
      "Epoch 4 Train batch 580/3877 Loss=2.9529 Acc=38.88%\n",
      "Epoch 4 Train batch 590/3877 Loss=2.9533 Acc=38.88%\n",
      "Epoch 4 Train batch 600/3877 Loss=2.9534 Acc=38.87%\n",
      "Epoch 4 Train batch 610/3877 Loss=2.9539 Acc=38.87%\n",
      "Epoch 4 Train batch 620/3877 Loss=2.9540 Acc=38.90%\n",
      "Epoch 4 Train batch 630/3877 Loss=2.9537 Acc=38.89%\n",
      "Epoch 4 Train batch 640/3877 Loss=2.9554 Acc=38.86%\n",
      "Epoch 4 Train batch 650/3877 Loss=2.9552 Acc=38.87%\n",
      "Epoch 4 Train batch 660/3877 Loss=2.9552 Acc=38.88%\n",
      "Epoch 4 Train batch 670/3877 Loss=2.9565 Acc=38.85%\n",
      "Epoch 4 Train batch 680/3877 Loss=2.9555 Acc=38.85%\n",
      "Epoch 4 Train batch 690/3877 Loss=2.9564 Acc=38.84%\n",
      "Epoch 4 Train batch 700/3877 Loss=2.9562 Acc=38.85%\n",
      "Epoch 4 Train batch 710/3877 Loss=2.9564 Acc=38.83%\n",
      "Epoch 4 Train batch 720/3877 Loss=2.9569 Acc=38.83%\n",
      "Epoch 4 Train batch 730/3877 Loss=2.9571 Acc=38.83%\n",
      "Epoch 4 Train batch 740/3877 Loss=2.9570 Acc=38.82%\n",
      "Epoch 4 Train batch 750/3877 Loss=2.9579 Acc=38.81%\n",
      "Epoch 4 Train batch 760/3877 Loss=2.9571 Acc=38.82%\n",
      "Epoch 4 Train batch 770/3877 Loss=2.9575 Acc=38.82%\n",
      "Epoch 4 Train batch 780/3877 Loss=2.9576 Acc=38.81%\n",
      "Epoch 4 Train batch 790/3877 Loss=2.9576 Acc=38.81%\n",
      "Epoch 4 Train batch 800/3877 Loss=2.9578 Acc=38.81%\n",
      "Epoch 4 Train batch 810/3877 Loss=2.9583 Acc=38.81%\n",
      "Epoch 4 Train batch 820/3877 Loss=2.9588 Acc=38.81%\n",
      "Epoch 4 Train batch 830/3877 Loss=2.9587 Acc=38.82%\n",
      "Epoch 4 Train batch 840/3877 Loss=2.9588 Acc=38.82%\n",
      "Epoch 4 Train batch 850/3877 Loss=2.9593 Acc=38.80%\n",
      "Epoch 4 Train batch 860/3877 Loss=2.9591 Acc=38.80%\n",
      "Epoch 4 Train batch 870/3877 Loss=2.9595 Acc=38.79%\n",
      "Epoch 4 Train batch 880/3877 Loss=2.9598 Acc=38.79%\n",
      "Epoch 4 Train batch 890/3877 Loss=2.9592 Acc=38.79%\n",
      "Epoch 4 Train batch 900/3877 Loss=2.9597 Acc=38.79%\n",
      "Epoch 4 Train batch 910/3877 Loss=2.9590 Acc=38.78%\n",
      "Epoch 4 Train batch 920/3877 Loss=2.9583 Acc=38.80%\n",
      "Epoch 4 Train batch 930/3877 Loss=2.9581 Acc=38.80%\n",
      "Epoch 4 Train batch 940/3877 Loss=2.9586 Acc=38.79%\n",
      "Epoch 4 Train batch 950/3877 Loss=2.9582 Acc=38.79%\n",
      "Epoch 4 Train batch 960/3877 Loss=2.9578 Acc=38.79%\n",
      "Epoch 4 Train batch 970/3877 Loss=2.9577 Acc=38.80%\n",
      "Epoch 4 Train batch 980/3877 Loss=2.9577 Acc=38.79%\n",
      "Epoch 4 Train batch 990/3877 Loss=2.9576 Acc=38.79%\n",
      "Epoch 4 Train batch 1000/3877 Loss=2.9578 Acc=38.79%\n",
      "Epoch 4 Train batch 1010/3877 Loss=2.9578 Acc=38.80%\n",
      "Epoch 4 Train batch 1020/3877 Loss=2.9575 Acc=38.80%\n",
      "Epoch 4 Train batch 1030/3877 Loss=2.9575 Acc=38.80%\n",
      "Epoch 4 Train batch 1040/3877 Loss=2.9577 Acc=38.79%\n",
      "Epoch 4 Train batch 1050/3877 Loss=2.9576 Acc=38.80%\n",
      "Epoch 4 Train batch 1060/3877 Loss=2.9574 Acc=38.80%\n",
      "Epoch 4 Train batch 1070/3877 Loss=2.9572 Acc=38.80%\n",
      "Epoch 4 Train batch 1080/3877 Loss=2.9573 Acc=38.80%\n",
      "Epoch 4 Train batch 1090/3877 Loss=2.9572 Acc=38.80%\n",
      "Epoch 4 Train batch 1100/3877 Loss=2.9571 Acc=38.79%\n",
      "Epoch 4 Train batch 1110/3877 Loss=2.9565 Acc=38.79%\n",
      "Epoch 4 Train batch 1120/3877 Loss=2.9571 Acc=38.78%\n",
      "Epoch 4 Train batch 1130/3877 Loss=2.9571 Acc=38.78%\n",
      "Epoch 4 Train batch 1140/3877 Loss=2.9571 Acc=38.78%\n",
      "Epoch 4 Train batch 1150/3877 Loss=2.9559 Acc=38.78%\n",
      "Epoch 4 Train batch 1160/3877 Loss=2.9557 Acc=38.78%\n",
      "Epoch 4 Train batch 1170/3877 Loss=2.9560 Acc=38.78%\n",
      "Epoch 4 Train batch 1180/3877 Loss=2.9567 Acc=38.77%\n",
      "Epoch 4 Train batch 1190/3877 Loss=2.9575 Acc=38.76%\n",
      "Epoch 4 Train batch 1200/3877 Loss=2.9574 Acc=38.76%\n",
      "Epoch 4 Train batch 1210/3877 Loss=2.9569 Acc=38.77%\n",
      "Epoch 4 Train batch 1220/3877 Loss=2.9569 Acc=38.78%\n",
      "Epoch 4 Train batch 1230/3877 Loss=2.9568 Acc=38.78%\n",
      "Epoch 4 Train batch 1240/3877 Loss=2.9566 Acc=38.79%\n",
      "Epoch 4 Train batch 1250/3877 Loss=2.9567 Acc=38.78%\n",
      "Epoch 4 Train batch 1260/3877 Loss=2.9562 Acc=38.79%\n",
      "Epoch 4 Train batch 1270/3877 Loss=2.9566 Acc=38.79%\n",
      "Epoch 4 Train batch 1280/3877 Loss=2.9567 Acc=38.78%\n",
      "Epoch 4 Train batch 1290/3877 Loss=2.9565 Acc=38.78%\n",
      "Epoch 4 Train batch 1300/3877 Loss=2.9560 Acc=38.78%\n",
      "Epoch 4 Train batch 1310/3877 Loss=2.9557 Acc=38.78%\n",
      "Epoch 4 Train batch 1320/3877 Loss=2.9558 Acc=38.78%\n",
      "Epoch 4 Train batch 1330/3877 Loss=2.9555 Acc=38.79%\n",
      "Epoch 4 Train batch 1340/3877 Loss=2.9557 Acc=38.79%\n",
      "Epoch 4 Train batch 1350/3877 Loss=2.9551 Acc=38.79%\n",
      "Epoch 4 Train batch 1360/3877 Loss=2.9552 Acc=38.80%\n",
      "Epoch 4 Train batch 1370/3877 Loss=2.9553 Acc=38.80%\n",
      "Epoch 4 Train batch 1380/3877 Loss=2.9555 Acc=38.79%\n",
      "Epoch 4 Train batch 1390/3877 Loss=2.9556 Acc=38.79%\n",
      "Epoch 4 Train batch 1400/3877 Loss=2.9553 Acc=38.80%\n",
      "Epoch 4 Train batch 1410/3877 Loss=2.9554 Acc=38.80%\n",
      "Epoch 4 Train batch 1420/3877 Loss=2.9555 Acc=38.80%\n",
      "Epoch 4 Train batch 1430/3877 Loss=2.9558 Acc=38.80%\n",
      "Epoch 4 Train batch 1440/3877 Loss=2.9559 Acc=38.80%\n",
      "Epoch 4 Train batch 1450/3877 Loss=2.9557 Acc=38.80%\n",
      "Epoch 4 Train batch 1460/3877 Loss=2.9557 Acc=38.80%\n",
      "Epoch 4 Train batch 1470/3877 Loss=2.9556 Acc=38.80%\n",
      "Epoch 4 Train batch 1480/3877 Loss=2.9554 Acc=38.81%\n",
      "Epoch 4 Train batch 1490/3877 Loss=2.9554 Acc=38.81%\n",
      "Epoch 4 Train batch 1500/3877 Loss=2.9554 Acc=38.82%\n",
      "Epoch 4 Train batch 1510/3877 Loss=2.9556 Acc=38.82%\n",
      "Epoch 4 Train batch 1520/3877 Loss=2.9553 Acc=38.83%\n",
      "Epoch 4 Train batch 1530/3877 Loss=2.9556 Acc=38.82%\n",
      "Epoch 4 Train batch 1540/3877 Loss=2.9556 Acc=38.83%\n",
      "Epoch 4 Train batch 1550/3877 Loss=2.9556 Acc=38.83%\n",
      "Epoch 4 Train batch 1560/3877 Loss=2.9552 Acc=38.83%\n",
      "Epoch 4 Train batch 1570/3877 Loss=2.9555 Acc=38.83%\n",
      "Epoch 4 Train batch 1580/3877 Loss=2.9559 Acc=38.82%\n",
      "Epoch 4 Train batch 1590/3877 Loss=2.9562 Acc=38.82%\n",
      "Epoch 4 Train batch 1600/3877 Loss=2.9564 Acc=38.82%\n",
      "Epoch 4 Train batch 1610/3877 Loss=2.9565 Acc=38.82%\n",
      "Epoch 4 Train batch 1620/3877 Loss=2.9564 Acc=38.82%\n",
      "Epoch 4 Train batch 1630/3877 Loss=2.9565 Acc=38.82%\n",
      "Epoch 4 Train batch 1640/3877 Loss=2.9565 Acc=38.82%\n",
      "Epoch 4 Train batch 1650/3877 Loss=2.9563 Acc=38.82%\n",
      "Epoch 4 Train batch 1660/3877 Loss=2.9566 Acc=38.82%\n",
      "Epoch 4 Train batch 1670/3877 Loss=2.9567 Acc=38.81%\n",
      "Epoch 4 Train batch 1680/3877 Loss=2.9568 Acc=38.82%\n",
      "Epoch 4 Train batch 1690/3877 Loss=2.9577 Acc=38.81%\n",
      "Epoch 4 Train batch 1700/3877 Loss=2.9576 Acc=38.81%\n",
      "Epoch 4 Train batch 1710/3877 Loss=2.9571 Acc=38.81%\n",
      "Epoch 4 Train batch 1720/3877 Loss=2.9574 Acc=38.80%\n",
      "Epoch 4 Train batch 1730/3877 Loss=2.9576 Acc=38.80%\n",
      "Epoch 4 Train batch 1740/3877 Loss=2.9575 Acc=38.80%\n",
      "Epoch 4 Train batch 1750/3877 Loss=2.9581 Acc=38.79%\n",
      "Epoch 4 Train batch 1760/3877 Loss=2.9584 Acc=38.79%\n",
      "Epoch 4 Train batch 1770/3877 Loss=2.9582 Acc=38.79%\n",
      "Epoch 4 Train batch 1780/3877 Loss=2.9586 Acc=38.78%\n",
      "Epoch 4 Train batch 1790/3877 Loss=2.9587 Acc=38.79%\n",
      "Epoch 4 Train batch 1800/3877 Loss=2.9594 Acc=38.78%\n",
      "Epoch 4 Train batch 1810/3877 Loss=2.9597 Acc=38.77%\n",
      "Epoch 4 Train batch 1820/3877 Loss=2.9598 Acc=38.77%\n",
      "Epoch 4 Train batch 1830/3877 Loss=2.9599 Acc=38.77%\n",
      "Epoch 4 Train batch 1840/3877 Loss=2.9600 Acc=38.77%\n",
      "Epoch 4 Train batch 1850/3877 Loss=2.9598 Acc=38.76%\n",
      "Epoch 4 Train batch 1860/3877 Loss=2.9601 Acc=38.76%\n",
      "Epoch 4 Train batch 1870/3877 Loss=2.9600 Acc=38.76%\n",
      "Epoch 4 Train batch 1880/3877 Loss=2.9598 Acc=38.77%\n",
      "Epoch 4 Train batch 1890/3877 Loss=2.9597 Acc=38.77%\n",
      "Epoch 4 Train batch 1900/3877 Loss=2.9595 Acc=38.77%\n",
      "Epoch 4 Train batch 1910/3877 Loss=2.9591 Acc=38.77%\n",
      "Epoch 4 Train batch 1920/3877 Loss=2.9592 Acc=38.77%\n",
      "Epoch 4 Train batch 1930/3877 Loss=2.9590 Acc=38.77%\n",
      "Epoch 4 Train batch 1940/3877 Loss=2.9596 Acc=38.76%\n",
      "Epoch 4 Train batch 1950/3877 Loss=2.9594 Acc=38.77%\n",
      "Epoch 4 Train batch 1960/3877 Loss=2.9593 Acc=38.78%\n",
      "Epoch 4 Train batch 1970/3877 Loss=2.9594 Acc=38.77%\n",
      "Epoch 4 Train batch 1980/3877 Loss=2.9595 Acc=38.77%\n",
      "Epoch 4 Train batch 1990/3877 Loss=2.9596 Acc=38.77%\n",
      "Epoch 4 Train batch 2000/3877 Loss=2.9595 Acc=38.77%\n",
      "Epoch 4 Train batch 2010/3877 Loss=2.9596 Acc=38.77%\n",
      "Epoch 4 Train batch 2020/3877 Loss=2.9597 Acc=38.77%\n",
      "Epoch 4 Train batch 2030/3877 Loss=2.9601 Acc=38.77%\n",
      "Epoch 4 Train batch 2040/3877 Loss=2.9601 Acc=38.76%\n",
      "Epoch 4 Train batch 2050/3877 Loss=2.9600 Acc=38.76%\n",
      "Epoch 4 Train batch 2060/3877 Loss=2.9604 Acc=38.76%\n",
      "Epoch 4 Train batch 2070/3877 Loss=2.9604 Acc=38.76%\n",
      "Epoch 4 Train batch 2080/3877 Loss=2.9602 Acc=38.76%\n",
      "Epoch 4 Train batch 2090/3877 Loss=2.9603 Acc=38.76%\n",
      "Epoch 4 Train batch 2100/3877 Loss=2.9606 Acc=38.76%\n",
      "Epoch 4 Train batch 2110/3877 Loss=2.9604 Acc=38.76%\n",
      "Epoch 4 Train batch 2120/3877 Loss=2.9604 Acc=38.76%\n",
      "Epoch 4 Train batch 2130/3877 Loss=2.9602 Acc=38.76%\n",
      "Epoch 4 Train batch 2140/3877 Loss=2.9603 Acc=38.76%\n",
      "Epoch 4 Train batch 2150/3877 Loss=2.9600 Acc=38.76%\n",
      "Epoch 4 Train batch 2160/3877 Loss=2.9605 Acc=38.75%\n",
      "Epoch 4 Train batch 2170/3877 Loss=2.9607 Acc=38.75%\n",
      "Epoch 4 Train batch 2180/3877 Loss=2.9607 Acc=38.75%\n",
      "Epoch 4 Train batch 2190/3877 Loss=2.9605 Acc=38.75%\n",
      "Epoch 4 Train batch 2200/3877 Loss=2.9603 Acc=38.76%\n",
      "Epoch 4 Train batch 2210/3877 Loss=2.9601 Acc=38.76%\n",
      "Epoch 4 Train batch 2220/3877 Loss=2.9607 Acc=38.75%\n",
      "Epoch 4 Train batch 2230/3877 Loss=2.9609 Acc=38.75%\n",
      "Epoch 4 Train batch 2240/3877 Loss=2.9610 Acc=38.75%\n",
      "Epoch 4 Train batch 2250/3877 Loss=2.9612 Acc=38.75%\n",
      "Epoch 4 Train batch 2260/3877 Loss=2.9615 Acc=38.75%\n",
      "Epoch 4 Train batch 2270/3877 Loss=2.9618 Acc=38.75%\n",
      "Epoch 4 Train batch 2280/3877 Loss=2.9615 Acc=38.75%\n",
      "Epoch 4 Train batch 2290/3877 Loss=2.9616 Acc=38.75%\n",
      "Epoch 4 Train batch 2300/3877 Loss=2.9615 Acc=38.75%\n",
      "Epoch 4 Train batch 2310/3877 Loss=2.9618 Acc=38.74%\n",
      "Epoch 4 Train batch 2320/3877 Loss=2.9614 Acc=38.75%\n",
      "Epoch 4 Train batch 2330/3877 Loss=2.9613 Acc=38.75%\n",
      "Epoch 4 Train batch 2340/3877 Loss=2.9613 Acc=38.75%\n",
      "Epoch 4 Train batch 2350/3877 Loss=2.9614 Acc=38.75%\n",
      "Epoch 4 Train batch 2360/3877 Loss=2.9616 Acc=38.75%\n",
      "Epoch 4 Train batch 2370/3877 Loss=2.9617 Acc=38.75%\n",
      "Epoch 4 Train batch 2380/3877 Loss=2.9618 Acc=38.76%\n",
      "Epoch 4 Train batch 2390/3877 Loss=2.9618 Acc=38.76%\n",
      "Epoch 4 Train batch 2400/3877 Loss=2.9618 Acc=38.76%\n",
      "Epoch 4 Train batch 2410/3877 Loss=2.9622 Acc=38.75%\n",
      "Epoch 4 Train batch 2420/3877 Loss=2.9622 Acc=38.76%\n",
      "Epoch 4 Train batch 2430/3877 Loss=2.9622 Acc=38.76%\n",
      "Epoch 4 Train batch 2440/3877 Loss=2.9618 Acc=38.76%\n",
      "Epoch 4 Train batch 2450/3877 Loss=2.9615 Acc=38.76%\n",
      "Epoch 4 Train batch 2460/3877 Loss=2.9614 Acc=38.77%\n",
      "Epoch 4 Train batch 2470/3877 Loss=2.9613 Acc=38.77%\n",
      "Epoch 4 Train batch 2480/3877 Loss=2.9615 Acc=38.77%\n",
      "Epoch 4 Train batch 2490/3877 Loss=2.9614 Acc=38.77%\n",
      "Epoch 4 Train batch 2500/3877 Loss=2.9616 Acc=38.76%\n",
      "Epoch 4 Train batch 2510/3877 Loss=2.9616 Acc=38.77%\n",
      "Epoch 4 Train batch 2520/3877 Loss=2.9616 Acc=38.77%\n",
      "Epoch 4 Train batch 2530/3877 Loss=2.9616 Acc=38.77%\n",
      "Epoch 4 Train batch 2540/3877 Loss=2.9617 Acc=38.77%\n",
      "Epoch 4 Train batch 2550/3877 Loss=2.9615 Acc=38.77%\n",
      "Epoch 4 Train batch 2560/3877 Loss=2.9616 Acc=38.77%\n",
      "Epoch 4 Train batch 2570/3877 Loss=2.9618 Acc=38.77%\n",
      "Epoch 4 Train batch 2580/3877 Loss=2.9621 Acc=38.77%\n",
      "Epoch 4 Train batch 2590/3877 Loss=2.9624 Acc=38.77%\n",
      "Epoch 4 Train batch 2600/3877 Loss=2.9629 Acc=38.77%\n",
      "Epoch 4 Train batch 2610/3877 Loss=2.9627 Acc=38.77%\n",
      "Epoch 4 Train batch 2620/3877 Loss=2.9625 Acc=38.77%\n",
      "Epoch 4 Train batch 2630/3877 Loss=2.9625 Acc=38.77%\n",
      "Epoch 4 Train batch 2640/3877 Loss=2.9624 Acc=38.77%\n",
      "Epoch 4 Train batch 2650/3877 Loss=2.9622 Acc=38.77%\n",
      "Epoch 4 Train batch 2660/3877 Loss=2.9624 Acc=38.77%\n",
      "Epoch 4 Train batch 2670/3877 Loss=2.9623 Acc=38.77%\n",
      "Epoch 4 Train batch 2680/3877 Loss=2.9623 Acc=38.77%\n",
      "Epoch 4 Train batch 2690/3877 Loss=2.9623 Acc=38.77%\n",
      "Epoch 4 Train batch 2700/3877 Loss=2.9623 Acc=38.77%\n",
      "Epoch 4 Train batch 2710/3877 Loss=2.9624 Acc=38.77%\n",
      "Epoch 4 Train batch 2720/3877 Loss=2.9625 Acc=38.77%\n",
      "Epoch 4 Train batch 2730/3877 Loss=2.9626 Acc=38.76%\n",
      "Epoch 4 Train batch 2740/3877 Loss=2.9626 Acc=38.77%\n",
      "Epoch 4 Train batch 2750/3877 Loss=2.9627 Acc=38.76%\n",
      "Epoch 4 Train batch 2760/3877 Loss=2.9625 Acc=38.77%\n",
      "Epoch 4 Train batch 2770/3877 Loss=2.9624 Acc=38.77%\n",
      "Epoch 4 Train batch 2780/3877 Loss=2.9624 Acc=38.77%\n",
      "Epoch 4 Train batch 2790/3877 Loss=2.9622 Acc=38.78%\n",
      "Epoch 4 Train batch 2800/3877 Loss=2.9626 Acc=38.78%\n",
      "Epoch 4 Train batch 2810/3877 Loss=2.9624 Acc=38.78%\n",
      "Epoch 4 Train batch 2820/3877 Loss=2.9626 Acc=38.78%\n",
      "Epoch 4 Train batch 2830/3877 Loss=2.9629 Acc=38.78%\n",
      "Epoch 4 Train batch 2840/3877 Loss=2.9629 Acc=38.78%\n",
      "Epoch 4 Train batch 2850/3877 Loss=2.9627 Acc=38.78%\n",
      "Epoch 4 Train batch 2860/3877 Loss=2.9627 Acc=38.78%\n",
      "Epoch 4 Train batch 2870/3877 Loss=2.9626 Acc=38.78%\n",
      "Epoch 4 Train batch 2880/3877 Loss=2.9626 Acc=38.78%\n",
      "Epoch 4 Train batch 2890/3877 Loss=2.9625 Acc=38.78%\n",
      "Epoch 4 Train batch 2900/3877 Loss=2.9625 Acc=38.78%\n",
      "Epoch 4 Train batch 2910/3877 Loss=2.9624 Acc=38.78%\n",
      "Epoch 4 Train batch 2920/3877 Loss=2.9624 Acc=38.78%\n",
      "Epoch 4 Train batch 2930/3877 Loss=2.9624 Acc=38.78%\n",
      "Epoch 4 Train batch 2940/3877 Loss=2.9627 Acc=38.78%\n",
      "Epoch 4 Train batch 2950/3877 Loss=2.9629 Acc=38.78%\n",
      "Epoch 4 Train batch 2960/3877 Loss=2.9632 Acc=38.77%\n",
      "Epoch 4 Train batch 2970/3877 Loss=2.9634 Acc=38.77%\n",
      "Epoch 4 Train batch 2980/3877 Loss=2.9635 Acc=38.77%\n",
      "Epoch 4 Train batch 2990/3877 Loss=2.9637 Acc=38.77%\n",
      "Epoch 4 Train batch 3000/3877 Loss=2.9637 Acc=38.77%\n",
      "Epoch 4 Train batch 3010/3877 Loss=2.9639 Acc=38.76%\n",
      "Epoch 4 Train batch 3020/3877 Loss=2.9638 Acc=38.77%\n",
      "Epoch 4 Train batch 3030/3877 Loss=2.9637 Acc=38.76%\n",
      "Epoch 4 Train batch 3040/3877 Loss=2.9639 Acc=38.76%\n",
      "Epoch 4 Train batch 3050/3877 Loss=2.9638 Acc=38.76%\n",
      "Epoch 4 Train batch 3060/3877 Loss=2.9639 Acc=38.76%\n",
      "Epoch 4 Train batch 3070/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3080/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3090/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3100/3877 Loss=2.9642 Acc=38.76%\n",
      "Epoch 4 Train batch 3110/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3120/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3130/3877 Loss=2.9640 Acc=38.77%\n",
      "Epoch 4 Train batch 3140/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3150/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3160/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3170/3877 Loss=2.9643 Acc=38.76%\n",
      "Epoch 4 Train batch 3180/3877 Loss=2.9643 Acc=38.76%\n",
      "Epoch 4 Train batch 3190/3877 Loss=2.9644 Acc=38.76%\n",
      "Epoch 4 Train batch 3200/3877 Loss=2.9644 Acc=38.76%\n",
      "Epoch 4 Train batch 3210/3877 Loss=2.9646 Acc=38.76%\n",
      "Epoch 4 Train batch 3220/3877 Loss=2.9643 Acc=38.76%\n",
      "Epoch 4 Train batch 3230/3877 Loss=2.9644 Acc=38.76%\n",
      "Epoch 4 Train batch 3240/3877 Loss=2.9644 Acc=38.76%\n",
      "Epoch 4 Train batch 3250/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3260/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3270/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3280/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3290/3877 Loss=2.9638 Acc=38.76%\n",
      "Epoch 4 Train batch 3300/3877 Loss=2.9638 Acc=38.76%\n",
      "Epoch 4 Train batch 3310/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3320/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3330/3877 Loss=2.9638 Acc=38.76%\n",
      "Epoch 4 Train batch 3340/3877 Loss=2.9638 Acc=38.76%\n",
      "Epoch 4 Train batch 3350/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3360/3877 Loss=2.9639 Acc=38.76%\n",
      "Epoch 4 Train batch 3370/3877 Loss=2.9639 Acc=38.76%\n",
      "Epoch 4 Train batch 3380/3877 Loss=2.9642 Acc=38.76%\n",
      "Epoch 4 Train batch 3390/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3400/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3410/3877 Loss=2.9639 Acc=38.76%\n",
      "Epoch 4 Train batch 3420/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3430/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3440/3877 Loss=2.9638 Acc=38.76%\n",
      "Epoch 4 Train batch 3450/3877 Loss=2.9641 Acc=38.75%\n",
      "Epoch 4 Train batch 3460/3877 Loss=2.9639 Acc=38.76%\n",
      "Epoch 4 Train batch 3470/3877 Loss=2.9639 Acc=38.76%\n",
      "Epoch 4 Train batch 3480/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3490/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3500/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3510/3877 Loss=2.9642 Acc=38.76%\n",
      "Epoch 4 Train batch 3520/3877 Loss=2.9645 Acc=38.75%\n",
      "Epoch 4 Train batch 3530/3877 Loss=2.9646 Acc=38.75%\n",
      "Epoch 4 Train batch 3540/3877 Loss=2.9646 Acc=38.76%\n",
      "Epoch 4 Train batch 3550/3877 Loss=2.9645 Acc=38.76%\n",
      "Epoch 4 Train batch 3560/3877 Loss=2.9644 Acc=38.76%\n",
      "Epoch 4 Train batch 3570/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3580/3877 Loss=2.9642 Acc=38.76%\n",
      "Epoch 4 Train batch 3590/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3600/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3610/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3620/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3630/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3640/3877 Loss=2.9639 Acc=38.76%\n",
      "Epoch 4 Train batch 3650/3877 Loss=2.9639 Acc=38.77%\n",
      "Epoch 4 Train batch 3660/3877 Loss=2.9637 Acc=38.77%\n",
      "Epoch 4 Train batch 3670/3877 Loss=2.9637 Acc=38.77%\n",
      "Epoch 4 Train batch 3680/3877 Loss=2.9638 Acc=38.77%\n",
      "Epoch 4 Train batch 3690/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3700/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3710/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3720/3877 Loss=2.9641 Acc=38.76%\n",
      "Epoch 4 Train batch 3730/3877 Loss=2.9641 Acc=38.77%\n",
      "Epoch 4 Train batch 3740/3877 Loss=2.9640 Acc=38.76%\n",
      "Epoch 4 Train batch 3750/3877 Loss=2.9639 Acc=38.77%\n",
      "Epoch 4 Train batch 3760/3877 Loss=2.9640 Acc=38.77%\n",
      "Epoch 4 Train batch 3770/3877 Loss=2.9639 Acc=38.77%\n",
      "Epoch 4 Train batch 3780/3877 Loss=2.9640 Acc=38.77%\n",
      "Epoch 4 Train batch 3790/3877 Loss=2.9639 Acc=38.77%\n",
      "Epoch 4 Train batch 3800/3877 Loss=2.9639 Acc=38.77%\n",
      "Epoch 4 Train batch 3810/3877 Loss=2.9641 Acc=38.77%\n",
      "Epoch 4 Train batch 3820/3877 Loss=2.9640 Acc=38.77%\n",
      "Epoch 4 Train batch 3830/3877 Loss=2.9643 Acc=38.77%\n",
      "Epoch 4 Train batch 3840/3877 Loss=2.9643 Acc=38.77%\n",
      "Epoch 4 Train batch 3850/3877 Loss=2.9643 Acc=38.76%\n",
      "Epoch 4 Train batch 3860/3877 Loss=2.9641 Acc=38.77%\n",
      "Epoch 4 Train batch 3870/3877 Loss=2.9643 Acc=38.77%\n",
      "Epoch 4 Train batch 3877/3877 Loss=2.9642 Acc=38.77%\n",
      "Epoch 4/5 train_loss=2.9642 train_acc=38.77% val_loss=3.0750 val_acc=38.66%\n",
      "Epoch 5 Train batch 10/3877 Loss=2.8178 Acc=38.95%\n",
      "Epoch 5 Train batch 20/3877 Loss=2.8341 Acc=38.84%\n",
      "Epoch 5 Train batch 30/3877 Loss=2.8327 Acc=39.03%\n",
      "Epoch 5 Train batch 40/3877 Loss=2.8422 Acc=39.19%\n",
      "Epoch 5 Train batch 50/3877 Loss=2.8293 Acc=39.42%\n",
      "Epoch 5 Train batch 60/3877 Loss=2.8237 Acc=39.59%\n",
      "Epoch 5 Train batch 70/3877 Loss=2.8395 Acc=39.50%\n",
      "Epoch 5 Train batch 80/3877 Loss=2.8336 Acc=39.66%\n",
      "Epoch 5 Train batch 90/3877 Loss=2.8339 Acc=39.72%\n",
      "Epoch 5 Train batch 100/3877 Loss=2.8321 Acc=39.85%\n",
      "Epoch 5 Train batch 110/3877 Loss=2.8291 Acc=39.91%\n",
      "Epoch 5 Train batch 120/3877 Loss=2.8365 Acc=39.81%\n",
      "Epoch 5 Train batch 130/3877 Loss=2.8357 Acc=39.79%\n",
      "Epoch 5 Train batch 140/3877 Loss=2.8347 Acc=39.81%\n",
      "Epoch 5 Train batch 150/3877 Loss=2.8344 Acc=39.86%\n",
      "Epoch 5 Train batch 160/3877 Loss=2.8408 Acc=39.76%\n",
      "Epoch 5 Train batch 170/3877 Loss=2.8386 Acc=39.78%\n",
      "Epoch 5 Train batch 180/3877 Loss=2.8378 Acc=39.76%\n",
      "Epoch 5 Train batch 190/3877 Loss=2.8393 Acc=39.70%\n",
      "Epoch 5 Train batch 200/3877 Loss=2.8380 Acc=39.71%\n",
      "Epoch 5 Train batch 210/3877 Loss=2.8378 Acc=39.71%\n",
      "Epoch 5 Train batch 220/3877 Loss=2.8384 Acc=39.69%\n",
      "Epoch 5 Train batch 230/3877 Loss=2.8351 Acc=39.77%\n",
      "Epoch 5 Train batch 240/3877 Loss=2.8361 Acc=39.78%\n",
      "Epoch 5 Train batch 250/3877 Loss=2.8356 Acc=39.80%\n",
      "Epoch 5 Train batch 260/3877 Loss=2.8347 Acc=39.81%\n",
      "Epoch 5 Train batch 270/3877 Loss=2.8330 Acc=39.86%\n",
      "Epoch 5 Train batch 280/3877 Loss=2.8329 Acc=39.89%\n",
      "Epoch 5 Train batch 290/3877 Loss=2.8314 Acc=39.92%\n",
      "Epoch 5 Train batch 300/3877 Loss=2.8311 Acc=39.94%\n",
      "Epoch 5 Train batch 310/3877 Loss=2.8287 Acc=40.00%\n",
      "Epoch 5 Train batch 320/3877 Loss=2.8318 Acc=39.95%\n",
      "Epoch 5 Train batch 330/3877 Loss=2.8343 Acc=39.95%\n",
      "Epoch 5 Train batch 340/3877 Loss=2.8341 Acc=39.98%\n",
      "Epoch 5 Train batch 350/3877 Loss=2.8345 Acc=39.97%\n",
      "Epoch 5 Train batch 360/3877 Loss=2.8340 Acc=39.98%\n",
      "Epoch 5 Train batch 370/3877 Loss=2.8343 Acc=39.97%\n",
      "Epoch 5 Train batch 380/3877 Loss=2.8342 Acc=39.96%\n",
      "Epoch 5 Train batch 390/3877 Loss=2.8343 Acc=39.96%\n",
      "Epoch 5 Train batch 400/3877 Loss=2.8343 Acc=39.96%\n",
      "Epoch 5 Train batch 410/3877 Loss=2.8352 Acc=39.97%\n",
      "Epoch 5 Train batch 420/3877 Loss=2.8353 Acc=40.00%\n",
      "Epoch 5 Train batch 430/3877 Loss=2.8359 Acc=40.00%\n",
      "Epoch 5 Train batch 440/3877 Loss=2.8357 Acc=39.99%\n",
      "Epoch 5 Train batch 450/3877 Loss=2.8363 Acc=39.98%\n",
      "Epoch 5 Train batch 460/3877 Loss=2.8360 Acc=39.98%\n",
      "Epoch 5 Train batch 470/3877 Loss=2.8352 Acc=39.99%\n",
      "Epoch 5 Train batch 480/3877 Loss=2.8359 Acc=39.99%\n",
      "Epoch 5 Train batch 490/3877 Loss=2.8359 Acc=39.99%\n",
      "Epoch 5 Train batch 500/3877 Loss=2.8369 Acc=39.97%\n",
      "Epoch 5 Train batch 510/3877 Loss=2.8375 Acc=39.97%\n",
      "Epoch 5 Train batch 520/3877 Loss=2.8380 Acc=39.96%\n",
      "Epoch 5 Train batch 530/3877 Loss=2.8380 Acc=39.96%\n",
      "Epoch 5 Train batch 540/3877 Loss=2.8383 Acc=39.95%\n",
      "Epoch 5 Train batch 550/3877 Loss=2.8388 Acc=39.92%\n",
      "Epoch 5 Train batch 560/3877 Loss=2.8387 Acc=39.91%\n",
      "Epoch 5 Train batch 570/3877 Loss=2.8386 Acc=39.92%\n",
      "Epoch 5 Train batch 580/3877 Loss=2.8386 Acc=39.93%\n",
      "Epoch 5 Train batch 590/3877 Loss=2.8391 Acc=39.92%\n",
      "Epoch 5 Train batch 600/3877 Loss=2.8404 Acc=39.90%\n",
      "Epoch 5 Train batch 610/3877 Loss=2.8398 Acc=39.90%\n",
      "Epoch 5 Train batch 620/3877 Loss=2.8390 Acc=39.90%\n",
      "Epoch 5 Train batch 630/3877 Loss=2.8392 Acc=39.90%\n",
      "Epoch 5 Train batch 640/3877 Loss=2.8378 Acc=39.92%\n",
      "Epoch 5 Train batch 650/3877 Loss=2.8369 Acc=39.93%\n",
      "Epoch 5 Train batch 660/3877 Loss=2.8377 Acc=39.92%\n",
      "Epoch 5 Train batch 670/3877 Loss=2.8382 Acc=39.90%\n",
      "Epoch 5 Train batch 680/3877 Loss=2.8373 Acc=39.91%\n",
      "Epoch 5 Train batch 690/3877 Loss=2.8369 Acc=39.92%\n",
      "Epoch 5 Train batch 700/3877 Loss=2.8363 Acc=39.93%\n",
      "Epoch 5 Train batch 710/3877 Loss=2.8356 Acc=39.94%\n",
      "Epoch 5 Train batch 720/3877 Loss=2.8358 Acc=39.93%\n",
      "Epoch 5 Train batch 730/3877 Loss=2.8354 Acc=39.94%\n",
      "Epoch 5 Train batch 740/3877 Loss=2.8357 Acc=39.94%\n",
      "Epoch 5 Train batch 750/3877 Loss=2.8361 Acc=39.93%\n",
      "Epoch 5 Train batch 760/3877 Loss=2.8359 Acc=39.93%\n",
      "Epoch 5 Train batch 770/3877 Loss=2.8361 Acc=39.93%\n",
      "Epoch 5 Train batch 780/3877 Loss=2.8369 Acc=39.93%\n",
      "Epoch 5 Train batch 790/3877 Loss=2.8368 Acc=39.93%\n",
      "Epoch 5 Train batch 800/3877 Loss=2.8371 Acc=39.92%\n",
      "Epoch 5 Train batch 810/3877 Loss=2.8367 Acc=39.93%\n",
      "Epoch 5 Train batch 820/3877 Loss=2.8366 Acc=39.93%\n",
      "Epoch 5 Train batch 830/3877 Loss=2.8364 Acc=39.94%\n",
      "Epoch 5 Train batch 840/3877 Loss=2.8374 Acc=39.92%\n",
      "Epoch 5 Train batch 850/3877 Loss=2.8383 Acc=39.90%\n",
      "Epoch 5 Train batch 860/3877 Loss=2.8385 Acc=39.90%\n",
      "Epoch 5 Train batch 870/3877 Loss=2.8383 Acc=39.92%\n",
      "Epoch 5 Train batch 880/3877 Loss=2.8388 Acc=39.91%\n",
      "Epoch 5 Train batch 890/3877 Loss=2.8381 Acc=39.90%\n",
      "Epoch 5 Train batch 900/3877 Loss=2.8381 Acc=39.90%\n",
      "Epoch 5 Train batch 910/3877 Loss=2.8381 Acc=39.91%\n",
      "Epoch 5 Train batch 920/3877 Loss=2.8373 Acc=39.92%\n",
      "Epoch 5 Train batch 930/3877 Loss=2.8380 Acc=39.92%\n",
      "Epoch 5 Train batch 940/3877 Loss=2.8381 Acc=39.92%\n",
      "Epoch 5 Train batch 950/3877 Loss=2.8391 Acc=39.91%\n",
      "Epoch 5 Train batch 960/3877 Loss=2.8390 Acc=39.91%\n",
      "Epoch 5 Train batch 970/3877 Loss=2.8399 Acc=39.90%\n",
      "Epoch 5 Train batch 980/3877 Loss=2.8406 Acc=39.88%\n",
      "Epoch 5 Train batch 990/3877 Loss=2.8414 Acc=39.87%\n",
      "Epoch 5 Train batch 1000/3877 Loss=2.8420 Acc=39.85%\n",
      "Epoch 5 Train batch 1010/3877 Loss=2.8417 Acc=39.85%\n",
      "Epoch 5 Train batch 1020/3877 Loss=2.8422 Acc=39.83%\n",
      "Epoch 5 Train batch 1030/3877 Loss=2.8422 Acc=39.84%\n",
      "Epoch 5 Train batch 1040/3877 Loss=2.8426 Acc=39.84%\n",
      "Epoch 5 Train batch 1050/3877 Loss=2.8429 Acc=39.84%\n",
      "Epoch 5 Train batch 1060/3877 Loss=2.8438 Acc=39.83%\n",
      "Epoch 5 Train batch 1070/3877 Loss=2.8438 Acc=39.83%\n",
      "Epoch 5 Train batch 1080/3877 Loss=2.8437 Acc=39.83%\n",
      "Epoch 5 Train batch 1090/3877 Loss=2.8437 Acc=39.83%\n",
      "Epoch 5 Train batch 1100/3877 Loss=2.8439 Acc=39.82%\n",
      "Epoch 5 Train batch 1110/3877 Loss=2.8440 Acc=39.82%\n",
      "Epoch 5 Train batch 1120/3877 Loss=2.8441 Acc=39.83%\n",
      "Epoch 5 Train batch 1130/3877 Loss=2.8444 Acc=39.82%\n",
      "Epoch 5 Train batch 1140/3877 Loss=2.8443 Acc=39.83%\n",
      "Epoch 5 Train batch 1150/3877 Loss=2.8442 Acc=39.84%\n",
      "Epoch 5 Train batch 1160/3877 Loss=2.8438 Acc=39.84%\n",
      "Epoch 5 Train batch 1170/3877 Loss=2.8444 Acc=39.84%\n",
      "Epoch 5 Train batch 1180/3877 Loss=2.8443 Acc=39.85%\n",
      "Epoch 5 Train batch 1190/3877 Loss=2.8442 Acc=39.85%\n",
      "Epoch 5 Train batch 1200/3877 Loss=2.8443 Acc=39.85%\n",
      "Epoch 5 Train batch 1210/3877 Loss=2.8438 Acc=39.85%\n",
      "Epoch 5 Train batch 1220/3877 Loss=2.8440 Acc=39.85%\n",
      "Epoch 5 Train batch 1230/3877 Loss=2.8439 Acc=39.85%\n",
      "Epoch 5 Train batch 1240/3877 Loss=2.8433 Acc=39.85%\n",
      "Epoch 5 Train batch 1250/3877 Loss=2.8436 Acc=39.84%\n",
      "Epoch 5 Train batch 1260/3877 Loss=2.8434 Acc=39.85%\n",
      "Epoch 5 Train batch 1270/3877 Loss=2.8440 Acc=39.84%\n",
      "Epoch 5 Train batch 1280/3877 Loss=2.8438 Acc=39.84%\n",
      "Epoch 5 Train batch 1290/3877 Loss=2.8441 Acc=39.84%\n",
      "Epoch 5 Train batch 1300/3877 Loss=2.8448 Acc=39.83%\n",
      "Epoch 5 Train batch 1310/3877 Loss=2.8451 Acc=39.83%\n",
      "Epoch 5 Train batch 1320/3877 Loss=2.8456 Acc=39.83%\n",
      "Epoch 5 Train batch 1330/3877 Loss=2.8455 Acc=39.83%\n",
      "Epoch 5 Train batch 1340/3877 Loss=2.8453 Acc=39.83%\n",
      "Epoch 5 Train batch 1350/3877 Loss=2.8447 Acc=39.84%\n",
      "Epoch 5 Train batch 1360/3877 Loss=2.8451 Acc=39.83%\n",
      "Epoch 5 Train batch 1370/3877 Loss=2.8458 Acc=39.82%\n",
      "Epoch 5 Train batch 1380/3877 Loss=2.8461 Acc=39.82%\n",
      "Epoch 5 Train batch 1390/3877 Loss=2.8467 Acc=39.81%\n",
      "Epoch 5 Train batch 1400/3877 Loss=2.8463 Acc=39.82%\n",
      "Epoch 5 Train batch 1410/3877 Loss=2.8464 Acc=39.82%\n",
      "Epoch 5 Train batch 1420/3877 Loss=2.8465 Acc=39.82%\n",
      "Epoch 5 Train batch 1430/3877 Loss=2.8462 Acc=39.82%\n",
      "Epoch 5 Train batch 1440/3877 Loss=2.8462 Acc=39.82%\n",
      "Epoch 5 Train batch 1450/3877 Loss=2.8464 Acc=39.82%\n",
      "Epoch 5 Train batch 1460/3877 Loss=2.8465 Acc=39.81%\n",
      "Epoch 5 Train batch 1470/3877 Loss=2.8463 Acc=39.82%\n",
      "Epoch 5 Train batch 1480/3877 Loss=2.8460 Acc=39.82%\n",
      "Epoch 5 Train batch 1490/3877 Loss=2.8460 Acc=39.82%\n",
      "Epoch 5 Train batch 1500/3877 Loss=2.8463 Acc=39.82%\n",
      "Epoch 5 Train batch 1510/3877 Loss=2.8466 Acc=39.81%\n",
      "Epoch 5 Train batch 1520/3877 Loss=2.8467 Acc=39.81%\n",
      "Epoch 5 Train batch 1530/3877 Loss=2.8469 Acc=39.80%\n",
      "Epoch 5 Train batch 1540/3877 Loss=2.8470 Acc=39.80%\n",
      "Epoch 5 Train batch 1550/3877 Loss=2.8475 Acc=39.79%\n",
      "Epoch 5 Train batch 1560/3877 Loss=2.8478 Acc=39.78%\n",
      "Epoch 5 Train batch 1570/3877 Loss=2.8483 Acc=39.77%\n",
      "Epoch 5 Train batch 1580/3877 Loss=2.8487 Acc=39.77%\n",
      "Epoch 5 Train batch 1590/3877 Loss=2.8491 Acc=39.76%\n",
      "Epoch 5 Train batch 1600/3877 Loss=2.8491 Acc=39.76%\n",
      "Epoch 5 Train batch 1610/3877 Loss=2.8493 Acc=39.76%\n",
      "Epoch 5 Train batch 1620/3877 Loss=2.8497 Acc=39.75%\n",
      "Epoch 5 Train batch 1630/3877 Loss=2.8500 Acc=39.75%\n",
      "Epoch 5 Train batch 1640/3877 Loss=2.8498 Acc=39.75%\n",
      "Epoch 5 Train batch 1650/3877 Loss=2.8501 Acc=39.74%\n",
      "Epoch 5 Train batch 1660/3877 Loss=2.8499 Acc=39.75%\n",
      "Epoch 5 Train batch 1670/3877 Loss=2.8500 Acc=39.75%\n",
      "Epoch 5 Train batch 1680/3877 Loss=2.8501 Acc=39.74%\n",
      "Epoch 5 Train batch 1690/3877 Loss=2.8500 Acc=39.75%\n",
      "Epoch 5 Train batch 1700/3877 Loss=2.8501 Acc=39.75%\n",
      "Epoch 5 Train batch 1710/3877 Loss=2.8500 Acc=39.75%\n",
      "Epoch 5 Train batch 1720/3877 Loss=2.8501 Acc=39.75%\n",
      "Epoch 5 Train batch 1730/3877 Loss=2.8502 Acc=39.75%\n",
      "Epoch 5 Train batch 1740/3877 Loss=2.8508 Acc=39.75%\n",
      "Epoch 5 Train batch 1750/3877 Loss=2.8508 Acc=39.75%\n",
      "Epoch 5 Train batch 1760/3877 Loss=2.8509 Acc=39.74%\n",
      "Epoch 5 Train batch 1770/3877 Loss=2.8510 Acc=39.74%\n",
      "Epoch 5 Train batch 1780/3877 Loss=2.8511 Acc=39.74%\n",
      "Epoch 5 Train batch 1790/3877 Loss=2.8511 Acc=39.75%\n",
      "Epoch 5 Train batch 1800/3877 Loss=2.8517 Acc=39.74%\n",
      "Epoch 5 Train batch 1810/3877 Loss=2.8518 Acc=39.74%\n",
      "Epoch 5 Train batch 1820/3877 Loss=2.8518 Acc=39.74%\n",
      "Epoch 5 Train batch 1830/3877 Loss=2.8521 Acc=39.74%\n",
      "Epoch 5 Train batch 1840/3877 Loss=2.8519 Acc=39.74%\n",
      "Epoch 5 Train batch 1850/3877 Loss=2.8519 Acc=39.74%\n",
      "Epoch 5 Train batch 1860/3877 Loss=2.8523 Acc=39.74%\n",
      "Epoch 5 Train batch 1870/3877 Loss=2.8520 Acc=39.74%\n",
      "Epoch 5 Train batch 1880/3877 Loss=2.8520 Acc=39.75%\n",
      "Epoch 5 Train batch 1890/3877 Loss=2.8521 Acc=39.75%\n",
      "Epoch 5 Train batch 1900/3877 Loss=2.8527 Acc=39.74%\n",
      "Epoch 5 Train batch 1910/3877 Loss=2.8526 Acc=39.74%\n",
      "Epoch 5 Train batch 1920/3877 Loss=2.8527 Acc=39.73%\n",
      "Epoch 5 Train batch 1930/3877 Loss=2.8530 Acc=39.72%\n",
      "Epoch 5 Train batch 1940/3877 Loss=2.8529 Acc=39.73%\n",
      "Epoch 5 Train batch 1950/3877 Loss=2.8529 Acc=39.73%\n",
      "Epoch 5 Train batch 1960/3877 Loss=2.8531 Acc=39.72%\n",
      "Epoch 5 Train batch 1970/3877 Loss=2.8530 Acc=39.72%\n",
      "Epoch 5 Train batch 1980/3877 Loss=2.8529 Acc=39.72%\n",
      "Epoch 5 Train batch 1990/3877 Loss=2.8531 Acc=39.72%\n",
      "Epoch 5 Train batch 2000/3877 Loss=2.8530 Acc=39.72%\n",
      "Epoch 5 Train batch 2010/3877 Loss=2.8526 Acc=39.72%\n",
      "Epoch 5 Train batch 2020/3877 Loss=2.8525 Acc=39.73%\n",
      "Epoch 5 Train batch 2030/3877 Loss=2.8524 Acc=39.73%\n",
      "Epoch 5 Train batch 2040/3877 Loss=2.8520 Acc=39.73%\n",
      "Epoch 5 Train batch 2050/3877 Loss=2.8521 Acc=39.74%\n",
      "Epoch 5 Train batch 2060/3877 Loss=2.8521 Acc=39.73%\n",
      "Epoch 5 Train batch 2070/3877 Loss=2.8521 Acc=39.74%\n",
      "Epoch 5 Train batch 2080/3877 Loss=2.8524 Acc=39.73%\n",
      "Epoch 5 Train batch 2090/3877 Loss=2.8526 Acc=39.73%\n",
      "Epoch 5 Train batch 2100/3877 Loss=2.8527 Acc=39.73%\n",
      "Epoch 5 Train batch 2110/3877 Loss=2.8526 Acc=39.73%\n",
      "Epoch 5 Train batch 2120/3877 Loss=2.8527 Acc=39.73%\n",
      "Epoch 5 Train batch 2130/3877 Loss=2.8527 Acc=39.73%\n",
      "Epoch 5 Train batch 2140/3877 Loss=2.8529 Acc=39.74%\n",
      "Epoch 5 Train batch 2150/3877 Loss=2.8529 Acc=39.74%\n",
      "Epoch 5 Train batch 2160/3877 Loss=2.8529 Acc=39.74%\n",
      "Epoch 5 Train batch 2170/3877 Loss=2.8529 Acc=39.74%\n",
      "Epoch 5 Train batch 2180/3877 Loss=2.8529 Acc=39.74%\n",
      "Epoch 5 Train batch 2190/3877 Loss=2.8528 Acc=39.74%\n",
      "Epoch 5 Train batch 2200/3877 Loss=2.8529 Acc=39.74%\n",
      "Epoch 5 Train batch 2210/3877 Loss=2.8527 Acc=39.74%\n",
      "Epoch 5 Train batch 2220/3877 Loss=2.8527 Acc=39.74%\n",
      "Epoch 5 Train batch 2230/3877 Loss=2.8527 Acc=39.74%\n",
      "Epoch 5 Train batch 2240/3877 Loss=2.8525 Acc=39.75%\n",
      "Epoch 5 Train batch 2250/3877 Loss=2.8527 Acc=39.75%\n",
      "Epoch 5 Train batch 2260/3877 Loss=2.8526 Acc=39.75%\n",
      "Epoch 5 Train batch 2270/3877 Loss=2.8524 Acc=39.75%\n",
      "Epoch 5 Train batch 2280/3877 Loss=2.8525 Acc=39.75%\n",
      "Epoch 5 Train batch 2290/3877 Loss=2.8527 Acc=39.75%\n",
      "Epoch 5 Train batch 2300/3877 Loss=2.8525 Acc=39.76%\n",
      "Epoch 5 Train batch 2310/3877 Loss=2.8525 Acc=39.76%\n",
      "Epoch 5 Train batch 2320/3877 Loss=2.8527 Acc=39.75%\n",
      "Epoch 5 Train batch 2330/3877 Loss=2.8528 Acc=39.76%\n",
      "Epoch 5 Train batch 2340/3877 Loss=2.8530 Acc=39.76%\n",
      "Epoch 5 Train batch 2350/3877 Loss=2.8532 Acc=39.75%\n",
      "Epoch 5 Train batch 2360/3877 Loss=2.8530 Acc=39.76%\n",
      "Epoch 5 Train batch 2370/3877 Loss=2.8533 Acc=39.76%\n",
      "Epoch 5 Train batch 2380/3877 Loss=2.8534 Acc=39.76%\n",
      "Epoch 5 Train batch 2390/3877 Loss=2.8537 Acc=39.76%\n",
      "Epoch 5 Train batch 2400/3877 Loss=2.8537 Acc=39.76%\n",
      "Epoch 5 Train batch 2410/3877 Loss=2.8537 Acc=39.76%\n",
      "Epoch 5 Train batch 2420/3877 Loss=2.8540 Acc=39.75%\n",
      "Epoch 5 Train batch 2430/3877 Loss=2.8542 Acc=39.75%\n",
      "Epoch 5 Train batch 2440/3877 Loss=2.8543 Acc=39.75%\n",
      "Epoch 5 Train batch 2450/3877 Loss=2.8544 Acc=39.76%\n",
      "Epoch 5 Train batch 2460/3877 Loss=2.8545 Acc=39.76%\n",
      "Epoch 5 Train batch 2470/3877 Loss=2.8544 Acc=39.76%\n",
      "Epoch 5 Train batch 2480/3877 Loss=2.8544 Acc=39.76%\n",
      "Epoch 5 Train batch 2490/3877 Loss=2.8546 Acc=39.76%\n",
      "Epoch 5 Train batch 2500/3877 Loss=2.8549 Acc=39.76%\n",
      "Epoch 5 Train batch 2510/3877 Loss=2.8551 Acc=39.75%\n",
      "Epoch 5 Train batch 2520/3877 Loss=2.8554 Acc=39.75%\n",
      "Epoch 5 Train batch 2530/3877 Loss=2.8554 Acc=39.75%\n",
      "Epoch 5 Train batch 2540/3877 Loss=2.8552 Acc=39.75%\n",
      "Epoch 5 Train batch 2550/3877 Loss=2.8554 Acc=39.75%\n",
      "Epoch 5 Train batch 2560/3877 Loss=2.8555 Acc=39.75%\n",
      "Epoch 5 Train batch 2570/3877 Loss=2.8555 Acc=39.76%\n",
      "Epoch 5 Train batch 2580/3877 Loss=2.8558 Acc=39.75%\n",
      "Epoch 5 Train batch 2590/3877 Loss=2.8560 Acc=39.75%\n",
      "Epoch 5 Train batch 2600/3877 Loss=2.8562 Acc=39.75%\n",
      "Epoch 5 Train batch 2610/3877 Loss=2.8561 Acc=39.75%\n",
      "Epoch 5 Train batch 2620/3877 Loss=2.8560 Acc=39.75%\n",
      "Epoch 5 Train batch 2630/3877 Loss=2.8557 Acc=39.75%\n",
      "Epoch 5 Train batch 2640/3877 Loss=2.8557 Acc=39.75%\n",
      "Epoch 5 Train batch 2650/3877 Loss=2.8559 Acc=39.75%\n",
      "Epoch 5 Train batch 2660/3877 Loss=2.8558 Acc=39.74%\n",
      "Epoch 5 Train batch 2670/3877 Loss=2.8555 Acc=39.75%\n",
      "Epoch 5 Train batch 2680/3877 Loss=2.8554 Acc=39.75%\n",
      "Epoch 5 Train batch 2690/3877 Loss=2.8555 Acc=39.74%\n",
      "Epoch 5 Train batch 2700/3877 Loss=2.8557 Acc=39.74%\n",
      "Epoch 5 Train batch 2710/3877 Loss=2.8556 Acc=39.75%\n",
      "Epoch 5 Train batch 2720/3877 Loss=2.8556 Acc=39.75%\n",
      "Epoch 5 Train batch 2730/3877 Loss=2.8557 Acc=39.74%\n",
      "Epoch 5 Train batch 2740/3877 Loss=2.8560 Acc=39.73%\n",
      "Epoch 5 Train batch 2750/3877 Loss=2.8564 Acc=39.73%\n",
      "Epoch 5 Train batch 2760/3877 Loss=2.8562 Acc=39.73%\n",
      "Epoch 5 Train batch 2770/3877 Loss=2.8563 Acc=39.73%\n",
      "Epoch 5 Train batch 2780/3877 Loss=2.8561 Acc=39.73%\n",
      "Epoch 5 Train batch 2790/3877 Loss=2.8564 Acc=39.73%\n",
      "Epoch 5 Train batch 2800/3877 Loss=2.8565 Acc=39.73%\n",
      "Epoch 5 Train batch 2810/3877 Loss=2.8565 Acc=39.73%\n",
      "Epoch 5 Train batch 2820/3877 Loss=2.8566 Acc=39.73%\n",
      "Epoch 5 Train batch 2830/3877 Loss=2.8566 Acc=39.74%\n",
      "Epoch 5 Train batch 2840/3877 Loss=2.8568 Acc=39.74%\n",
      "Epoch 5 Train batch 2850/3877 Loss=2.8569 Acc=39.74%\n",
      "Epoch 5 Train batch 2860/3877 Loss=2.8571 Acc=39.73%\n",
      "Epoch 5 Train batch 2870/3877 Loss=2.8570 Acc=39.73%\n",
      "Epoch 5 Train batch 2880/3877 Loss=2.8570 Acc=39.73%\n",
      "Epoch 5 Train batch 2890/3877 Loss=2.8573 Acc=39.73%\n",
      "Epoch 5 Train batch 2900/3877 Loss=2.8571 Acc=39.73%\n",
      "Epoch 5 Train batch 2910/3877 Loss=2.8573 Acc=39.73%\n",
      "Epoch 5 Train batch 2920/3877 Loss=2.8572 Acc=39.73%\n",
      "Epoch 5 Train batch 2930/3877 Loss=2.8572 Acc=39.73%\n",
      "Epoch 5 Train batch 2940/3877 Loss=2.8570 Acc=39.73%\n",
      "Epoch 5 Train batch 2950/3877 Loss=2.8573 Acc=39.73%\n",
      "Epoch 5 Train batch 2960/3877 Loss=2.8574 Acc=39.73%\n",
      "Epoch 5 Train batch 2970/3877 Loss=2.8573 Acc=39.73%\n",
      "Epoch 5 Train batch 2980/3877 Loss=2.8574 Acc=39.73%\n",
      "Epoch 5 Train batch 2990/3877 Loss=2.8576 Acc=39.73%\n",
      "Epoch 5 Train batch 3000/3877 Loss=2.8573 Acc=39.74%\n",
      "Epoch 5 Train batch 3010/3877 Loss=2.8576 Acc=39.74%\n",
      "Epoch 5 Train batch 3020/3877 Loss=2.8576 Acc=39.74%\n",
      "Epoch 5 Train batch 3030/3877 Loss=2.8578 Acc=39.74%\n",
      "Epoch 5 Train batch 3040/3877 Loss=2.8578 Acc=39.73%\n",
      "Epoch 5 Train batch 3050/3877 Loss=2.8577 Acc=39.73%\n",
      "Epoch 5 Train batch 3060/3877 Loss=2.8577 Acc=39.74%\n",
      "Epoch 5 Train batch 3070/3877 Loss=2.8577 Acc=39.74%\n",
      "Epoch 5 Train batch 3080/3877 Loss=2.8578 Acc=39.74%\n",
      "Epoch 5 Train batch 3090/3877 Loss=2.8579 Acc=39.74%\n",
      "Epoch 5 Train batch 3100/3877 Loss=2.8581 Acc=39.74%\n",
      "Epoch 5 Train batch 3110/3877 Loss=2.8582 Acc=39.74%\n",
      "Epoch 5 Train batch 3120/3877 Loss=2.8583 Acc=39.73%\n",
      "Epoch 5 Train batch 3130/3877 Loss=2.8582 Acc=39.74%\n",
      "Epoch 5 Train batch 3140/3877 Loss=2.8579 Acc=39.74%\n",
      "Epoch 5 Train batch 3150/3877 Loss=2.8579 Acc=39.74%\n",
      "Epoch 5 Train batch 3160/3877 Loss=2.8580 Acc=39.74%\n",
      "Epoch 5 Train batch 3170/3877 Loss=2.8579 Acc=39.74%\n",
      "Epoch 5 Train batch 3180/3877 Loss=2.8581 Acc=39.74%\n",
      "Epoch 5 Train batch 3190/3877 Loss=2.8583 Acc=39.74%\n",
      "Epoch 5 Train batch 3200/3877 Loss=2.8583 Acc=39.74%\n",
      "Epoch 5 Train batch 3210/3877 Loss=2.8582 Acc=39.74%\n",
      "Epoch 5 Train batch 3220/3877 Loss=2.8581 Acc=39.74%\n",
      "Epoch 5 Train batch 3230/3877 Loss=2.8584 Acc=39.74%\n",
      "Epoch 5 Train batch 3240/3877 Loss=2.8585 Acc=39.74%\n",
      "Epoch 5 Train batch 3250/3877 Loss=2.8584 Acc=39.74%\n",
      "Epoch 5 Train batch 3260/3877 Loss=2.8584 Acc=39.74%\n",
      "Epoch 5 Train batch 3270/3877 Loss=2.8587 Acc=39.73%\n",
      "Epoch 5 Train batch 3280/3877 Loss=2.8588 Acc=39.73%\n",
      "Epoch 5 Train batch 3290/3877 Loss=2.8589 Acc=39.73%\n",
      "Epoch 5 Train batch 3300/3877 Loss=2.8593 Acc=39.72%\n",
      "Epoch 5 Train batch 3310/3877 Loss=2.8595 Acc=39.72%\n",
      "Epoch 5 Train batch 3320/3877 Loss=2.8596 Acc=39.72%\n",
      "Epoch 5 Train batch 3330/3877 Loss=2.8597 Acc=39.72%\n",
      "Epoch 5 Train batch 3340/3877 Loss=2.8597 Acc=39.72%\n",
      "Epoch 5 Train batch 3350/3877 Loss=2.8594 Acc=39.72%\n",
      "Epoch 5 Train batch 3360/3877 Loss=2.8594 Acc=39.72%\n",
      "Epoch 5 Train batch 3370/3877 Loss=2.8596 Acc=39.72%\n",
      "Epoch 5 Train batch 3380/3877 Loss=2.8595 Acc=39.72%\n",
      "Epoch 5 Train batch 3390/3877 Loss=2.8595 Acc=39.72%\n",
      "Epoch 5 Train batch 3400/3877 Loss=2.8593 Acc=39.72%\n",
      "Epoch 5 Train batch 3410/3877 Loss=2.8591 Acc=39.73%\n",
      "Epoch 5 Train batch 3420/3877 Loss=2.8591 Acc=39.73%\n",
      "Epoch 5 Train batch 3430/3877 Loss=2.8591 Acc=39.73%\n",
      "Epoch 5 Train batch 3440/3877 Loss=2.8590 Acc=39.73%\n",
      "Epoch 5 Train batch 3450/3877 Loss=2.8589 Acc=39.73%\n",
      "Epoch 5 Train batch 3460/3877 Loss=2.8589 Acc=39.73%\n",
      "Epoch 5 Train batch 3470/3877 Loss=2.8589 Acc=39.73%\n",
      "Epoch 5 Train batch 3480/3877 Loss=2.8589 Acc=39.74%\n",
      "Epoch 5 Train batch 3490/3877 Loss=2.8590 Acc=39.74%\n",
      "Epoch 5 Train batch 3500/3877 Loss=2.8590 Acc=39.74%\n",
      "Epoch 5 Train batch 3510/3877 Loss=2.8587 Acc=39.74%\n",
      "Epoch 5 Train batch 3520/3877 Loss=2.8588 Acc=39.74%\n",
      "Epoch 5 Train batch 3530/3877 Loss=2.8588 Acc=39.74%\n",
      "Epoch 5 Train batch 3540/3877 Loss=2.8590 Acc=39.73%\n",
      "Epoch 5 Train batch 3550/3877 Loss=2.8589 Acc=39.74%\n",
      "Epoch 5 Train batch 3560/3877 Loss=2.8589 Acc=39.74%\n",
      "Epoch 5 Train batch 3570/3877 Loss=2.8590 Acc=39.74%\n",
      "Epoch 5 Train batch 3580/3877 Loss=2.8590 Acc=39.74%\n",
      "Epoch 5 Train batch 3590/3877 Loss=2.8590 Acc=39.74%\n",
      "Epoch 5 Train batch 3600/3877 Loss=2.8589 Acc=39.74%\n",
      "Epoch 5 Train batch 3610/3877 Loss=2.8588 Acc=39.74%\n",
      "Epoch 5 Train batch 3620/3877 Loss=2.8586 Acc=39.74%\n",
      "Epoch 5 Train batch 3630/3877 Loss=2.8586 Acc=39.74%\n",
      "Epoch 5 Train batch 3640/3877 Loss=2.8586 Acc=39.74%\n",
      "Epoch 5 Train batch 3650/3877 Loss=2.8586 Acc=39.74%\n",
      "Epoch 5 Train batch 3660/3877 Loss=2.8586 Acc=39.75%\n",
      "Epoch 5 Train batch 3670/3877 Loss=2.8585 Acc=39.74%\n",
      "Epoch 5 Train batch 3680/3877 Loss=2.8584 Acc=39.75%\n",
      "Epoch 5 Train batch 3690/3877 Loss=2.8584 Acc=39.75%\n",
      "Epoch 5 Train batch 3700/3877 Loss=2.8588 Acc=39.74%\n",
      "Epoch 5 Train batch 3710/3877 Loss=2.8587 Acc=39.74%\n",
      "Epoch 5 Train batch 3720/3877 Loss=2.8587 Acc=39.74%\n",
      "Epoch 5 Train batch 3730/3877 Loss=2.8587 Acc=39.74%\n",
      "Epoch 5 Train batch 3740/3877 Loss=2.8586 Acc=39.74%\n",
      "Epoch 5 Train batch 3750/3877 Loss=2.8585 Acc=39.75%\n",
      "Epoch 5 Train batch 3760/3877 Loss=2.8585 Acc=39.75%\n",
      "Epoch 5 Train batch 3770/3877 Loss=2.8585 Acc=39.75%\n",
      "Epoch 5 Train batch 3780/3877 Loss=2.8587 Acc=39.74%\n",
      "Epoch 5 Train batch 3790/3877 Loss=2.8588 Acc=39.74%\n",
      "Epoch 5 Train batch 3800/3877 Loss=2.8588 Acc=39.74%\n",
      "Epoch 5 Train batch 3810/3877 Loss=2.8586 Acc=39.74%\n",
      "Epoch 5 Train batch 3820/3877 Loss=2.8586 Acc=39.75%\n",
      "Epoch 5 Train batch 3830/3877 Loss=2.8588 Acc=39.74%\n",
      "Epoch 5 Train batch 3840/3877 Loss=2.8589 Acc=39.74%\n",
      "Epoch 5 Train batch 3850/3877 Loss=2.8590 Acc=39.74%\n",
      "Epoch 5 Train batch 3860/3877 Loss=2.8591 Acc=39.73%\n",
      "Epoch 5 Train batch 3870/3877 Loss=2.8591 Acc=39.73%\n",
      "Epoch 5 Train batch 3877/3877 Loss=2.8592 Acc=39.73%\n",
      "Epoch 5/5 train_loss=2.8592 train_acc=39.73% val_loss=3.0645 val_acc=38.75%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model 3: Pre-trained ViT as encoder, same text transformer decoder:",
   "id": "f825371530f54d33"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Image caption model with transformers, pre-trained encoder.\n",
    "\n",
    "Encoder: ViT with transfer learning from google/vit-base-patch16-224.\n",
    "\n",
    "Decoder: Small text transformer, no transfer learning."
   ],
   "id": "33697f2d30915e76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-20T23:44:31.753286Z",
     "start_time": "2025-10-20T23:44:02.679745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --------------- Encoder: ---------------\n",
    "\n",
    "# Load pretrained DINOv3 encoder\n",
    "encoder = AutoModel.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "\n",
    "# Freeze encoder parameters\n",
    "for param in encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Define a projection layer if necessary\n",
    "class EncoderWithProjection(nn.Module):\n",
    "    def __init__(self, encoder, embed_size):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.proj = nn.Linear(encoder.config.hidden_size, embed_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.encoder(x)\n",
    "        pooled = outputs.pooler_output  # (batch_size, hidden_size)\n",
    "        return self.proj(pooled)\n",
    "\n",
    "# --------------- Training: ---------------\n",
    "\n",
    "clear_cache()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 2e-5\n",
    "\n",
    "EMBED_SIZE = 768\n",
    "\n",
    "OUTPUT_DIR = \"./models_vit_DINOv3_enc\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "# Instantiate models\n",
    "enc = EncoderWithProjection(\n",
    "    encoder,\n",
    "    embed_size=EMBED_SIZE\n",
    ")\n",
    "\n",
    "# Optimizers and loss\n",
    "enc_opt = torch.optim.Adam(enc.parameters(), lr=LEARNING_RATE)\n",
    "dec_opt = None # decoder frozen\n",
    "\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "\n",
    "# Train\n",
    "history = fit_model(\n",
    "    enc=enc, dec=dec,\n",
    "    train_loader=train_loader, val_loader=val_loader,\n",
    "    enc_opt=enc_opt, dec_opt=dec_opt,\n",
    "    device=DEVICE,\n",
    "    vocab=vocab,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    train_encoder_only=True\n",
    ")"
   ],
   "id": "ac8f5b46562fe1f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 6989\n",
      "Epoch 1 Train batch 10/3877 Loss=3.2261 Acc=36.74%\n",
      "Epoch 1 Train batch 20/3877 Loss=3.1950 Acc=36.39%\n",
      "Epoch 1 Train batch 30/3877 Loss=3.1916 Acc=36.14%\n",
      "Epoch 1 Train batch 40/3877 Loss=3.1947 Acc=36.23%\n",
      "Epoch 1 Train batch 50/3877 Loss=3.1856 Acc=36.38%\n",
      "Epoch 1 Train batch 60/3877 Loss=3.1844 Acc=36.63%\n",
      "Epoch 1 Train batch 70/3877 Loss=3.1682 Acc=36.90%\n",
      "Epoch 1 Train batch 80/3877 Loss=3.1688 Acc=36.92%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 51\u001B[39m\n\u001B[32m     48\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mVocab size:\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28mlen\u001B[39m(vocab))\n\u001B[32m     50\u001B[39m \u001B[38;5;66;03m# Train\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m51\u001B[39m history = \u001B[43mfit_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     52\u001B[39m \u001B[43m    \u001B[49m\u001B[43menc\u001B[49m\u001B[43m=\u001B[49m\u001B[43menc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdec\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdec\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     53\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m=\u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     54\u001B[39m \u001B[43m    \u001B[49m\u001B[43menc_opt\u001B[49m\u001B[43m=\u001B[49m\u001B[43menc_opt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdec_opt\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdec_opt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     55\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mDEVICE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     56\u001B[39m \u001B[43m    \u001B[49m\u001B[43mvocab\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     57\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mOUTPUT_DIR\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     58\u001B[39m \u001B[43m    \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mNUM_EPOCHS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     59\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_encoder_only\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[32m     60\u001B[39m \u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 69\u001B[39m, in \u001B[36mfit_model\u001B[39m\u001B[34m(enc, dec, train_loader, val_loader, enc_opt, dec_opt, device, vocab, output_dir, num_epochs, criterion, print_every, train_encoder_only)\u001B[39m\n\u001B[32m     67\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (images, caps, _) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader, \u001B[32m1\u001B[39m):\n\u001B[32m     68\u001B[39m     images, caps = images.to(device), caps.to(device)\n\u001B[32m---> \u001B[39m\u001B[32m69\u001B[39m     features = \u001B[43menc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     70\u001B[39m     logits = dec(features, caps[:, :-\u001B[32m1\u001B[39m])\n\u001B[32m     71\u001B[39m     loss = criterion(logits.reshape(-\u001B[32m1\u001B[39m, logits.size(-\u001B[32m1\u001B[39m)), caps[:, \u001B[32m1\u001B[39m:].reshape(-\u001B[32m1\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 18\u001B[39m, in \u001B[36mEncoderWithProjection.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m---> \u001B[39m\u001B[32m18\u001B[39m     outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     19\u001B[39m     pooled = outputs.pooler_output  \u001B[38;5;66;03m# (batch_size, hidden_size)\u001B[39;00m\n\u001B[32m     20\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.proj(pooled)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\transformers\\utils\\generic.py:1064\u001B[39m, in \u001B[36mcheck_model_inputs.<locals>.wrapper\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1061\u001B[39m                 monkey_patched_layers.append((module, original_forward))\n\u001B[32m   1063\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1064\u001B[39m     outputs = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1065\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m original_exception:\n\u001B[32m   1066\u001B[39m     \u001B[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001B[39;00m\n\u001B[32m   1067\u001B[39m     \u001B[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001B[39;00m\n\u001B[32m   1068\u001B[39m     \u001B[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001B[39;00m\n\u001B[32m   1069\u001B[39m     kwargs_without_recordable = {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs.items() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m recordable_keys}\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py:485\u001B[39m, in \u001B[36mViTModel.forward\u001B[39m\u001B[34m(self, pixel_values, bool_masked_pos, head_mask, interpolate_pos_encoding, **kwargs)\u001B[39m\n\u001B[32m    479\u001B[39m     pixel_values = pixel_values.to(expected_dtype)\n\u001B[32m    481\u001B[39m embedding_output = \u001B[38;5;28mself\u001B[39m.embeddings(\n\u001B[32m    482\u001B[39m     pixel_values, bool_masked_pos=bool_masked_pos, interpolate_pos_encoding=interpolate_pos_encoding\n\u001B[32m    483\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m485\u001B[39m encoder_outputs: BaseModelOutput = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    487\u001B[39m sequence_output = encoder_outputs.last_hidden_state\n\u001B[32m    488\u001B[39m sequence_output = \u001B[38;5;28mself\u001B[39m.layernorm(sequence_output)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py:368\u001B[39m, in \u001B[36mViTEncoder.forward\u001B[39m\u001B[34m(self, hidden_states, head_mask)\u001B[39m\n\u001B[32m    366\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, layer_module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m.layer):\n\u001B[32m    367\u001B[39m     layer_head_mask = head_mask[i] \u001B[38;5;28;01mif\u001B[39;00m head_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m368\u001B[39m     hidden_states = \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    370\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m BaseModelOutput(last_hidden_state=hidden_states)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001B[39m, in \u001B[36mGradientCheckpointingLayer.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     91\u001B[39m         logger.warning_once(message)\n\u001B[32m     93\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(partial(\u001B[38;5;28msuper\u001B[39m().\u001B[34m__call__\u001B[39m, **kwargs), *args)\n\u001B[32m---> \u001B[39m\u001B[32m94\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py:353\u001B[39m, in \u001B[36mViTLayer.forward\u001B[39m\u001B[34m(self, hidden_states, head_mask)\u001B[39m\n\u001B[32m    350\u001B[39m layer_output = \u001B[38;5;28mself\u001B[39m.intermediate(layer_output)\n\u001B[32m    352\u001B[39m \u001B[38;5;66;03m# second residual connection is done here\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m353\u001B[39m layer_output = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlayer_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    355\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m layer_output\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\transformers\\models\\vit\\modeling_vit.py:322\u001B[39m, in \u001B[36mViTOutput.forward\u001B[39m\u001B[34m(self, hidden_states, input_tensor)\u001B[39m\n\u001B[32m    321\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m322\u001B[39m     hidden_states = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdense\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    323\u001B[39m     hidden_states = \u001B[38;5;28mself\u001B[39m.dropout(hidden_states)\n\u001B[32m    324\u001B[39m     hidden_states = hidden_states + input_tensor\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
